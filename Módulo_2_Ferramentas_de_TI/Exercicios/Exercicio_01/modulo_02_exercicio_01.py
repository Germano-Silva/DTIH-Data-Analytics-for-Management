# -*- coding: utf-8 -*-
"""Modulo_02-Exercicio_01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XR8H7MpyITOo-584XRL1wmtrxjSWlfPo
"""

import pandas as pd
from io import StringIO

# Dados do arquivo CSV
csv_data = """E-mail,Status do e-mail,Nome,Sobrenome,Nome completo,Usu√°rio - redes sociais,LinkedIn,Cargo,Pa√≠s,Localiza√ß√£o,Setor,Adicionar data,Nome da empresa,URL da empresa,Empresa - redes sociais,Tamanho da empresa,Pa√≠s da empresa,Localiza√ß√£o da empresa,Estado,Cidade,Setor da empresa,Telefone da sede,Telefone,Classifica√ß√£o
aliaksei.kaliaha@nordcurrent.com,unknown,Aliaksei,Kaliaha,Aliaksei Kaliaha,https://www.linkedin.com/in/alex-kolyago,https://www.linkedin.com/in/alex-kolyago,Senior DevOps/SRE Engineer,Lithuania,"Vilnius, Vilniaus, Lithuania",Mobile Games,2025-02-13 15:24:00,Nordcurrent,http://www.nordcurrent.com,https://www.linkedin.com/company/2817754,201-500,Lithuania,"Vilnius, Vilniaus, Lithuania",,Vilnius,Computer Games,,,Muito grande
..."""  # (dados truncados por brevidade)

# Carregar os dados
df = pd.read_csv(StringIO(csv_data))

# Analisar as colunas
colunas_info = []

for coluna in df.columns:
    # Tipo de dados
    tipo_dados = str(df[coluna].dtype)

    # Amostra de valores √∫nicos (primeiros 5)
    valores_unicos = df[coluna].dropna().unique()[:5]

    # Descri√ß√£o da informa√ß√£o baseada no nome da coluna e valores
    if coluna == "E-mail":
        descricao = "Endere√ßo de e-mail dos profissionais"
    elif coluna == "Status do e-mail":
        descricao = "Status de valida√ß√£o do e-mail (valid, not valid, unknown)"
    elif coluna == "Nome":
        descricao = "Primeiro nome do profissional"
    elif coluna == "Sobrenome":
        descricao = "Sobrenome do profissional"
    elif coluna == "Nome completo":
        descricao = "Nome completo do profissional"
    elif coluna == "Usu√°rio - redes sociais":
        descricao = "URLs de perfis em redes sociais"
    elif coluna == "LinkedIn":
        descricao = "URL do perfil do LinkedIn"
    elif coluna == "Cargo":
        descricao = "Cargo/posi√ß√£o do profissional na empresa"
    elif coluna == "Pa√≠s":
        descricao = "Pa√≠s de localiza√ß√£o do profissional"
    elif coluna == "Localiza√ß√£o":
        descricao = "Localiza√ß√£o detalhada do profissional"
    elif coluna == "Setor":
        descricao = "Setor de atua√ß√£o do profissional"
    elif coluna == "Adicionar data":
        descricao = "Data e hora de adi√ß√£o do registro"
    elif coluna == "Nome da empresa":
        descricao = "Nome da empresa onde o profissional trabalha"
    elif coluna == "URL da empresa":
        descricao = "Website da empresa"
    elif coluna == "Empresa - redes sociais":
        descricao = "URLs de redes sociais da empresa"
    elif coluna == "Tamanho da empresa":
        descricao = "Faixa de tamanho da empresa (ex: 1-10, 11-50, 51-200, etc.)"
    elif coluna == "Pa√≠s da empresa":
        descricao = "Pa√≠s onde a empresa est√° sediada"
    elif coluna == "Localiza√ß√£o da empresa":
        descricao = "Localiza√ß√£o detalhada da sede da empresa"
    elif coluna == "Estado":
        descricao = "Estado/prov√≠ncia da empresa"
    elif coluna == "Cidade":
        descricao = "Cidade da empresa"
    elif coluna == "Setor da empresa":
        descricao = "Setor principal de atua√ß√£o da empresa"
    elif coluna == "Telefone da sede":
        descricao = "Telefone da sede da empresa"
    elif coluna == "Telefone":
        descricao = "Telefone de contato (provavelmente do profissional)"
    elif coluna == "Classifica√ß√£o":
        descricao = "Classifica√ß√£o de tamanho da empresa (Pequena, M√©dia, Grande, etc.)"
    else:
        descricao = "Informa√ß√£o n√£o especificada"

    colunas_info.append({
        "Coluna": coluna,
        "Tipo de Dados": tipo_dados,
        "Descri√ß√£o": descricao,
        "Valores √önicos (amostra)": list(valores_unicos)
    })

# Criar DataFrame com as informa√ß√µes
info_df = pd.DataFrame(colunas_info)

# Exibir resultados
print("AN√ÅLISE DAS COLUNAS DO DATASET")
print("=" * 80)

for _, row in info_df.iterrows():
    print(f"\nCOLUNA: {row['Coluna']}")
    print(f"Tipo de dados: {row['Tipo de Dados']}")
    print(f"Descri√ß√£o: {row['Descri√ß√£o']}")
    print(f"Valores √∫nicos (amostra): {row['Valores √önicos (amostra)']}")
    print("-" * 80)

# Estat√≠sticas gerais
print(f"\nRESUMO GERAL:")
print(f"Total de colunas: {len(df.columns)}")
print(f"Total de registros: {len(df)}")
print(f"Colunas com valores nulos: {df.isnull().any().sum()}")

# =============================================================================
# AN√ÅLISE DE QUALIDADE DA BASE DE DADOS
# =============================================================================

import pandas as pd
import numpy as np

def analisar_qualidade_dados(df, limite_exibicao=20):
    """
    Fun√ß√£o para analisar a qualidade dos dados e identificar problemas

    Parameters:
    df: DataFrame a ser analisado
    limite_exibicao: N√∫mero m√°ximo de valores a exibir para cada coluna
    """

    print("=" * 60)
    print("AN√ÅLISE DE QUALIDADE DA BASE DE DADOS")
    print("=" * 60)

    # 1. Informa√ß√µes b√°sicas da base
    print(f"\n1. INFORMACOES BASICAS:")
    print(f"   - Total de registros: {df.shape[0]:,}")
    print(f"   - Total de colunas: {df.shape[1]}")
    print(f"   - Total de c√©lulas: {df.shape[0] * df.shape[1]:,}")

    # 2. An√°lise de Valores Nulos
    print(f"\n2. ANALISE DE VALORES NULOS:")

    # Calculando valores nulos por coluna
    nulos_por_coluna = df.isnull().sum()
    nulos_percentual = (df.isnull().sum() / len(df)) * 100

    # Criando DataFrame para an√°lise de nulos
    analise_nulos = pd.DataFrame({
        'Coluna': nulos_por_coluna.index,
        'Valores_Nulos': nulos_por_coluna.values,
        'Percentual_Nulos': nulos_percentual.values
    })

    # Filtrando apenas colunas com valores nulos
    colunas_com_nulos = analise_nulos[analise_nulos['Valores_Nulos'] > 0]

    if len(colunas_com_nulos) > 0:
        print("   ‚ö†Ô∏è  Colunas com valores nulos:")
        for _, row in colunas_com_nulos.sort_values('Percentual_Nulos', ascending=False).iterrows():
            print(f"      - {row['Coluna']}: {row['Valores_Nulos']:,} nulos ({row['Percentual_Nulos']:.2f}%)")
    else:
        print("   ‚úÖ Nenhum valor nulo encontrado")

    # 3. An√°lise de Registros Duplicados
    print(f"\n3. ANALISE DE REGISTROS DUPLICADOS:")

    duplicados_totais = df.duplicated().sum()
    duplicados_completos = df[df.duplicated(keep=False)]

    print(f"   - Registros totalmente duplicados: {duplicados_totais:,}")

    if duplicados_totais > 0:
        print(f"   ‚ö†Ô∏è  Percentual de duplicados: {(duplicados_totais/len(df))*100:.2f}%")
        if duplicados_totais > 5:
            print(f"   üìã Amostra de 5 registros duplicados:")
            print(duplicados_completos.head(5).to_string())
        else:
            print(f"   üìã Todos os registros duplicados:")
            print(duplicados_completos.to_string())

    # 4. An√°lise de Inconsist√™ncias por Coluna
    print(f"\n4. ANALISE DE INCONSISTENCIAS ESPECIFICAS:")

    # Para colunas categ√≥ricas espec√≠ficas
    colunas_categoricas = df.select_dtypes(include=['object']).columns

    for coluna in colunas_categoricas:
        valores_unicos = df[coluna].nunique()

        # Mostrar an√°lise para todas as colunas categ√≥ricas, mas com limite de exibi√ß√£o
        print(f"\n   üìä {coluna}:")
        print(f"      - Valores √∫nicos: {valores_unicos}")
        print(f"      - Valores nulos: {df[coluna].isnull().sum()} ({df[coluna].isnull().sum()/len(df)*100:.1f}%)")

        # Mostrar distribui√ß√£o com limite
        if valores_unicos > 0:
            distribuicao = df[coluna].value_counts(dropna=False)
            print(f"      - Top {min(limite_exibicao, valores_unicos)} valores:")

            for i, (valor, count) in enumerate(distribuicao.items()):
                if i >= limite_exibicao:
                    print(f"        ... e mais {valores_unicos - limite_exibicao} valores")
                    break
                percentual = (count / len(df)) * 100
                print(f"        '{valor}': {count:,} registros ({percentual:.1f}%)")

    # 5. An√°lise espec√≠fica para colunas problem√°ticas identificadas
    print(f"\n5. ANALISE ESPECIFICA DE COLUNAS PROBLEMATICAS:")

    # Colunas que devem ser num√©ricas mas est√£o como float64 com muitos nulos
    colunas_numericas_problematicas = ['Estado', 'Telefone da sede', 'Telefone']

    for coluna in colunas_numericas_problematicas:
        if coluna in df.columns:
            nulos_coluna = df[coluna].isnull().sum()
            print(f"   üîç {coluna}:")
            print(f"      - Tipo de dados: {df[coluna].dtype}")
            print(f"      - Valores nulos: {nulos_coluna:,} ({nulos_coluna/len(df)*100:.1f}%)")
            print(f"      - Valores n√£o nulos: {len(df) - nulos_coluna:,}")

            if nulos_coluna < len(df):
                print(f"      - Valores √∫nicos n√£o nulos: {df[coluna].dropna().nunique()}")
                # Mostrar mais exemplos se necess√°rio
                valores_exemplo = df[coluna].dropna().unique()
                print(f"      - Exemplo de valores (mostrando {min(10, len(valores_exemplo))}): {valores_exemplo[:10]}")

    # 6. An√°lise de redund√¢ncia entre colunas
    print(f"\n6. ANALISE DE REDUNDANCIA:")

    # Verificar se Nome + Sobrenome = Nome completo
    if all(col in df.columns for col in ['Nome', 'Sobrenome', 'Nome completo']):
        nomes_combinados = (df['Nome'] + ' ' + df['Sobrenome']).fillna('')
        nomes_iguais = (nomes_combinados == df['Nome completo'].fillna('')).sum()
        print(f"   - Concord√¢ncia Nome+Sobrenome vs Nome completo: {nomes_iguais/len(df)*100:.1f}% ({nomes_iguais:,} registros)")

    # Verificar redund√¢ncia LinkedIn vs redes sociais
    if all(col in df.columns for col in ['LinkedIn', 'Usu√°rio - redes sociais']):
        linkedin_in_redes = df['Usu√°rio - redes sociais'].str.contains('linkedin', case=False, na=False).sum()
        print(f"   - Perfis LinkedIn na coluna gen√©rica: {linkedin_in_redes:,} registros")

    return analise_nulos

# =============================================================================
# EXECU√á√ÉO DA AN√ÅLISE
# =============================================================================

# Supondo que seu DataFrame se chame 'df'
# Substitua 'df' pelo nome do seu DataFrame

try:
    # Executar an√°lise com limite maior de exibi√ß√£o
    resultado_analise = analisar_qualidade_dados(df, limite_exibicao=15)

    # Resumo final
    print("\n" + "=" * 60)
    print("RESUMO DA QUALIDADE DOS DADOS")
    print("=" * 60)

    total_nulos = df.isnull().sum().sum()
    total_celulas = df.shape[0] * df.shape[1]
    percentual_nulos = (total_nulos / total_celulas) * 100

    print(f"üìà Total de valores nulos: {total_nulos:,}/{total_celulas:,} ({percentual_nulos:.2f}%)")
    print(f"üîÅ Registros duplicados: {df.duplicated().sum():,}")

    colunas_problematicas = [col for col in df.columns if df[col].isnull().sum()/len(df) > 0.5]
    print(f"üè≠ Colunas com mais de 50% de nulos: {len(colunas_problematicas)}")
    if colunas_problematicas:
        for coluna in colunas_problematicas:
            percentual = df[coluna].isnull().sum()/len(df)*100
            print(f"     - {coluna}: {percentual:.1f}% nulos")

except NameError:
    print("‚ùå DataFrame 'df' n√£o encontrado.")
    print("üí° Certifique-se de que seu DataFrame est√° carregado com o nome 'df'")
except Exception as e:
    print(f"‚ùå Erro durante a an√°lise: {e}")

# =============================================================================
# FUN√á√ÉO ADICIONAL PARA DETALHAR FORMATOS ESPEC√çFICOS
# =============================================================================

def analisar_formatos_especificos(df, limite_exibicao=15):
    """
    Analisa formatos espec√≠ficos em colunas problem√°ticas
    """
    print("\n" + "=" * 60)
    print("AN√ÅLISE DE FORMATOS ESPEC√çFICOS")
    print("=" * 60)

    # An√°lise da coluna 'Tamanho da empresa'
    if 'Tamanho da empresa' in df.columns:
        print(f"\nüì¶ FORMATOS NA COLUNA 'Tamanho da empresa':")
        formatos = df['Tamanho da empresa'].value_counts(dropna=False)
        total_formatos = len(formatos)

        for i, (formato, count) in enumerate(formatos.items()):
            if i >= limite_exibicao:
                print(f"   ... e mais {total_formatos - limite_exibicao} formatos")
                break
            print(f"   '{formato}': {count:,} registros")

    # An√°lise da coluna 'Localiza√ß√£o'
    if 'Localiza√ß√£o' in df.columns:
        print(f"\nüìç PADR√ïES NA COLUNA 'Localiza√ß√£o':")
        # Verificar se segue o padr√£o "cidade, estado, pais"
        padrao_correta = df['Localiza√ß√£o'].str.match(r'^[^,]+,\s*[^,]+,\s*[^,]+$', na=False).sum()
        print(f"   - Registros no formato 'cidade, estado, pais': {padrao_correta:,}")
        print(f"   - Registros fora do padr√£o: {len(df) - padrao_correta - df['Localiza√ß√£o'].isnull().sum():,}")

# Executar an√°lise de formatos
try:
    analisar_formatos_especificos(df)
except NameError:
    print("DataFrame n√£o dispon√≠vel para an√°lise de formatos")

import pandas as pd
import re

# Carregar o dataset
df = pd.read_csv('Base_Dados_Exercicio_01.csv')

# Fun√ß√£o para extrair e padronizar dom√≠nios
def extrair_e_padronizar_dominio(email):
    if pd.isna(email) or '@' not in str(email):
        return None
    dominio = email.split('@')[1].lower()
    # Remover 'www.', 'http://', 'https://' se presentes
    dominio = re.sub(r'^(www\.|http://|https://)', '', dominio)
    return dominio

# Criar nova coluna com dom√≠nios padronizados
df['Dom√≠nio'] = df['E-mail'].apply(extrair_e_padronizar_dominio)

# Mostrar primeiras linhas para verifica√ß√£o
print("Primeiras linhas com a nova coluna 'Dom√≠nio':")
print(df[['E-mail', 'Dom√≠nio', 'Status do e-mail']].head(10))

# Mostrar alguns exemplos de dom√≠nios padronizados
print("\nAlguns exemplos de dom√≠nios ap√≥s padroniza√ß√£o:")
print(df['Dom√≠nio'].value_counts().head(15))

# Salvar o resultado (opcional)
df.to_csv('Base_Dados_Exercicio_01_email.csv', index=False)
print("\nDataset salvo como 'Base_Dados_Exercicio_01_email.csv'")

# An√°lise de distribui√ß√£o
status_counts = df['Status do e-mail'].value_counts()
print("Distribui√ß√£o do Status:")
print(status_counts)

# An√°lise cruzada com Dom√≠nio
print("\nTop dom√≠nios com status 'not valid':")
print(df[df['Status do e-mail'] == 'not valid']['Dom√≠nio'].value_counts().head(10))

print("\nTop dom√≠nios com status 'unknown':")
print(df[df['Status do e-mail'] == 'unknown']['Dom√≠nio'].value_counts().head(10))

import pandas as pd
import re

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_email.csv')

# 1. WHITELIST de dom√≠nios corporativos conhecidos (baseado na an√°lise)
WHITELIST_DOMINIOS = [
    'pwc.com', 'ey.com', 'siemens.com', 'amazon.com', 'accenture.com',
    'capgemini.com', 'ibm.com', 'microsoft.com', 'google.com', 'apple.com',
    'oracle.com', 'sap.com', 'deloitte.com', 'kpmg.com', 'allianz.com',
    'orange-business.com', 'thalesgroup.com', 'loreal.com', 'engie.com',
    'veep.com', 'veepee.com', 'vente-privee.com', 't-systems.com',
    'atos.net', 'govdata.co.uk', 'nordcurrent.com', 'eclear.com',
    'empathy.co', 'thinkproject.com', 'spendesk.com', 'gocardless.com',
    'selency.com', 'mytraffic.fr', 'evosoft.com', 'exasol.com',
    'cegedim.com', 'vaiva.io', 'dalet.com', 'clevercards.com',
    'ceffu.com', 'infobip.com', 'quandoo.com', 'autogeneral.com.au',
    'eqs.com', 'personio.com', 'yoti.com', 'aboutyou.de',
    'sellerx.com', 'leanix.net', 'codility.com', 'pandascore.co'
]

# 2. Lista de dom√≠nios de email pessoais
DOMINIOS_PESSOAIS = ['gmail.com', 'hotmail.com', 'outlook.com', 'yahoo.com',
                     'icloud.com', 'aol.com', 'protonmail.com', 'live.com',
                     'mail.com', 'zoho.com']

# 3. Fun√ß√£o para reclassifica√ß√£o autom√°tica
def reclassificar_status(row):
    dominio = row['Dom√≠nio']
    status_original = row['Status do e-mail']

    # Se for dom√≠nio corporativo na whitelist, automaticamente v√°lido
    if dominio in WHITELIST_DOMINIOS:
        return 'corporate_valid'

    # Se for dom√≠nio pessoal, categorizar como personal
    elif dominio in DOMINIOS_PESSOAIS:
        return 'personal'

    # Manter classifica√ß√£o original para outros casos
    else:
        return status_original

# 4. Fun√ß√£o para calcular pontua√ß√£o de confian√ßa
def calcular_pontuacao_confianca(row):
    pontuacao = 0

    # Dom√≠nio corporativo (+3 pontos)
    if row['Dom√≠nio'] in WHITELIST_DOMINIOS:
        pontuacao += 3

    # Cargo relevante (+2 pontos)
    cargo = str(row['Cargo']).lower() if pd.notna(row['Cargo']) else ''
    cargos_relevantes = ['cto', 'chief', 'director', 'head', 'manager', 'lead',
                        'senior', 'president', 'vp', 'vice president', 'executive']
    if any(title in cargo for title in cargos_relevantes):
        pontuacao += 2

    # LinkedIn v√°lido (+1 ponto)
    linkedin = str(row['LinkedIn']) if pd.notna(row['LinkedIn']) else ''
    if 'linkedin.com' in linkedin and not linkedin.endswith('linkedin.com'):
        pontuacao += 1

    # Empresa com tamanho consider√°vel (+1 ponto)
    tamanho_empresa = str(row['Tamanho da empresa']) if pd.notna(row['Tamanho da empresa']) else ''
    if any(size in tamanho_empresa for size in ['Grande', 'Muito grande', 'Enorme', 'Enterprise']):
        pontuacao += 1

    return pontuacao

# 5. Fun√ß√£o para categorizar n√≠vel de confian√ßa
def categorizar_confianca(pontuacao):
    if pontuacao >= 4:
        return 'high_confidence'
    elif pontuacao >= 2:
        return 'medium_confidence'
    else:
        return 'low_confidence'

# APLICAR AS MELHORIAS
print("Aplicando melhorias na base de dados...")

# A. Reclassificar status de e-mail
df['Status_Email_Reclassificado'] = df.apply(reclassificar_status, axis=1)

# B. Calcular pontua√ß√£o de confian√ßa
df['Pontuacao_Confianca'] = df.apply(calcular_pontuacao_confianca, axis=1)

# C. Categorizar n√≠vel de confian√ßa
df['Nivel_Confianca'] = df['Pontuacao_Confianca'].apply(categorizar_confianca)

# D. Criar status final consolidado
def status_final(row):
    if row['Status_Email_Reclassificado'] == 'corporate_valid':
        return 'valid'
    elif row['Status_Email_Reclassificado'] == 'personal':
        return 'personal'
    elif row['Nivel_Confianca'] == 'high_confidence':
        return 'likely_valid'
    else:
        return row['Status_Email_Reclassificado']

df['Status_Final'] = df.apply(status_final, axis=1)

# ANALISAR RESULTADOS
print("\n=== DISTRIBUI√á√ÉO DOS NOVOS STATUS ===")
print(df['Status_Final'].value_counts())

print("\n=== COMPARA√á√ÉO STATUS ORIGINAL vs FINAL ===")
comparacao = pd.crosstab(df['Status do e-mail'], df['Status_Final'])
print(comparacao)

print("\n=== PONTUA√á√ÉO DE CONFI√ÇNCIA POR CATEGORIA ===")
print(df.groupby('Status_Final')['Pontuacao_Confianca'].mean().round(2))

# SALVAR BASE MELHORADA
df.to_csv('Base_Dados_Exercicio_01_status_email.csv', index=False)
print(f"\nBase melhorada salva como 'Base_Dados_Exercicio_01_status_email.csv'")
print(f"Colunas adicionadas: Status_Email_Reclassificado, Pontuacao_Confianca, Nivel_Confianca, Status_Final")

# MOSTRAR ALGUNS EXEMPLOS DE RECLASSIFICA√á√ÉO
print("\n=== EXEMPLOS DE RECLASSIFICA√á√ÉO ===")
exemplos = df[df['Status do e-mail'].isin(['unknown', 'not valid']) &
              df['Status_Final'].isin(['valid', 'likely_valid'])].head(5)
print(exemplos[['E-mail', 'Dom√≠nio', 'Cargo', 'Status do e-mail', 'Status_Final', 'Pontuacao_Confianca']])

print("An√°lise da coluna Nome:")
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Nome'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Nome'].nunique()}")
print("\nPrimeiros valores:")
print(df['Nome'].head(10))

import pandas as pd
import numpy as np

# Carregar o arquivo atual
df = pd.read_csv('Base_Dados_Exercicio_01_status_email.csv')

# An√°lise inicial da coluna Nome
print("=== AN√ÅLISE INICIAL DA COLUNA NOME ===")
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Nome'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Nome'].nunique()}")
print("\nPrimeiros valores:")
print(df['Nome'].head(10))

# Verificar valores nulos espec√≠ficos
nulos_nome = df[df['Nome'].isnull()]
if not nulos_nome.empty:
    print(f"\nüìç Registros com Nome nulo:")
    print(nulos_nome[['E-mail', 'Nome completo', 'Nome', 'Sobrenome']])

# 1. Preencher valores nulos - tentar extrair do Nome completo
def preencher_nome(row):
    if pd.isna(row['Nome']) and pd.notna(row['Nome completo']):
        # Extrair primeiro nome do nome completo
        nome_completo = str(row['Nome completo'])
        primeiro_nome = nome_completo.split()[0] if nome_completo.split() else 'N√£o Informado'
        return primeiro_nome
    elif pd.isna(row['Nome']):
        return 'N√£o Informado'
    else:
        return row['Nome']

df['Nome'] = df.apply(preencher_nome, axis=1)

# 2. Padronizar capitaliza√ß√£o e remover espa√ßos extras
df['Nome'] = df['Nome'].str.title().str.strip()

# 3. Limpeza de caracteres especiais/problem√°ticos
# Remover n√∫meros e caracteres especiais (mantendo letras, espa√ßos e h√≠fens)
df['Nome'] = df['Nome'].apply(lambda x: re.sub(r'[^a-zA-Z√Ä-√ø\s\-]', '', str(x)) if pd.notna(x) else x)

# 4. Verificar qualidade ap√≥s limpeza
print("\n=== AN√ÅLISE AP√ìS LIMPEZA ===")
print(f"Valores nulos: {df['Nome'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Nome'].nunique()}")

# Verificar nomes muito curtos (poss√≠veis erros)
nomes_curtos = df[df['Nome'].str.len() < 2]
if len(nomes_curtos) > 0:
    print(f"\n‚ö†Ô∏è  Nomes com menos de 2 caracteres: {len(nomes_curtos)}")
    print(nomes_curtos[['Nome', 'Nome completo', 'E-mail']].to_string())

# 5. Verificar consist√™ncia com Nome completo
def verificar_consistencia_nome(row):
    if pd.notna(row['Nome completo']):
        nome_completo = str(row['Nome completo'])
        primeiro_nome_completo = nome_completo.split()[0] if nome_completo.split() else ''
        return row['Nome'] == primeiro_nome_completo
    return True

df['Nome_Consistente'] = df.apply(verificar_consistencia_nome, axis=1)
inconsistentes = df[~df['Nome_Consistente']]

print(f"\nüîç Verifica√ß√£o de consist√™ncia Nome vs Nome completo:")
print(f"Registros inconsistentes: {len(inconsistentes)}")
if len(inconsistentes) > 0:
    print(inconsistentes[['Nome', 'Nome completo', 'E-mail']].head(5).to_string())

# 6. Salvar base atualizada
df.to_csv('Base_Dados_Exercicio_01_nome.csv', index=False)
print(f"\nüíæ Base salva com coluna 'Nome' otimizada!")
print(f"üìç Coluna 'Nome_Consistente' adicionada para controle de qualidade")

# Mostrar amostra final
print("\nüéØ Amostra final da coluna Nome:")
print(df[['Nome', 'Sobrenome', 'Nome completo', 'Nome_Consistente']].head(10).to_string())

import pandas as pd
import re

# Carregar o arquivo atual
df = pd.read_csv('Base_Dados_Exercicio_01_nome.csv')

# An√°lise inicial da coluna Sobrenome
print("=== AN√ÅLISE INICIAL DA COLUNA SOBRENOME ===")
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Sobrenome'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Sobrenome'].nunique()}")
print("\nPrimeiros valores:")
print(df['Sobrenome'].head(15))

# Verificar valores nulos espec√≠ficos
nulos_sobrenome = df[df['Sobrenome'].isnull()]
if not nulos_sobrenome.empty:
    print(f"\nüìç Registros com Sobrenome nulo:")
    print(nulos_sobrenome[['E-mail', 'Nome completo', 'Nome', 'Sobrenome']].to_string())

# 1. Preencher valores nulos - tentar extrair do Nome completo
def preencher_sobrenome(row):
    if pd.isna(row['Sobrenome']) and pd.notna(row['Nome completo']):
        nome_completo = str(row['Nome completo'])
        partes = nome_completo.split()

        if len(partes) >= 2:
            # Pegar √∫ltimo nome (sobrenome)
            sobrenome = ' '.join(partes[1:])
            return sobrenome
        else:
            return 'N√£o Informado'
    elif pd.isna(row['Sobrenome']):
        return 'N√£o Informado'
    else:
        return row['Sobrenome']

df['Sobrenome'] = df.apply(preencher_sobrenome, axis=1)

# 2. Padronizar capitaliza√ß√£o (manter caso de sobrenomes compostos)
def padronizar_sobrenome(sobrenome):
    if pd.isna(sobrenome) or sobrenome == 'N√£o Informado':
        return sobrenome

    sobrenome_str = str(sobrenome)
    # Title case mas preservar conectivos (De, Van, Von, etc.)
    partes = sobrenome_str.split()
    partes_padronizadas = []

    for parte in partes:
        if parte.lower() in ['de', 'da', 'do', 'das', 'dos', 'van', 'von', 'del', 'la', 'le']:
            partes_padronizadas.append(parte.lower())
        else:
            partes_padronizadas.append(parte.title())

    return ' '.join(partes_padronizadas)

df['Sobrenome'] = df['Sobrenome'].apply(padronizar_sobrenome)

# 3. Remover espa√ßos extras
df['Sobrenome'] = df['Sobrenome'].str.strip()

# 4. Limpeza de caracteres especiais (mantendo letras, espa√ßos, h√≠fens e ap√≥strofos)
df['Sobrenome'] = df['Sobrenome'].apply(lambda x: re.sub(r'[^a-zA-Z√Ä-√ø\s\-\']', '', str(x)) if pd.notna(x) and x != 'N√£o Informado' else x)

# 5. Verificar qualidade ap√≥s limpeza
print("\n=== AN√ÅLISE AP√ìS LIMPEZA ===")
print(f"Valores nulos: {df['Sobrenome'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Sobrenome'].nunique()}")

# Verificar sobrenomes muito curtos
sobrenomes_curtos = df[df['Sobrenome'].str.len() < 2]
if len(sobrenomes_curtos) > 0:
    print(f"\n‚ö†Ô∏è  Sobrenomes com menos de 2 caracteres: {len(sobrenomes_curtos)}")
    print(sobrenomes_curtos[['Sobrenome', 'Nome completo', 'E-mail']].head().to_string())

# An√°lise de distribui√ß√£o dos sobrenomes mais comuns
print(f"\nüìä Top 10 sobrenomes mais comuns:")
print(df['Sobrenome'].value_counts().head(10))

# 6. Verificar consist√™ncia com Nome completo
def verificar_consistencia_sobrenome(row):
    if pd.notna(row['Nome completo']) and row['Sobrenome'] != 'N√£o Informado':
        nome_completo = str(row['Nome completo'])
        partes = nome_completo.split()

        if len(partes) >= 2:
            sobrenome_completo = ' '.join(partes[1:])
            return row['Sobrenome'] == sobrenome_completo
    return True

df['Sobrenome_Consistente'] = df.apply(verificar_consistencia_sobrenome, axis=1)
inconsistentes_sobrenome = df[~df['Sobrenome_Consistente']]

print(f"\nüîç Verifica√ß√£o de consist√™ncia Sobrenome vs Nome completo:")
print(f"Registros inconsistentes: {len(inconsistentes_sobrenome)}")
if len(inconsistentes_sobrenome) > 0:
    print(inconsistentes_sobrenome[['Sobrenome', 'Nome completo', 'E-mail']].head(5).to_string())

# 7. Verificar combina√ß√£o Nome + Sobrenome vs Nome completo
def verificar_nome_completo(row):
    if pd.notna(row['Nome']) and pd.notna(row['Sobrenome']) and row['Nome'] != 'N√£o Informado' and row['Sobrenome'] != 'N√£o Informado':
        nome_completo_calculado = f"{row['Nome']} {row['Sobrenome']}"
        return nome_completo_calculado == str(row['Nome completo'])
    return True

df['Nome_Completo_Consistente'] = df.apply(verificar_nome_completo, axis=1)
inconsistentes_completo = df[~df['Nome_Completo_Consistente']]

print(f"\nüîç Verifica√ß√£o de consist√™ncia Nome + Sobrenome vs Nome completo:")
print(f"Registros inconsistentes: {len(inconsistentes_completo)}")
if len(inconsistentes_completo) > 0:
    print(inconsistentes_completo[['Nome', 'Sobrenome', 'Nome completo', 'E-mail']].head(5).to_string())

# 8. Salvar base atualizada
df.to_csv('Base_Dados_Exercicio_01_sobrenome.csv', index=False)
print(f"\nüíæ Base salva com coluna 'Sobrenome' otimizada!")
print(f"üìç Colunas adicionadas: 'Sobrenome_Consistente', 'Nome_Completo_Consistente'")

# Mostrar amostra final
print("\nüéØ Amostra final das colunas de nome:")
print(df[['Nome', 'Sobrenome', 'Nome completo', 'Sobrenome_Consistente', 'Nome_Completo_Consistente']].head(15).to_string())

# Estat√≠sticas finais
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"Registros com Sobrenome 'N√£o Informado': {len(df[df['Sobrenome'] == 'N√£o Informado'])}")
print(f"Registros com inconsist√™ncias no sobrenome: {len(inconsistentes_sobrenome)}")
print(f"Registros com inconsist√™ncias no nome completo: {len(inconsistentes_completo)}")

import pandas as pd
import re

# Carregar o arquivo atual
df = pd.read_csv('Base_Dados_Exercicio_01_sobrenome.csv')

# An√°lise inicial da coluna Nome completo
print("=== AN√ÅLISE INICIAL DA COLUNA NOME COMPLETO ===")
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Nome completo'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Nome completo'].nunique()}")
print("\nPrimeiros valores:")
print(df['Nome completo'].head(15))

# Verificar valores nulos espec√≠ficos
nulos_completo = df[df['Nome completo'].isnull()]
if not nulos_completo.empty:
    print(f"\nüìç Registros com Nome completo nulo:")
    print(nulos_completo[['E-mail', 'Nome', 'Sobrenome', 'Nome completo']].to_string())

# 1. Preencher valores nulos - construir a partir de Nome + Sobrenome
def preencher_nome_completo(row):
    if pd.isna(row['Nome completo']) or str(row['Nome completo']).strip() == '':
        nome = row['Nome'] if pd.notna(row['Nome']) and row['Nome'] != 'N√£o Informado' else ''
        sobrenome = row['Sobrenome'] if pd.notna(row['Sobrenome']) and row['Sobrenome'] != 'N√£o Informado' else ''

        if nome and sobrenome:
            return f"{nome} {sobrenome}"
        elif nome:
            return nome
        elif sobrenome:
            return sobrenome
        else:
            return 'N√£o Informado'
    else:
        return row['Nome completo']

df['Nome completo'] = df.apply(preencher_nome_completo, axis=1)

# 2. Padronizar capitaliza√ß√£o (Title Case para nomes completos)
def padronizar_nome_completo(nome_completo):
    if pd.isna(nome_completo) or nome_completo == 'N√£o Informado':
        return nome_completo

    nome_str = str(nome_completo)
    # Title case mas preservar conectivos e part√≠culas
    partes = nome_str.split()
    partes_padronizadas = []

    for parte in partes:
        if parte.lower() in ['de', 'da', 'do', 'das', 'dos', 'van', 'von', 'del', 'la', 'le', 'y', 'e']:
            partes_padronizadas.append(parte.lower())
        elif parte.upper() == parte:  # Se estiver tudo em mai√∫sculo
            partes_padronizadas.append(parte.title())
        else:
            partes_padronizadas.append(parte)

    return ' '.join(partes_padronizadas)

df['Nome completo'] = df['Nome completo'].apply(padronizar_nome_completo)

# 3. Remover espa√ßos extras e caracteres desnecess√°rios
df['Nome completo'] = df['Nome completo'].str.strip()
df['Nome completo'] = df['Nome completo'].apply(lambda x: re.sub(r'\s+', ' ', str(x)))  # M√∫ltiplos espa√ßos para um

# 4. Limpeza de caracteres especiais (mantendo letras, espa√ßos, h√≠fens, ap√≥strofos e pontos)
df['Nome completo'] = df['Nome completo'].apply(lambda x: re.sub(r'[^a-zA-Z√Ä-√ø\s\-\'\.]', '', str(x)) if pd.notna(x) and x != 'N√£o Informado' else x)

# 5. Verificar qualidade ap√≥s limpeza
print("\n=== AN√ÅLISE AP√ìS LIMPEZA ===")
print(f"Valores nulos: {df['Nome completo'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Nome completo'].nunique()}")

# Verificar nomes completos muito curtos
nomes_curtos = df[df['Nome completo'].str.len() < 3]
if len(nomes_curtos) > 0:
    print(f"\n‚ö†Ô∏è  Nomes completos com menos de 3 caracteres: {len(nomes_curtos)}")
    print(nomes_curtos[['Nome completo', 'Nome', 'Sobrenome', 'E-mail']].head().to_string())

# 6. An√°lise de comprimento dos nomes completos
df['Tamanho_Nome_Completo'] = df['Nome completo'].str.len()
print(f"\nüìä Estat√≠sticas de comprimento do Nome completo:")
print(f"M√≠nimo: {df['Tamanho_Nome_Completo'].min()} caracteres")
print(f"M√°ximo: {df['Tamanho_Nome_Completo'].max()} caracteres")
print(f"M√©dia: {df['Tamanho_Nome_Completo'].mean():.1f} caracteres")

# 7. Identificar poss√≠veis t√≠tulos ou sufixos (PhD, MSc, etc.)
def identificar_titulos(nome_completo):
    if pd.isna(nome_completo) or nome_completo == 'N√£o Informado':
        return ''

    titulos = []
    nome_str = str(nome_completo)

    # Verificar titulos comuns
    titulos_comuns = ['PhD', 'MSc', 'MBA', 'PMP', 'PSM', 'ITIL', 'Cobit', 'Eng', 'Dr', 'Dra', 'Mr', 'Mrs', 'Ms']

    for titulo in titulos_comuns:
        if titulo in nome_str:
            titulos.append(titulo)

    return ', '.join(titulos) if titulos else 'Nenhum'

df['Titulos_Identificados'] = df['Nome completo'].apply(identificar_titulos)

print(f"\nüéì Titulos identificados nos nomes completos:")
print(df['Titulos_Identificados'].value_counts())

# 8. Verificar padr√µes estranhos (muitas palavras, caracteres repetidos, etc.)
def verificar_padroes_estranhos(nome_completo):
    if pd.isna(nome_completo) or nome_completo == 'N√£o Informado':
        return False

    nome_str = str(nome_completo)
    # Muitas palavras (mais de 6)
    if len(nome_str.split()) > 6:
        return True
    # Caracteres repetidos
    if re.search(r'(.)\1{3,}', nome_str):  # 4 ou mais do mesmo caractere consecutivo
        return True
    # Muitos n√∫meros (se houver)
    if len(re.findall(r'\d', nome_str)) > 2:
        return True

    return False

df['Padrao_Estranho'] = df['Nome completo'].apply(verificar_padroes_estranhos)
estranhos = df[df['Padrao_Estranho']]

print(f"\n‚ö†Ô∏è  Nomes completos com padr√µes estranhos: {len(estranhos)}")
if len(estranhos) > 0:
    print(estranhos[['Nome completo', 'E-mail', 'Titulos_Identificados']].head().to_string())

# 9. An√°lise de distribui√ß√£o dos nomes completos mais comuns
print(f"\nüìä Top 10 nomes completos mais comuns:")
top_nomes = df['Nome completo'].value_counts().head(10)
print(top_nomes)

# 10. Salvar base atualizada
df.to_csv('Base_Dados_Exercicio_01_nome_completo.csv', index=False)
print(f"\nüíæ Base salva com coluna 'Nome completo' otimizada!")
print(f"üìç Colunas adicionadas: 'Tamanho_Nome_Completo', 'Titulos_Identificados', 'Padrao_Estranho'")

# Mostrar amostra final
print("\nüéØ Amostra final da coluna Nome completo:")
print(df[['Nome completo', 'Tamanho_Nome_Completo', 'Titulos_Identificados', 'Padrao_Estranho']].head(15).to_string())

# Estat√≠sticas finais
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"Registros com Nome completo 'N√£o Informado': {len(df[df['Nome completo'] == 'N√£o Informado'])}")
print(f"Registros com t√≠tulos identificados: {len(df[df['Titulos_Identificados'] != 'Nenhum'])}")
print(f"Registros com padr√µes estranhos: {len(estranhos)}")

import pandas as pd
import numpy as np
import re

# Carregar o arquivo
df = pd.read_csv('Base_Dados_Exercicio_01_nome_completo.csv')

# An√°lise inicial da coluna "Usu√°rio - redes sociais"
print("=== AN√ÅLISE INICIAL DA COLUNA 'Usu√°rio - redes sociais' ===")
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Usu√°rio - redes sociais'].isnull().sum()}")
print(f"Valores vazios/em branco: {(df['Usu√°rio - redes sociais'] == '').sum()}")
print(f"Valores √∫nicos: {df['Usu√°rio - redes sociais'].nunique()}")

# Verificar os primeiros valores
print("\nüìã Primeiros 15 valores:")
print(df['Usu√°rio - redes sociais'].head(15))

# Verificar os √∫ltimos 15 valores
print("\nüìã √öltimos 15 valores:")
print(df['Usu√°rio - redes sociais'].tail(15))

# An√°lise mais detalhada
print("\n=== AN√ÅLISE DETALHADA ===")

# 1. Verificar tipos de valores presentes
valores_unicos = df['Usu√°rio - redes sociais'].dropna().unique()
print(f"\nüîç Tipos de valores encontrados (amostra de 20):")
for i, valor in enumerate(valores_unicos[:20]):
    print(f"  {i+1}. {repr(valor)}")

# 2. An√°lise de comprimento dos valores
df['Comprimento_RedeSocial'] = df['Usu√°rio - redes sociais'].str.len().fillna(0)
print(f"\nüìè Estat√≠sticas de comprimento:")
print(f"M√≠nimo: {df['Comprimento_RedeSocial'].min()} caracteres")
print(f"M√°ximo: {df['Comprimento_RedeSocial'].max()} caracteres")
print(f"M√©dia: {df['Comprimento_RedeSocial'].mean():.1f} caracteres")
print(f"Mediana: {df['Comprimento_RedeSocial'].median()} caracteres")

# 3. Identificar padr√µes de URLs
def identificar_tipo_url(url):
    if pd.isna(url) or url == '':
        return 'Vazio/Nulo'

    url_str = str(url).lower()

    if 'linkedin.com' in url_str:
        return 'LinkedIn'
    elif 'twitter.com' in url_str or 'x.com' in url_str:
        return 'Twitter/X'
    elif 'facebook.com' in url_str:
        return 'Facebook'
    elif 'instagram.com' in url_str:
        return 'Instagram'
    elif 'github.com' in url_str:
        return 'GitHub'
    elif 'youtube.com' in url_str:
        return 'YouTube'
    elif 'http://' in url_str or 'https://' in url_str:
        return 'Outra URL'
    elif '/' in url_str or '.' in url_str:
        return 'Poss√≠vel URL incompleta'
    else:
        return 'Texto/Nome de usu√°rio'

df['Tipo_RedeSocial'] = df['Usu√°rio - redes sociais'].apply(identificar_tipo_url)

print(f"\nüåê Distribui√ß√£o por tipo de rede social:")
print(df['Tipo_RedeSocial'].value_counts())

# 4. Verificar URLs v√°lidas vs inv√°lidas
def verificar_url_valida(url):
    if pd.isna(url) or url == '':
        return False

    url_str = str(url)
    # Verificar se parece uma URL (cont√©m http, https ou www)
    if re.match(r'^(http|https|www\.)', url_str, re.IGNORECASE):
        # Verificar se tem dom√≠nio v√°lido
        if re.search(r'\.(com|org|net|io|co|edu|gov|br|de|fr|uk|es|it)$', url_str, re.IGNORECASE):
            return True
        return False
    return False

df['URL_Valida'] = df['Usu√°rio - redes sociais'].apply(verificar_url_valida)

print(f"\n‚úÖ URLs v√°lidas: {df['URL_Valida'].sum()}")
print(f"‚ùå URLs inv√°lidas: {len(df) - df['URL_Valida'].sum() - df['Usu√°rio - redes sociais'].isnull().sum() - (df['Usu√°rio - redes sociais'] == '').sum()}")

# 5. Identificar valores problem√°ticos
def identificar_problemas(url):
    if pd.isna(url) or url == '':
        return 'Sem dados'

    url_str = str(url)
    problemas = []

    if len(url_str) < 5:
        problemas.append('Muito curto')
    if len(url_str) > 200:
        problemas.append('Muito longo')
    if ' ' in url_str and 'http' not in url_str:
        problemas.append('Espa√ßos em branco')
    if re.search(r'[<>{}|\\^~\[\]]', url_str):
        problemas.append('Caracteres inv√°lidos')
    if url_str.strip() != url_str:
        problemas.append('Espa√ßos extras')

    return ', '.join(problemas) if problemas else 'OK'

df['Problemas_Identificados'] = df['Usu√°rio - redes sociais'].apply(identificar_problemas)

print(f"\n‚ö†Ô∏è  Problemas identificados:")
print(df['Problemas_Identificados'].value_counts())

# 6. Cruzamento com outras colunas
print(f"\nüîó Rela√ß√£o com coluna LinkedIn:")
linkedin_cruzamento = pd.crosstab(df['Tipo_RedeSocial'], df['LinkedIn'].notnull())
print(linkedin_cruzamento)

# 7. Mostrar exemplos problem√°ticos
print(f"\nüéØ Exemplos de valores problem√°ticos:")
problemas_graves = df[df['Problemas_Identificados'] != 'OK']
if not problemas_graves.empty:
    print(problemas_graves[['Usu√°rio - redes sociais', 'Problemas_Identificados', 'E-mail']].head(10).to_string())
else:
    print("Nenhum problema grave identificado")

# 8. Estat√≠sticas finais
print(f"\nüìä ESTAT√çSTICAS FINAIS:")
print(f"Total de registros: {len(df)}")
print(f"Valores preenchidos: {len(df) - df['Usu√°rio - redes sociais'].isnull().sum() - (df['Usu√°rio - redes sociais'] == '').sum()}")
print(f"Taxa de preenchimento: {(len(df) - df['Usu√°rio - redes sociais'].isnull().sum() - (df['Usu√°rio - redes sociais'] == '').sum()) / len(df) * 100:.1f}%")
print(f"Principais redes sociais: {df['Tipo_RedeSocial'].value_counts().head(3).to_dict()}")

import pandas as pd
import numpy as np
import re
from urllib.parse import urlparse, urlunparse

# Carregar o arquivo
df = pd.read_csv('Base_Dados_Exercicio_01_nome_completo.csv')

print("=== TRATAMENTO DA COLUNA 'Usu√°rio - redes sociais' ===")

# 1. IDENTIFICAR E SEPARAR MULTIPLAS URLs
def separar_multiplas_urls(url):
    if pd.isna(url) or url == '':
        return []

    urls = []
    # Separar por v√≠rgulas, espa√ßos ou ponto e v√≠rgula
    partes = re.split(r'[,;\s]+', str(url))

    for parte in partes:
        parte = parte.strip()
        if parte and 'http' in parte:
            urls.append(parte)
        elif parte and len(parte) > 5:  # Poss√≠vel URL sem http
            urls.append('https://' + parte)

    return urls

df['URLs_Separadas'] = df['Usu√°rio - redes sociais'].apply(separar_multiplas_urls)

# 2. PADRONIZAR URLs (https://, formato consistente)
def padronizar_url(url):
    if not url:
        return None

    try:
        # Garantir que tem protocolo
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url

        # Parse da URL
        parsed = urlparse(url)

        # Padronizar: sempre https, remover www, caminho min√∫sculo
        netloc = parsed.netloc.replace('www.', '')
        path = parsed.path.lower()

        # Reconstruir URL padronizada
        url_padronizada = urlunparse(('https', netloc, path, '', '', ''))

        return url_padronizada

    except:
        return None

def processar_urls(urls):
    urls_padronizadas = []
    for url in urls:
        url_pad = padronizar_url(url)
        if url_pad:
            urls_padronizadas.append(url_pad)
    return urls_padronizadas

df['URLs_Padronizadas'] = df['URLs_Separadas'].apply(processar_urls)

# 3. EXTRAIR USERNAME DO LINKEDIN
def extrair_username_linkedin(url):
    if 'linkedin.com/in/' in url:
        match = re.search(r'linkedin\.com/in/([^/?]+)', url)
        if match:
            return match.group(1)
    return None

def extrair_usernames(urls):
    usernames = []
    for url in urls:
        if 'linkedin.com' in url:
            username = extrair_username_linkedin(url)
            if username:
                usernames.append(username)
    return usernames

df['LinkedIn_Usernames'] = df['URLs_Padronizadas'].apply(extrair_usernames)

# 4. CLASSIFICAR POR TIPO DE REDE SOCIAL
def classificar_redes_sociais(urls):
    redes = {}
    for url in urls:
        if 'linkedin.com' in url:
            redes['linkedin'] = redes.get('linkedin', []) + [url]
        elif 'twitter.com' in url or 'x.com' in url:
            redes['twitter'] = redes.get('twitter', []) + [url]
        elif 'facebook.com' in url:
            redes['facebook'] = redes.get('facebook', []) + [url]
        elif 'github.com' in url:
            redes['github'] = redes.get('github', []) + [url]
        else:
            redes['outras'] = redes.get('outras', []) + [url]
    return redes

df['Redes_Sociais_Classificadas'] = df['URLs_Padronizadas'].apply(classificar_redes_sociais)

# 5. CRIAR COLUNAS SEPARADAS PARA CADA TIPO
def extrair_principal_linkedin(redes):
    return redes.get('linkedin', [])[0] if redes.get('linkedin') else None

def extrair_outras_redes(redes):
    outras = []
    for tipo, urls in redes.items():
        if tipo != 'linkedin':
            outras.extend(urls)
    return outras

df['LinkedIn_Principal'] = df['Redes_Sociais_Classificadas'].apply(extrair_principal_linkedin)
df['Outras_Redes_Sociais'] = df['Redes_Sociais_Classificadas'].apply(extrair_outras_redes)

# 6. VALIDAR URLs
def validar_url(url):
    if not url:
        return False
    return bool(re.match(r'^https://[a-z0-9.-]+/.*', url))

df['URLs_Validas'] = df['URLs_Padronizadas'].apply(lambda urls: [url for url in urls if validar_url(url)])

# 7. CRIAR COLUNA FINAL PADRONIZADA
def criar_url_final(redes):
    linkedin = redes.get('linkedin', [])
    if linkedin:
        return linkedin[0]  # Primeiro LinkedIn como principal
    outras = [url for tipo, urls in redes.items() for url in urls if tipo != 'linkedin']
    return outras[0] if outras else None

df['Rede_Social_Principal'] = df['Redes_Sociais_Classificadas'].apply(criar_url_final)

# 8. REMOVER COLUNAS TEMPOR√ÅRIAS
colunas_manter = [
    'Usu√°rio - redes sociais',  # Original
    'Rede_Social_Principal',    # URL principal padronizada
    'LinkedIn_Principal',       # LinkedIn espec√≠fico
    'Outras_Redes_Sociais',     # Lista de outras redes
    'LinkedIn_Usernames',       # Usernames extra√≠dos
    'URLs_Validas'              # Todas URLs v√°lidas
]

df_final = df[colunas_manter]

# 9. AN√ÅLISE DOS RESULTADOS
print("\n‚úÖ TRATAMENTO CONCLU√çDO!")
print(f"Registros com LinkedIn principal: {df_final['LinkedIn_Principal'].notnull().sum()}")
print(f"Registros com outras redes sociais: {df_final['Outras_Redes_Sociais'].apply(len).sum()}")
print(f"Usernames LinkedIn extra√≠dos: {df_final['LinkedIn_Usernames'].apply(len).sum()}")

print("\nüìä Exemplos ap√≥s tratamento:")
print(df_final[['Usu√°rio - redes sociais', 'Rede_Social_Principal', 'LinkedIn_Usernames']].head(10).to_string())

# 10. SALVAR BASE TRATADA
df.to_csv('Base_Dados_Exercicio_01_redes_sociais.csv', index=False)
print(f"\nüíæ Base tratada salva como 'Base_Dados_Exercicio_01_redes_sociais.csv'")

# ESTAT√çSTICAS FINAIS
print(f"\nüéØ ESTAT√çSTICAS FINAIS:")
print(f"Total de registros: {len(df_final)}")
print(f"Com LinkedIn padronizado: {df_final['LinkedIn_Principal'].notnull().sum()}")
print(f"Com outras redes sociais: {len(df_final[df_final['Outras_Redes_Sociais'].apply(len) > 0])}")
print(f"Usernames extra√≠dos √∫nicos: {df_final['LinkedIn_Usernames'].explode().nunique()}")

import pandas as pd
import numpy as np
import re

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_redes_sociais.csv')

print("=== AN√ÅLISE DA COLUNA 'LinkedIn' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['LinkedIn'].isnull().sum()}")
print(f"Valores vazios/em branco: {(df['LinkedIn'] == '').sum()}")
print(f"Valores √∫nicos: {df['LinkedIn'].nunique()}")

# Verificar primeiros valores
print("\nüìã Primeiros 15 valores:")
print(df['LinkedIn'].head(15))

# Verificar √∫ltimos 15 valores
print("\nüìã √öltimos 15 valores:")
print(df['LinkedIn'].tail(15))

# An√°lise detalhada
print("\n=== AN√ÅLISE DETALHADA ===")

# 1. Verificar formato das URLs
def analisar_formato_linkedin(url):
    if pd.isna(url) or url == '':
        return 'Vazio/Nulo'

    url_str = str(url).lower()

    if 'linkedin.com' not in url_str:
        return 'N√£o √© LinkedIn'
    elif '/in/' in url_str:
        return 'Perfil (/in/)'
    elif '/company/' in url_str:
        return 'Empresa (/company/)'
    elif '/school/' in url_str:
        return 'Universidade (/school/)'
    else:
        return 'Outro formato LinkedIn'

df['Formato_LinkedIn'] = df['LinkedIn'].apply(analisar_formato_linkedin)

print("üìä Distribui√ß√£o por formato:")
print(df['Formato_LinkedIn'].value_counts())

# 2. Comparar com coluna de redes sociais anterior
print(f"\nüîó Compara√ß√£o com 'Usu√°rio - redes sociais':")
print(f"Ambas preenchidas: {((df['LinkedIn'].notnull()) & (df['Usu√°rio - redes sociais'].notnull())).sum()}")
print(f"Apenas LinkedIn: {(df['LinkedIn'].notnull() & df['Usu√°rio - redes sociais'].isnull()).sum()}")
print(f"Apenas Rede Social: {(df['LinkedIn'].isnull() & df['Usu√°rio - redes sociais'].notnull()).sum()}")

# 3. Verificar consist√™ncia entre as duas colunas
def verificar_consistencia(row):
    if pd.isna(row['LinkedIn']) or pd.isna(row['Rede_Social_Principal']):
        return 'Dados incompletos'

    linkedin = str(row['LinkedIn']).lower()
    rede_principal = str(row['Rede_Social_Principal']).lower()

    # Extrair username de ambas para comparar
    user_linkedin = re.search(r'linkedin\.com/in/([^/?]+)', linkedin)
    user_rede = re.search(r'linkedin\.com/in/([^/?]+)', rede_principal)

    if user_linkedin and user_rede:
        return 'Consistente' if user_linkedin.group(1) == user_rede.group(1) else 'Inconsistente'
    else:
        return 'Formato diferente'

df['Consistencia_LinkedIn'] = df.apply(verificar_consistencia, axis=1)

print(f"\n‚úÖ Consist√™ncia entre colunas LinkedIn:")
print(df['Consistencia_LinkedIn'].value_counts())

# 4. Padronizar URLs do LinkedIn
def padronizar_linkedin_url(url):
    if pd.isna(url) or url == '':
        return None

    try:
        # Garantir formato completo
        url_str = str(url).strip()

        if not url_str.startswith('http'):
            url_str = 'https://' + url_str

        # Remover par√¢metros desnecess√°rios
        if '?' in url_str:
            url_str = url_str.split('?')[0]

        # Garantir formato can√¥nico
        url_str = url_str.replace('www.', '').replace('http://', 'https://')

        return url_str

    except:
        return None

df['LinkedIn_Padronizado'] = df['LinkedIn'].apply(padronizar_linkedin_url)

# 5. Extrair informa√ß√µes dos perfis
def extrair_info_linkedin(url):
    if pd.isna(url):
        return None

    url_str = str(url)
    info = {}

    # Extrair username
    match_user = re.search(r'linkedin\.com/in/([^/?]+)', url_str)
    if match_user:
        info['username'] = match_user.group(1)

    # Verificar se √© perfil premium
    info['premium'] = 'premium' in url_str.lower()

    # Verificar se tem par√¢metros espec√≠ficos
    info['tem_parametros'] = '?' in url_str

    return info

df['Info_LinkedIn'] = df['LinkedIn_Padronizado'].apply(extrair_info_linkedin)

# 6. Criar colunas separadas para as informa√ß√µes
df['LinkedIn_Username'] = df['Info_LinkedIn'].apply(lambda x: x['username'] if x and 'username' in x else None)
df['LinkedIn_Premium'] = df['Info_LinkedIn'].apply(lambda x: x['premium'] if x else False)
df['LinkedIn_Parametros'] = df['Info_LinkedIn'].apply(lambda x: x['tem_parametros'] if x else False)

# 7. An√°lise de qualidade
print(f"\nüéØ Qualidade dos dados LinkedIn:")
print(f"URLs padronizadas: {df['LinkedIn_Padronizado'].notnull().sum()}")
print(f"Usernames extra√≠dos: {df['LinkedIn_Username'].notnull().sum()}")
print(f"Perfis premium: {df['LinkedIn_Premium'].sum()}")
print(f"URLs com par√¢metros: {df['LinkedIn_Parametros'].sum()}")

# 8. Identificar problemas
def identificar_problemas_linkedin(url):
    if pd.isna(url):
        return 'Vazio'

    url_str = str(url)
    problemas = []

    if not url_str.startswith('http'):
        problemas.append('Sem protocolo')
    if ' ' in url_str:
        problemas.append('Com espa√ßos')
    if len(url_str) > 100:
        problemas.append('Muito longo')
    if 'linkedin.com' not in url_str:
        problemas.append('N√£o √© LinkedIn')

    return ', '.join(problemas) if problemas else 'OK'

df['Problemas_LinkedIn'] = df['LinkedIn'].apply(identificar_problemas_linkedin)

print(f"\n‚ö†Ô∏è  Problemas identificados:")
print(df['Problemas_LinkedIn'].value_counts().head(10))

# 9. Integra√ß√£o final - criar URL definitiva
def url_linkedin_definitiva(row):
    # Priorizar LinkedIn padronizado, depois rede social principal
    if pd.notna(row['LinkedIn_Padronizado']):
        return row['LinkedIn_Padronizado']
    elif pd.notna(row['Rede_Social_Principal']) and 'linkedin.com' in str(row['Rede_Social_Principal']):
        return row['Rede_Social_Principal']
    else:
        return None

df['LinkedIn_Definitivo'] = df.apply(url_linkedin_definitiva, axis=1)

# 10. Salvar base atualizada
df.to_csv('Base_Dados_Exercicio_01_linkedin.csv', index=False)

print(f"\nüíæ Base com LinkedIn tratado salva!")
print(f"üìä Estat√≠sticas finais:")
print(f"LinkedIn definitivo dispon√≠vel: {df['LinkedIn_Definitivo'].notnull().sum()}")
print(f"Taxa de cobertura: {df['LinkedIn_Definitivo'].notnull().sum() / len(df) * 100:.1f}%")

# Mostrar amostra final
print("\nüéØ Amostra final:")
amostra = df[['LinkedIn', 'LinkedIn_Padronizado', 'LinkedIn_Definitivo', 'LinkedIn_Username', 'Consistencia_LinkedIn']].head(10)
print(amostra.to_string())

import pandas as pd
import numpy as np
import re
from collections import Counter

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_linkedin.csv')

print("=== AN√ÅLISE DA COLUNA 'Cargo' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Cargo'].isnull().sum()}")
print(f"Valores vazios/em branco: {(df['Cargo'] == '').sum()}")
print(f"Valores √∫nicos: {df['Cargo'].nunique()}")

# Verificar primeiros valores
print("\nüìã Primeiros 20 valores:")
print(df['Cargo'].head(20))

# Verificar √∫ltimos 20 valores
print("\nüìã √öltimos 20 valores:")
print(df['Cargo'].tail(20))

# An√°lise detalhada
print("\n=== AN√ÅLISE DETALHADA ===")

# 1. An√°lise de comprimento
df['Comprimento_Cargo'] = df['Cargo'].str.len().fillna(0)
print(f"üìè Estat√≠sticas de comprimento:")
print(f"M√≠nimo: {df['Comprimento_Cargo'].min()} caracteres")
print(f"M√°ximo: {df['Comprimento_Cargo'].max()} caracteres")
print(f"M√©dia: {df['Comprimento_Cargo'].mean():.1f} caracteres")

# 2. Identificar padr√µes de capitaliza√ß√£o
def analisar_capitalizacao(cargo):
    if pd.isna(cargo) or cargo == '':
        return 'Vazio'

    cargo_str = str(cargo)

    if cargo_str.isupper():
        return 'TUDO_MAI√öSCULO'
    elif cargo_str.islower():
        return 'tudo_min√∫sculo'
    elif cargo_str.istitle():
        return 'Title_Case'
    else:
        return 'Misto'

df['Padrao_Capitalizacao'] = df['Cargo'].apply(analisar_capitalizacao)
print(f"\nüî† Padr√µes de capitaliza√ß√£o:")
print(df['Padrao_Capitalizacao'].value_counts())

# 3. Identificar cargos por n√≠vel hier√°rquico
def classificar_nivel_hierarquico(cargo):
    if pd.isna(cargo) or cargo == '':
        return 'N√£o Informado'

    cargo_str = str(cargo).lower()

    # Diretoria/C-Level
    if any(palavra in cargo_str for palavra in ['chief', 'ceo', 'cto', 'cfo', 'cio', 'cmo', 'director', 'diretor', 'head of']):
        return 'C-Level/Diretoria'

    # Ger√™ncia
    elif any(palavra in cargo_str for palavra in ['manager', 'gerente', 'lead', 'lider', 'supervisor']):
        return 'Ger√™ncia'

    # Coordena√ß√£o
    elif any(palavra in cargo_str for palavra in ['coordinator', 'coordenador', 'specialist', 'especialista']):
        return 'Coordena√ß√£o/Especialista'

    # Analista/J√∫nior
    elif any(palavra in cargo_str for palavra in ['analyst', 'analista', 'junior', 'jr', 'assistant', 'assistente']):
        return 'Analista/J√∫nior'

    # Consultoria
    elif any(palavra in cargo_str for palavra in ['consultant', 'consultor', 'advisor', 'adviser']):
        return 'Consultoria'

    else:
        return 'Outros'

df['Nivel_Hierarquico'] = df['Cargo'].apply(classificar_nivel_hierarquico)
print(f"\nüè¢ N√≠veis hier√°rquicos identificados:")
print(df['Nivel_Hierarquico'].value_counts())

# 4. Identificar √°reas/departamentos
def identificar_area(cargo):
    if pd.isna(cargo) or cargo == '':
        return 'N√£o Informado'

    cargo_str = str(cargo).lower()

    areas = {
        'TI': ['software', 'developer', 'engineer', 'devops', 'sre', 'it', 'technology', 'tech', 'system', 'data'],
        'Dados': ['data', 'analytics', 'bi', 'business intelligence', 'ai', 'machine learning', 'ml'],
        'Comercial': ['sales', 'vendas', 'account', 'business development', 'commercial'],
        'Marketing': ['marketing', 'growth', 'digital', 'social media'],
        'RH': ['hr', 'human resources', 'recruitment', 'talent'],
        'Financeiro': ['finance', 'financial', 'accounting', 'contabilidade'],
        'Opera√ß√µes': ['operations', 'operational', 'logistics', 'supply chain'],
        'Produto': ['product', 'produto', 'ux', 'ui', 'design']
    }

    for area, palavras_chave in areas.items():
        if any(palavra in cargo_str for palavra in palavras_chave):
            return area

    return 'Outras'

df['Area'] = df['Cargo'].apply(identificar_area)
print(f"\nüìä √Åreas identificadas:")
print(df['Area'].value_counts())

# 5. Identificar problemas e inconsist√™ncias
def identificar_problemas_cargo(cargo):
    if pd.isna(cargo) or cargo == '':
        return ['Vazio']

    problemas = []
    cargo_str = str(cargo)

    # Problemas comuns
    if len(cargo_str) < 3:
        problemas.append('Muito curto')
    if len(cargo_str) > 100:
        problemas.append('Muito longo')
    if re.search(r'\d{4,}', cargo_str):  # Muitos n√∫meros
        problemas.append('Muitos n√∫meros')
    if re.search(r'[^\w\s\/&+-]', cargo_str):  # Caracteres especiais
        problemas.append('Caracteres especiais')
    if '  ' in cargo_str:  # M√∫ltiplos espa√ßos
        problemas.append('M√∫ltiplos espa√ßos')

    return problemas if problemas else ['OK']

df['Problemas_Cargo'] = df['Cargo'].apply(identificar_problemas_cargo)

# Contar problemas
todos_problemas = [problema for sublist in df['Problemas_Cargo'] for problema in sublist]
print(f"\n‚ö†Ô∏è  Problemas identificados:")
print(pd.Series(todos_problemas).value_counts())

# 6. An√°lise de cargos mais comuns
print(f"\nüèÜ Top 20 cargos mais comuns:")
top_cargos = df['Cargo'].value_counts().head(20)
print(top_cargos)

# 7. Identificar cargos em m√∫ltiplos idiomas
def detectar_idioma(cargo):
    if pd.isna(cargo) or cargo == '':
        return 'Vazio'

    cargo_str = str(cargo).lower()

    # Palavras em portugu√™s
    pt_words = ['gerente', 'analista', 'coordenador', 'especialista', 'diretor', 'consultor', 'assistente']

    # Palavras em ingl√™s
    en_words = ['manager', 'analyst', 'coordinator', 'specialist', 'director', 'consultant', 'assistant']

    # Palavras em espanhol
    es_words = ['gerente', 'analista', 'coordinador', 'especialista', 'director', 'consultor', 'asistente']

    # Palavras em alem√£o
    de_words = ['manager', 'leiter', 'entwickler', 'berater', 'spezialist']

    has_pt = any(word in cargo_str for word in pt_words)
    has_en = any(word in cargo_str for word in en_words)
    has_es = any(word in cargo_str for word in es_words)
    has_de = any(word in cargo_str for word in de_words)

    idiomas = []
    if has_pt: idiomas.append('PT')
    if has_en: idiomas.append('EN')
    if has_es: idiomas.append('ES')
    if has_de: idiomas.append('DE')

    return '/'.join(idiomas) if idiomas else 'Outro'

df['Idioma_Cargo'] = df['Cargo'].apply(detectar_idioma)
print(f"\nüåç Idiomas detectados:")
print(df['Idioma_Cargo'].value_counts())

# 8. Mostrar exemplos problem√°ticos
print(f"\nüéØ Exemplos de cargos problem√°ticos:")
problemas_graves = df[df['Problemas_Cargo'].apply(lambda x: 'Muito curto' in x or 'Muitos n√∫meros' in x)]
if not problemas_graves.empty:
    print(problemas_graves[['Cargo', 'Problemas_Cargo']].head(10).to_string())
else:
    print("Nenhum problema grave encontrado")

# 9. An√°lise de qualidade geral
print(f"\nüìà QUALIDADE GERAL DA COLUNA CARGO:")
print(f"Taxa de preenchimento: {(len(df) - df['Cargo'].isnull().sum()) / len(df) * 100:.1f}%")
print(f"Cargos √∫nicos: {df['Cargo'].nunique()} ({(df['Cargo'].nunique() / len(df) * 100):.1f}% de unicidade)")
print(f"Cargos com problemas: {len(df[df['Problemas_Cargo'].apply(lambda x: 'OK' not in x)])}")


#--------------------------------------
# Padroniza√ß√£o
#--------------------------------------

# Dicion√°rio de padroniza√ß√£o
PADROES_CARGOS = {
    # Head of IT variations
    r'(?i)head\s+of\s+it': 'Head of IT',
    r'(?i)head\s+it': 'Head of IT',
    r'(?i)it\s+head': 'Head of IT',

    # Data Manager variations
    r'(?i)data\s*manager': 'Data Manager',
    r'(?i)datamanager': 'Data Manager',
    r'(?i)manager\s+data': 'Data Manager',

    # Compliance Manager variations
    r'(?i)compliance[\s-]*manager': 'Compliance Manager',
    r'(?i)manager\s+compliance': 'Compliance Manager',

    # CTO variations
    r'(?i)chief\s+technology\s+officer\s*\(?cto\)?': 'Chief Technology Officer (CTO)',
    r'(?i)cto\s*[:\-]?\s*chief\s+technology\s+officer': 'Chief Technology Officer (CTO)',
    r'(?i)cto$': 'Chief Technology Officer (CTO)',

    # IT Manager variations
    r'(?i)it\s+manager': 'IT Manager',
    r'(?i)manager\s+it': 'IT Manager',
}

def padronizar_cargo(cargo):
    if pd.isna(cargo):
        return cargo

    cargo_str = str(cargo).strip()

    # Aplicar padr√µes de substitui√ß√£o
    for padrao, substituicao in PADROES_CARGOS.items():
        if re.search(padrao, cargo_str):
            return substituicao

    # Capitaliza√ß√£o consistente (Title Case)
    cargo_str = cargo_str.title()

    # Remover caracteres especiais problem√°ticos
    cargo_str = re.sub(r'[^\w\s\/&()-]', '', cargo_str)

    # Corrigir m√∫ltiplos espa√ßos
    cargo_str = re.sub(r'\s+', ' ', cargo_str)

    # Corre√ß√µes espec√≠ficas p√≥s-title case
    correcoes = {
        'Of': 'of',
        'And': 'and',
        'Or': 'or',
        'It': 'IT',
        'Ctio': 'CTIO',
        'Cio': 'CIO',
        'Cto': 'CTO',
        'Cfo': 'CFO',
        'Ceo': 'CEO'
    }

    for errado, correto in correcoes.items():
        cargo_str = cargo_str.replace(errado, correto)

    return cargo_str

# Aplicar a padroniza√ß√£o
df['Cargo_Padronizado'] = df['Cargo'].apply(padronizar_cargo)

# Salvar an√°lise
df.to_csv('Base_Dados_Exercicio_01_cargo.csv', index=False)
print(f"\nüíæ An√°lise salva em 'Base_Dados_Exercicio_01_cargo.csv'")

import pandas as pd
import numpy as np

!pip install pycountry

import pycountry

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_cargo.csv')

print("=== AN√ÅLISE DA COLUNA 'Pa√≠s' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Pa√≠s'].isnull().sum()}")
print(f"Valores vazios/em branco: {(df['Pa√≠s'] == '').sum()}")
print(f"Valores √∫nicos: {df['Pa√≠s'].nunique()}")

# Verificar primeiros valores
print("\nüìã Primeiros 20 valores:")
print(df['Pa√≠s'].head(20))

# Verificar √∫ltimos 20 valores
print("\nüìã √öltimos 20 valores:")
print(df['Pa√≠s'].tail(20))

# An√°lise detalhada
print("\n=== AN√ÅLISE DETALHADA ===")

# 1. Distribui√ß√£o por pa√≠s
print("üìä Distribui√ß√£o por pa√≠s:")
distribuicao_paises = df['Pa√≠s'].value_counts()
print(distribuicao_paises.head(15))  # Top 15 pa√≠ses

# 2. Identificar valores problem√°ticos
def identificar_problemas_pais(pais):
    if pd.isna(pais) or pais == '':
        return ['Vazio/Nulo']

    problemas = []
    pais_str = str(pais)

    if len(pais_str) < 2:
        problemas.append('Muito curto')
    if len(pais_str) > 50:
        problemas.append('Muito longo')
    if any(char.isdigit() for char in pais_str):
        problemas.append('Cont√©m n√∫meros')
    if re.search(r'[^\w\s\-]', pais_str):  # Caracteres especiais n√£o permitidos
        problemas.append('Caracteres especiais')
    if pais_str.strip() != pais_str:
        problemas.append('Espa√ßos extras')

    return problemas if problemas else ['OK']

df['Problemas_Pais'] = df['Pa√≠s'].apply(identificar_problemas_pais)

# Contar problemas
todos_problemas = [problema for sublist in df['Problemas_Pais'] for problema in sublist]
print(f"\n‚ö†Ô∏è  Problemas identificados:")
print(pd.Series(todos_problemas).value_counts())

# 3. Verificar consist√™ncia com a coluna Localiza√ß√£o
def extrair_pais_localizacao(localizacao):
    if pd.isna(localizacao) or localizacao == '':
        return None

    partes = str(localizacao).split(',')
    if len(partes) >= 3:
        return partes[-1].strip()  # √öltima parte deve ser o pa√≠s
    return None

df['Pais_Extraido_Localizacao'] = df['Localiza√ß√£o'].apply(extrair_pais_localizacao)

# Verificar consist√™ncia
def verificar_consistencia_pais(row):
    if pd.isna(row['Pa√≠s']) and pd.isna(row['Pais_Extraido_Localizacao']):
        return 'Ambos nulos'
    elif pd.isna(row['Pa√≠s']):
        return 'Apenas Localiza√ß√£o tem pa√≠s'
    elif pd.isna(row['Pais_Extraido_Localizacao']):
        return 'Apenas Pa√≠s preenchido'
    elif row['Pa√≠s'].lower() == row['Pais_Extraido_Localizacao'].lower():
        return 'Consistente'
    else:
        return 'Inconsistente'

df['Consistencia_Pais'] = df.apply(verificar_consistencia_pais, axis=1)

print(f"\nüîç Consist√™ncia entre Pa√≠s e Localiza√ß√£o:")
print(df['Consistencia_Pais'].value_counts())

# 4. Identificar varia√ß√µes de nomes de pa√≠ses
def padronizar_nome_pais(pais):
    if pd.isna(pais) or pais == '':
        return pais

    pais = str(pais).strip()

    # Mapeamento de varia√ß√µes para nomes padr√£o
    variacoes = {
        'Germany': ['Deutschland', 'Alemanha', 'GERMANY'],
        'United Kingdom': ['UK', 'England', 'Great Britain', 'Britain', 'U.K.'],
        'France': ['Fran√ßa', 'FRANCE'],
        'Spain': ['Espa√±a', 'Espagne', 'Espanha'],
        'Portugal': ['Portugal', 'PORTUGAL'],
        'Lithuania': ['Lietuva', 'Litu√¢nia'],
        'Poland': ['Polska', 'Pol√≥nia', 'Pol√¥nia'],
        'Brazil': ['Brasil', 'BRAZIL'],
        'Ireland': ['√âire', 'Irlanda'],
        'Netherlands': ['Holland', 'Nederland', 'Pa√≠ses Baixos'],
        'United States': ['USA', 'US', 'America', 'United States of America']
    }

    for padrao, variacoes_list in variacoes.items():
        if pais in variacoes_list or pais.lower() in [v.lower() for v in variacoes_list]:
            return padrao

    return pais

# Aplicar padroniza√ß√£o para an√°lise
df['Pais_Padronizado_Temp'] = df['Pa√≠s'].apply(padronizar_nome_pais)

print(f"\nüåç Pa√≠ses ap√≥s padroniza√ß√£o b√°sica:")
print(df['Pais_Padronizado_Temp'].value_counts().head(10))

# 5. Identificar pa√≠ses inv√°lidos ou suspeitos
def verificar_validade_pais(pais):
    if pd.isna(pais) or pais == '':
        return 'Inv√°lido (vazio)'

    # Lista de pa√≠ses v√°lidos (lista parcial)
    paises_validos = [
        'Germany', 'United Kingdom', 'France', 'Spain', 'Portugal',
        'Lithuania', 'Poland', 'Brazil', 'Ireland', 'Netherlands',
        'United States', 'Belgium', 'Estonia', 'Switzerland', 'Austria',
        'Italy', 'Sweden', 'Denmark', 'Norway', 'Finland', 'Luxembourg',
        'Czech Republic', 'Slovakia', 'Hungary', 'Romania', 'Bulgaria',
        'Greece', 'Turkey', 'Russia', 'Ukraine', 'India', 'China',
        'Japan', 'South Korea', 'Australia', 'Canada', 'Mexico', 'Argentina'
    ]

    if pais in paises_validos:
        return 'V√°lido'
    else:
        return 'Possivelmente inv√°lido'

df['Validade_Pais'] = df['Pais_Padronizado_Temp'].apply(verificar_validade_pais)

print(f"\n‚úÖ Validade dos pa√≠ses:")
print(df['Validade_Pais'].value_counts())

# 6. Mostrar exemplos problem√°ticos
print(f"\nüéØ Exemplos de valores problem√°ticos:")
problemas_graves = df[df['Problemas_Pais'].apply(lambda x: 'Muito curto' in x or 'Cont√©m n√∫meros' in x)]
if not problemas_graves.empty:
    print(problemas_graves[['Pa√≠s', 'Localiza√ß√£o', 'Problemas_Pais']].head(10).to_string())

# Mostrar inconsist√™ncias
inconsistentes = df[df['Consistencia_Pais'] == 'Inconsistente']
print(f"\nüîç Exemplos de inconsist√™ncias Pa√≠s vs Localiza√ß√£o:")
if not inconsistentes.empty:
    print(inconsistentes[['Pa√≠s', 'Localiza√ß√£o', 'Pais_Extraido_Localizacao']].head(5).to_string())

# 7. Estat√≠sticas finais
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"Total de registros: {len(df)}")
print(f"Pa√≠ses √∫nicos: {df['Pa√≠s'].nunique()}")
print(f"Taxa de preenchimento: {(len(df) - df['Pa√≠s'].isnull().sum()) / len(df) * 100:.1f}%")
print(f"Inconsist√™ncias com Localiza√ß√£o: {len(inconsistentes)}")
print(f"Pa√≠ses possivelmente inv√°lidos: {len(df[df['Validade_Pais'] == 'Possivelmente inv√°lido'])}")


# Dicion√°rio completo de padroniza√ß√£o
MAPEAMENTO_PAISES = {
    # Varia√ß√µes comuns
    'Deutschland': 'Germany',
    'Alemania': 'Germany',
    'Alemanha': 'Germany',
    'Allemagne': 'France',
    'Fran√ßa': 'France',
    'Espa√±a': 'Spain',
    'Espagne': 'Spain',
    'Espanha': 'Spain',
    'Reino Unido': 'United Kingdom',
    'UK': 'United Kingdom',
    'U.K.': 'United Kingdom',
    'England': 'United Kingdom',
    'Britain': 'United Kingdom',
    'Brasil': 'Brazil',
    'Portugal': 'Portugal',
    'Polska': 'Poland',
    'Pol√≥nia': 'Poland',
    'Pol√¥nia': 'Poland',
    'Lietuva': 'Lithuania',
    'Litu√¢nia': 'Lithuania',
    '√âire': 'Ireland',
    'Irlanda': 'Ireland',
    'Nederland': 'Netherlands',
    'Holland': 'Netherlands',
    'Pa√≠ses Baixos': 'Netherlands',
    'USA': 'United States',
    'US': 'United States',
    'America': 'United States',
    'Estados Unidos': 'United States',

    # Corre√ß√µes de typo
    'Germnay': 'Germany',
    'France': 'France',
    'Spian': 'Spain',
    'Portgual': 'Portugal',
    'Brazill': 'Brazil'
}

def corrigir_e_preencher_pais(row):
    # Primeiro: tentar usar o pa√≠s j√° existente (se v√°lido)
    if pd.notna(row['Pa√≠s']) and row['Pa√≠s'] != '':
        pais = str(row['Pa√≠s']).strip()

        # Aplicar mapeamento de varia√ß√µes
        if pais in MAPEAMENTO_PAISES:
            return MAPEAMENTO_PAISES[pais]

        # Verificar se √© um pa√≠s v√°lido
        try:
            if pycountry.countries.lookup(pais):
                return pais
        except:
            pass

    # Segundo: extrair da localiza√ß√£o se pa√≠s estiver vazio
    if pd.isna(row['Pa√≠s']) or row['Pa√≠s'] == '':
        if pd.notna(row['Localiza√ß√£o']):
            partes = str(row['Localiza√ß√£o']).split(',')
            if len(partes) >= 3:
                pais_localizacao = partes[-1].strip()
                if pais_localizacao in MAPEAMENTO_PAISES:
                    return MAPEAMENTO_PAISES[pais_localizacao]
                try:
                    if pycountry.countries.lookup(pais_localizacao):
                        return pais_localizacao
                except:
                    pass

    # Terceiro: se n√£o conseguir determinar, manter original ou usar "Unknown"
    return row['Pa√≠s'] if pd.notna(row['Pa√≠s']) else 'Unknown'

# Aplicar a corre√ß√£o
df['Pa√≠s_Corrigido'] = df.apply(corrigir_e_preencher_pais, axis=1)

# Verificar resultados
print("‚úÖ Resultados da corre√ß√£o:")
print(f"Valores nulos antes: {df['Pa√≠s'].isnull().sum()}")
print(f"Valores nulos depois: {df['Pa√≠s_Corrigido'].isnull().sum()}")
print(f"Pa√≠ses √∫nicos: {df['Pa√≠s_Corrigido'].nunique()}")

# Validar contra pycountry
def validar_pais(pais):
    if pais == 'Unknown':
        return 'Unknown'
    try:
        pycountry.countries.lookup(pais)
        return 'V√°lido'
    except:
        return 'Inv√°lido'

df['Validade_Pais_Corrigido'] = df['Pa√≠s_Corrigido'].apply(validar_pais)
print(f"\nüìä Validade dos pa√≠ses corrigidos:")
print(df['Validade_Pais_Corrigido'].value_counts())


# Salvar an√°lise
df.to_csv('Base_Dados_Exercicio_01_pais.csv', index=False)
print(f"\nüíæ An√°lise salva em 'Base_Dados_Exercicio_01_pais.csv'")

import pandas as pd
import numpy as np
import re

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_pais.csv')

print("=== AN√ÅLISE DA COLUNA 'Localiza√ß√£o' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Localiza√ß√£o'].isnull().sum()}")
print(f"Valores vazios/em branco: {(df['Localiza√ß√£o'] == '').sum()}")
print(f"Valores √∫nicos: {df['Localiza√ß√£o'].nunique()}")

# Verificar primeiros valores
print("\nüìã Primeiros 20 valores:")
print(df['Localiza√ß√£o'].head(20))

# Verificar √∫ltimos 20 valores
print("\nüìã √öltimos 20 valores:")
print(df['Localiza√ß√£o'].tail(20))

# An√°lise detalhada
print("\n=== AN√ÅLISE DETALHADA ===")

# 1. Analisar padr√£o da localiza√ß√£o
def analisar_formato_localizacao(localizacao):
    if pd.isna(localizacao) or localizacao == '':
        return 'Vazio'

    loc_str = str(localizacao)
    partes = loc_str.split(',')

    if len(partes) == 3:
        return 'Cidade, Estado, Pa√≠s'
    elif len(partes) == 2:
        return 'Cidade, Pa√≠s'
    elif len(partes) == 1:
        return 'Apenas Pa√≠s'
    else:
        return 'Formato irregular'

df['Formato_Localizacao'] = df['Localiza√ß√£o'].apply(analisar_formato_localizacao)

print("üìä Distribui√ß√£o por formato:")
print(df['Formato_Localizacao'].value_counts())

# 2. Extrair componentes da localiza√ß√£o
def extrair_componentes(localizacao):
    if pd.isna(localizacao) or localizacao == '':
        return None, None, None

    partes = str(localizacao).split(',')
    partes = [p.strip() for p in partes if p.strip()]

    if len(partes) == 3:
        return partes[0], partes[1], partes[2]  # cidade, estado, pa√≠s
    elif len(partes) == 2:
        return partes[0], None, partes[1]  # cidade, pa√≠s
    elif len(partes) == 1:
        return None, None, partes[0]  # pa√≠s
    else:
        return None, None, None

# Extrair componentes
componentes = df['Localiza√ß√£o'].apply(extrair_componentes)
df['Cidade'] = componentes.apply(lambda x: x[0] if x else None)
df['Estado'] = componentes.apply(lambda x: x[1] if x else None)
df['Pais_Localizacao'] = componentes.apply(lambda x: x[2] if x else None)

print(f"\nüåç Componentes extra√≠dos:")
print(f"Cidades extra√≠das: {df['Cidade'].notnull().sum()}")
print(f"Estados extra√≠dos: {df['Estado'].notnull().sum()}")
print(f"Pa√≠ses extra√≠dos: {df['Pais_Localizacao'].notnull().sum()}")

# 3. Verificar consist√™ncia com coluna Pa√≠s
def verificar_consistencia_pais_localizacao(row):
    if pd.isna(row['Pa√≠s']) and pd.isna(row['Pais_Localizacao']):
        return 'Ambos nulos'
    elif pd.isna(row['Pa√≠s']):
        return 'Apenas Localiza√ß√£o tem pa√≠s'
    elif pd.isna(row['Pais_Localizacao']):
        return 'Apenas Pa√≠s preenchido'
    elif str(row['Pa√≠s']).lower() == str(row['Pais_Localizacao']).lower():
        return 'Consistente'
    else:
        return 'Inconsistente'

df['Consistencia_Pais_Completa'] = df.apply(verificar_consistencia_pais_localizacao, axis=1)

print(f"\nüîç Consist√™ncia completa Pa√≠s vs Localiza√ß√£o:")
print(df['Consistencia_Pais_Completa'].value_counts())

# 4. Identificar problemas na localiza√ß√£o
def identificar_problemas_localizacao(localizacao):
    if pd.isna(localizacao) or localizacao == '':
        return ['Vazio']

    problemas = []
    loc_str = str(localizacao)

    if len(loc_str) < 2:
        problemas.append('Muito curto')
    if len(loc_str) > 150:
        problemas.append('Muito longo')
    if any(char.isdigit() for char in loc_str):
        problemas.append('Cont√©m n√∫meros')
    if re.search(r'[^\w\s\-,]', loc_str):  # Caracteres especiais n√£o permitidos
        problemas.append('Caracteres especiais')
    if loc_str.strip() != loc_str:
        problemas.append('Espa√ßos extras')
    if '  ' in loc_str:
        problemas.append('M√∫ltiplos espa√ßos')

    return problemas if problemas else ['OK']

df['Problemas_Localizacao'] = df['Localiza√ß√£o'].apply(identificar_problemas_localizacao)

# Contar problemas
todos_problemas = [problema for sublist in df['Problemas_Localizacao'] for problema in sublist]
print(f"\n‚ö†Ô∏è  Problemas identificados na Localiza√ß√£o:")
print(pd.Series(todos_problemas).value_counts())

# 5. An√°lise de cidades e estados mais comuns
print(f"\nüèôÔ∏è  Top 10 cidades mais comuns:")
if df['Cidade'].notnull().sum() > 0:
    print(df['Cidade'].value_counts().head(10))

print(f"\nüèõÔ∏è  Top 10 estados mais comuns:")
if df['Estado'].notnull().sum() > 0:
    print(df['Estado'].value_counts().head(10))

# 6. Mostrar exemplos problem√°ticos
print(f"\nüéØ Exemplos de valores problem√°ticos:")
problemas_graves = df[df['Problemas_Localizacao'].apply(lambda x: 'Muito curto' in x or 'Cont√©m n√∫meros' in x)]
if not problemas_graves.empty:
    print(problemas_graves[['Localiza√ß√£o', 'Problemas_Localizacao']].head(5).to_string())

# Mostrar inconsist√™ncias
inconsistentes = df[df['Consistencia_Pais_Completa'] == 'Inconsistente']
print(f"\nüîç Exemplos de inconsist√™ncias:")
if not inconsistentes.empty:
    print(inconsistentes[['Pa√≠s', 'Pais_Localizacao', 'Localiza√ß√£o']].head(5).to_string())

# 7. Estat√≠sticas finais
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"Total de registros: {len(df)}")
print(f"Taxa de preenchimento: {(len(df) - df['Localiza√ß√£o'].isnull().sum()) / len(df) * 100:.1f}%")
print(f"Formatos predominantes: {dict(df['Formato_Localizacao'].value_counts().head(3))}")
print(f"Inconsist√™ncias Pa√≠s vs Localiza√ß√£o: {len(inconsistentes)}")

#-----------------------------------------------------------------------------------------------------------------------

# Dicion√°rio de padroniza√ß√£o para √°reas metropolitanas
MAPEAMENTO_AREAS_METROPOLITANAS = {
    'Greater Munich Metropolitan Area': 'Munich, Bavaria, Germany',
    'Greater Nuremberg Metropolitan Area': 'Nuremberg, Bavaria, Germany',
    'Greater London Area': 'London, England, United Kingdom',
    'Greater Paris Metropolitan Region': 'Paris, √éle-de-France, France',
    'Greater Barcelona Metropolitan Area': 'Barcelona, Catalonia, Spain',
    'Greater Madrid Metropolitan Area': 'Madrid, Community of Madrid, Spain',
    'Greater Hamburg Area': 'Hamburg, Hamburg, Germany',
    'Greater Berlin Area': 'Berlin, Berlin, Germany',
    'Greater Lyon Area': 'Lyon, Auvergne-Rh√¥ne-Alpes, France',
    'Greater Manchester Area': 'Manchester, England, United Kingdom',
    'Greater Lisbon Metropolitan Area': 'Lisbon, Lisbon, Portugal',
    'Greater Porto Metropolitan Area': 'Porto, Porto, Portugal'
}

# Dicion√°rio de padroniza√ß√£o de cidades
MAPEAMENTO_CIDADES = {
    'Lisboa': 'Lisbon',
    'Milano': 'Milan',
    'Roma': 'Rome',
    'M√ºnchen': 'Munich',
    'K√∂ln': 'Cologne',
    'Wien': 'Vienna',
    'Praha': 'Prague',
    'Bruxelles': 'Brussels',
    'Warszawa': 'Warsaw'
}

def padronizar_localizacao(localizacao):
    if pd.isna(localizacao) or localizacao == '':
        return localizacao

    loc_str = str(localizacao).strip()

    # 1. Verificar se √© uma √°rea metropolitana e mapear
    for area_metropolitana, localizacao_especifica in MAPEAMENTO_AREAS_METROPOLITANAS.items():
        if area_metropolitana.lower() in loc_str.lower():
            return localizacao_especifica

    # 2. Padronizar nomes de cidades
    for cidade_original, cidade_padronizada in MAPEAMENTO_CIDADES.items():
        if cidade_original in loc_str:
            loc_str = loc_str.replace(cidade_original, cidade_padronizada)

    # 3. Corrigir inconsist√™ncias de acentua√ß√£o
    correcoes_acentuacao = {
        '√éle-de-France': 'Ile-de-France',
        'Auvergne-Rh√¥ne-Alpes': 'Auvergne-Rhone-Alpes',
        'Provence-Alpes-C√¥te d\'Azur': 'Provence-Alpes-Cote d\'Azur'
    }

    for original, correcao in correcoes_acentuacao.items():
        if original in loc_str:
            loc_str = loc_str.replace(original, correcao)

    # 4. Remover n√∫meros de endere√ßos (ex: "Paris 15" ‚Üí "Paris")
    loc_str = re.sub(r'\s\d+', '', loc_str)  # Remove n√∫meros ap√≥s espa√ßo
    loc_str = re.sub(r'\d+\s', '', loc_str)  # Remove n√∫meros antes de espa√ßo

    # 5. Garantir formato consistente
    partes = [p.strip() for p in loc_str.split(',')]

    # Se tem apenas pa√≠s, tentar enriquecer com informa√ß√£o dispon√≠vel
    if len(partes) == 1 and len(partes[0]) > 3:
        # Verificar se √© um pa√≠s conhecido que pode ser expandido
        paises_principais = ['Germany', 'France', 'UK', 'Spain', 'Portugal', 'Poland']
        if partes[0] in paises_principais:
            return f"Capital, {partes[0]}"  # Placeholder para capital

    return ', '.join(partes)

def validar_consistencia_geografica(row):
    """Validar consist√™ncia entre Pa√≠s e Localiza√ß√£o"""
    if pd.isna(row['Pa√≠s']) or pd.isna(row['Pais_Localizacao']):
        return True  # N√£o pode validar se algum estiver vazio

    pais_coluna = str(row['Pa√≠s']).lower().strip()
    pais_localizacao = str(row['Pais_Localizacao']).lower().strip()

    # Mapeamento de equival√™ncias
    equivalencias = {
        'uk': ['united kingdom', 'england', 'great britain'],
        'usa': ['united states', 'america'],
        'netherlands': ['holland', 'nederland'],
        'germany': ['deutschland']
    }

    # Verificar equival√™ncias
    for pais_base, variantes in equivalencias.items():
        if pais_coluna == pais_base and pais_localizacao in variantes:
            return True
        if pais_localizacao == pais_base and pais_coluna in variantes:
            return True

    return pais_coluna == pais_localizacao

# Aplicar padroniza√ß√£o
df['Localiza√ß√£o_Padronizada'] = df['Localiza√ß√£o'].apply(padronizar_localizacao)

# Re-extrair componentes da localiza√ß√£o padronizada
componentes_padronizados = df['Localiza√ß√£o_Padronizada'].apply(extrair_componentes)
df['Cidade_Padronizada'] = componentes_padronizados.apply(lambda x: x[0] if x else None)
df['Estado_Padronizado'] = componentes_padronizados.apply(lambda x: x[1] if x else None)
df['Pais_Localizacao_Padronizado'] = componentes_padronizados.apply(lambda x: x[2] if x else None)

# Validar consist√™ncia
df['Consistencia_Validada'] = df.apply(validar_consistencia_geografica, axis=1)

print("‚úÖ Resultados da padroniza√ß√£o:")
print(f"Inconsist√™ncias resolvidas: {140 - len(df[~df['Consistencia_Validada']])}")
print(f"Localiza√ß√µes padronizadas: {df['Localiza√ß√£o_Padronizada'].nunique()} (antes: {df['Localiza√ß√£o'].nunique()})")

# Salvar an√°lise
df.to_csv('Base_Dados_Exercicio_01_localizacao.csv', index=False)
print(f"\nüíæ An√°lise salva em 'Base_Dados_Exercicio_01_localizacao.csv'")

import pandas as pd
import numpy as np
import re

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_localizacao.csv')

print("=== AN√ÅLISE DA COLUNA 'Setor' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Setor'].isnull().sum()}")
print(f"Valores vazios/em branco: {(df['Setor'] == '').sum()}")
print(f"Valores √∫nicos: {df['Setor'].nunique()}")

# Verificar primeiros valores
print("\nüìã Primeiros 20 valores:")
print(df['Setor'].head(20))

# Verificar √∫ltimos 20 valores
print("\nüìã √öltimos 20 valores:")
print(df['Setor'].tail(20))

# An√°lise detalhada
print("\n=== AN√ÅLISE DETALHADA ===")

# 1. Distribui√ß√£o geral dos setores
print("üìä Distribui√ß√£o geral dos setores:")
distribuicao_setores = df['Setor'].value_counts()
print(distribuicao_setores.head(15))  # Top 15 setores

# 2. An√°lise de categoriza√ß√£o
def categorizar_setor_amplo(setor):
    if pd.isna(setor) or setor == '':
        return 'N√£o Informado'

    setor_str = str(setor).lower()

    # Categorias amplas
    categorias = {
        'Tecnologia': ['software', 'technology', 'it', 'computer', 'internet', 'cloud', 'saas', 'devops'],
        'Dados & Analytics': ['data', 'analytics', 'business intelligence', 'ai', 'machine learning', 'big data'],
        'Consultoria': ['consulting', 'consultoria', 'services', 'professional services'],
        'Financeiro': ['financial', 'banking', 'fintech', 'insurance', 'investment'],
        'Sa√∫de': ['healthcare', 'medical', 'pharmaceutical', 'biotech', 'hospital'],
        'Varejo & E-commerce': ['retail', 'e-commerce', 'consumer goods', 'fashion'],
        'Manufacturing': ['manufacturing', 'industrial', 'automotive', 'engineering'],
        'Educa√ß√£o': ['education', 'edtech', 'e-learning', 'higher education'],
        'M√≠dia & Marketing': ['media', 'marketing', 'advertising', 'digital marketing'],
        'Telecom': ['telecommunications', 'telecom', 'communications'],
        'Energia': ['energy', 'oil', 'gas', 'renewable'],
        'Governo': ['government', 'public sector', 'defense'],
        'Games': ['gaming', 'games', 'gambling', 'casino']
    }

    for categoria, palavras_chave in categorias.items():
        if any(palavra in setor_str for palavra in palavras_chave):
            return categoria

    return 'Outros'

df['Categoria_Ampla'] = df['Setor'].apply(categorizar_setor_amplo)

print(f"\nüè¢ Categorias amplas identificadas:")
print(df['Categoria_Ampla'].value_counts())

# 3. Identificar problemas e inconsist√™ncias
def identificar_problemas_setor(setor):
    if pd.isna(setor) or setor == '':
        return ['Vazio']

    problemas = []
    setor_str = str(setor)

    if len(setor_str) < 3:
        problemas.append('Muito curto')
    if len(setor_str) > 100:
        problemas.append('Muito longo')
    if any(char.isdigit() for char in setor_str):
        problemas.append('Cont√©m n√∫meros')
    if re.search(r'[^\w\s\/&+-]', setor_str):  # Caracteres especiais
        problemas.append('Caracteres especiais')
    if setor_str.strip() != setor_str:
        problemas.append('Espa√ßos extras')
    if '  ' in setor_str:
        problemas.append('M√∫ltiplos espa√ßos')
    if setor_str.isupper():
        problemas.append('Tudo mai√∫sculo')
    if setor_str.islower():
        problemas.append('Tudo min√∫sculo')

    return problemas if problemas else ['OK']

df['Problemas_Setor'] = df['Setor'].apply(identificar_problemas_setor)

# Contar problemas
todos_problemas = [problema for sublist in df['Problemas_Setor'] for problema in sublist]
print(f"\n‚ö†Ô∏è  Problemas identificados:")
print(pd.Series(todos_problemas).value_counts())

# 4. An√°lise de granularidade
def analisar_granularidade(setor):
    if pd.isna(setor) or setor == '':
        return 'Vazio'

    setor_str = str(setor)
    palavras = setor_str.split()

    if len(palavras) == 1:
        return 'Muito gen√©rico'
    elif len(palavras) <= 3:
        return 'Adequado'
    else:
        return 'Muito espec√≠fico'

df['Granularidade_Setor'] = df['Setor'].apply(analisar_granularidade)

print(f"\nüìè Granularidade dos setores:")
print(df['Granularidade_Setor'].value_counts())

# 5. Identificar varia√ß√µes do mesmo setor
# Encontrar setores similares
setores_unicos = df['Setor'].dropna().unique()
setores_similares = {}

for setor in setores_unicos:
    setor_clean = re.sub(r'[^\w\s]', '', str(setor).lower()).strip()
    if setor_clean not in setores_similares:
        setores_similares[setor_clean] = []
    setores_similares[setor_clean].append(setor)

# Mostrar varia√ß√µes problem√°ticas
print(f"\nüîç Varia√ß√µes de mesmo setor (exemplos):")
for setor_base, variacoes in list(setores_similares.items())[:10]:
    if len(variacoes) > 1:
        print(f"  {setor_base}: {variacoes}")

# 6. Cruzamento com outras colunas
print(f"\nüîó Rela√ß√£o com √Årea de atua√ß√£o (da coluna Cargo):")
if 'Area' in df.columns:
    cruzamento = pd.crosstab(df['Categoria_Ampla'], df['Area'])
    print(cruzamento)

# 7. Mostrar exemplos problem√°ticos
print(f"\nüéØ Exemplos de valores problem√°ticos:")
problemas_graves = df[df['Problemas_Setor'].apply(lambda x: 'Muito curto' in x or 'Cont√©m n√∫meros' in x)]
if not problemas_graves.empty:
    print(problemas_graves[['Setor', 'Problemas_Setor']].head(5).to_string())

# Mostrar setores muito gen√©ricos
genericos = df[df['Granularidade_Setor'] == 'Muito gen√©rico']
print(f"\nüìã Exemplos de setores muito gen√©ricos:")
if not genericos.empty:
    print(genericos['Setor'].value_counts().head(10))

# 8. Estat√≠sticas finais
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"Total de registros: {len(df)}")
print(f"Taxa de preenchimento: {(len(df) - df['Setor'].isnull().sum()) / len(df) * 100:.1f}%")
print(f"Setores √∫nicos: {df['Setor'].nunique()}")
print(f"Problemas identificados: {len(df[df['Problemas_Setor'].apply(lambda x: 'OK' not in x)])}")


# Mapeamento hier√°rquico de setores
HIERARQUIA_SETORES = {
    # TI & Software
    'Information Technology & Services': 'Tecnologia - Infraestrutura',
    'Computer Software': 'Tecnologia - Software',
    'IT System Custom Software Development': 'Tecnologia - Software Custom',
    'Computer Games': 'Tecnologia - Games',
    'Computer Networking': 'Tecnologia - Redes',

    # Internet & Digital
    'Internet': 'Digital - Plataformas Online',
    'E-Learning': 'Digital - Educa√ß√£o',
    'Online Media': 'Digital - M√≠dia',

    # Telecomunica√ß√µes
    'Telecommunications': 'Telecom - Geral',

    # Dados & Analytics
    'Data Infrastructure and Analytics': 'Dados - Infraestrutura',
    'Business Intelligence': 'Dados - BI',
    'Market Research': 'Dados - Pesquisa',

    # Financeiro
    'Financial Services': 'Financeiro - Servi√ßos',
    'Banking': 'Financeiro - Bancos',
    'Insurance': 'Financeiro - Seguros',
    'Investment Banking': 'Financeiro - Investimentos',

    # Consultoria
    'Management Consulting': 'Consultoria - Gest√£o',
    'Information Technology & Services': 'Consultoria - TI',

    # Outros setores
    'Automotive': 'Manufacturing - Automotivo',
    'Pharmaceuticals': 'Sa√∫de - Farmac√™utico',
    'Healthcare': 'Sa√∫de - Geral'
}

# Subcategorias para setores gen√©ricos
SUBCATEGORIAS = {
    'Internet': ['E-commerce', 'Social Media', 'Content Platform', 'Marketplace'],
    'Telecommunications': ['Mobile Services', 'Broadband', 'Telecom Infrastructure'],
    'Financial Services': ['FinTech', 'Payment Solutions', 'Wealth Management']
}

def padronizar_setor(setor):
    if pd.isna(setor) or setor == '':
        return 'N√£o Informado'

    setor_str = str(setor).strip()

    # 1. Aplicar mapeamento hier√°rquico
    for setor_original, setor_padronizado in HIERARQUIA_SETORES.items():
        if setor_original.lower() == setor_str.lower():
            return setor_padronizado

    # 2. Para setores muito gen√©ricos, tentar enriquecer
    if setor_str in SUBCATEGORIAS:
        # Aqui poder√≠amos usar outras colunas para determinar a subcategoria
        return f"{setor_str} - Geral"

    # 3. Manter original mas aplicar capitaliza√ß√£o consistente
    return setor_str.title()

def categorizar_nivel_detalhe(setor):
    """Classificar por n√≠vel de detalhe"""
    if pd.isna(setor) or setor == '':
        return 'Nulo'

    setor_str = str(setor)
    palavras = setor_str.split()

    if len(palavras) <= 2:
        return 'Gen√©rico'
    elif len(palavras) <= 4:
        return 'Espec√≠fico'
    else:
        return 'Muito Espec√≠fico'

# Aplicar padroniza√ß√£o
df['Setor_Padronizado'] = df['Setor'].apply(padronizar_setor)
df['Nivel_Detalhe_Setor'] = df['Setor_Padronizado'].apply(categorizar_nivel_detalhe)

# Preencher nulos baseado em outras colunas
def preencher_setor_por_contexto(row):
    if pd.notna(row['Setor']):
        return row['Setor_Padronizado']

    # Tentar inferir setor a partir de outras colunas
    cargo = str(row['Cargo']).lower() if pd.notna(row['Cargo']) else ''
    empresa = str(row['Nome da empresa']).lower() if pd.notna(row['Nome da empresa']) else ''

    if any(palavra in cargo for palavra in ['data', 'analyst', 'scientist']):
        return 'Dados - Analytics'
    elif any(palavra in cargo for palavra in ['devops', 'sre', 'infrastructure']):
        return 'Tecnologia - Infraestrutura'
    elif any(palavra in empresa for palavra in ['tech', 'software', 'cloud']):
        return 'Tecnologia - Software'
    elif any(palavra in empresa for palavra in ['bank', 'finance', 'capital']):
        return 'Financeiro - Servi√ßos'

    return 'Setor N√£o Identificado'

df['Setor_Inferido'] = df.apply(preencher_setor_por_contexto, axis=1)
df['Setor_Final'] = df.apply(lambda x: x['Setor_Padronizado'] if pd.notna(x['Setor']) else x['Setor_Inferido'], axis=1)

# An√°lise dos resultados
print("‚úÖ Resultados da padroniza√ß√£o:")
print(f"Setores √∫nicos antes: {df['Setor'].nunique()}")
print(f"Setores √∫nicos depois: {df['Setor_Final'].nunique()}")
print(f"Nulos resolvidos: {55 - df['Setor_Final'].isnull().sum()}")

print(f"\nüìä Distribui√ß√£o dos setores padronizados:")
print(df['Setor_Final'].value_counts().head(10))

print(f"\nüìè N√≠vel de detalhe ap√≥s padroniza√ß√£o:")
print(df['Nivel_Detalhe_Setor'].value_counts())

# Salvar an√°lise
df.to_csv('Base_Dados_Exercicio_01_setor.csv', index=False)
print(f"\nüíæ An√°lise salva em 'Base_Dados_Exercicio_01_setor.csv'")

import pandas as pd
import numpy as np
from datetime import datetime

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_setor.csv')

print("=== AN√ÅLISE DA COLUNA 'Adicionar data' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Adicionar data'].isnull().sum()}")
print(f"Valores vazios/em branco: {(df['Adicionar data'] == '').sum()}")
print(f"Valores √∫nicos: {df['Adicionar data'].nunique()}")

# Verificar primeiros valores
print("\nüìã Primeiros 20 valores:")
print(df['Adicionar data'].head(20))

# Verificar √∫ltimos 20 valores
print("\nüìã √öltimos 20 valores:")
print(df['Adicionar data'].tail(20))

# An√°lise detalhada
print("\n=== AN√ÅLISE DETALHADA ===")

# 1. Converter para datetime e analisar formato
try:
    df['Data_Datetime'] = pd.to_datetime(df['Adicionar data'], errors='coerce')
    print("‚úÖ Convers√£o para datetime bem-sucedida")

    # Verificar valores que n√£o converteram
    falhas_conversao = df['Data_Datetime'].isnull().sum()
    if falhas_conversao > 0:
        print(f"‚ùå {falhas_conversao} valores n√£o puderam ser convertidos")
        print("Valores problem√°ticos:")
        print(df[df['Data_Datetime'].isnull()]['Adicionar data'].unique())

except Exception as e:
    print(f"‚ùå Erro na convers√£o: {e}")
    df['Data_Datetime'] = None

# 2. An√°lise de distribui√ß√£o temporal
if df['Data_Datetime'].notnull().any():
    print(f"\nüìÖ Estat√≠sticas temporais:")
    print(f"Data mais antiga: {df['Data_Datetime'].min()}")
    print(f"Data mais recente: {df['Data_Datetime'].max()}")
    print(f"Range temporal: {df['Data_Datetime'].max() - df['Data_Datetime'].min()}")

    # Distribui√ß√£o por ano/m√™s
    df['Ano'] = df['Data_Datetime'].dt.year
    df['Mes'] = df['Data_Datetime'].dt.month
    df['Dia'] = df['Data_Datetime'].dt.day

    print(f"\nüìä Distribui√ß√£o por ano:")
    print(df['Ano'].value_counts().sort_index())

    print(f"\nüìä Distribui√ß√£o por m√™s (2025):")
    if 2025 in df['Ano'].values:
        print(df[df['Ano'] == 2025]['Mes'].value_counts().sort_index())

# 3. Identificar problemas de formato
def identificar_problemas_data(data_str):
    if pd.isna(data_str) or data_str == '':
        return ['Vazio']

    problemas = []

    # Verificar se parece uma data
    if not any(char.isdigit() for char in str(data_str)):
        problemas.append('Sem n√∫meros')

    # Verificar formato muito longo/curto
    if len(str(data_str)) < 8:
        problemas.append('Muito curto')
    if len(str(data_str)) > 30:
        problemas.append('Muito longo')

    # Verificar caracteres problem√°ticos
    if re.search(r'[^\d\s\-:/]', str(data_str)):
        problemas.append('Caracteres inv√°lidos')

    return problemas if problemas else ['OK']

df['Problemas_Data'] = df['Adicionar data'].apply(identificar_problemas_data)

# Contar problemas
todos_problemas = [problema for sublist in df['Problemas_Data'] for problema in sublist]
print(f"\n‚ö†Ô∏è  Problemas identificados:")
print(pd.Series(todos_problemas).value_counts())

# 4. Verificar se todas as datas s√£o futuras (2025)
if df['Data_Datetime'].notnull().any():
    datas_futuras = df[df['Data_Datetime'] > pd.Timestamp.now()]
    print(f"\nüîÆ Datas futuras (2025): {len(datas_futuras)} registros")

    if len(datas_futuras) > 0:
        print("Exemplos de datas futuras:")
        print(datas_futuras['Adicionar data'].head(10).tolist())

# 5. An√°lise de padr√µes de preenchimento
def analisar_padrao_temporal(df):
    """Analisar padr√µes de preenchimento ao longo do tempo"""
    if df['Data_Datetime'].notnull().any():
        # Agrupar por dia para ver volume
        daily_counts = df.groupby(df['Data_Datetime'].dt.date).size()
        print(f"\nüìà Volume por dia:")
        print(f"M√°ximo: {daily_counts.max()} registros/dia")
        print(f"M√≠nimo: {daily_counts.min()} registros/dia")
        print(f"M√©dia: {daily_counts.mean():.1f} registros/dia")

analisar_padrao_temporal(df)

# 6. Verificar consist√™ncia com outras colunas temporais
# (Se houver outras colunas de data no dataset)
colunas_data = [col for col in df.columns if 'data' in col.lower() or 'date' in col.lower()]
print(f"\nüìÖ Colunas de data no dataset: {colunas_data}")

# 7. Mostrar exemplos problem√°ticos
print(f"\nüéØ Exemplos de valores problem√°ticos:")
problemas_graves = df[df['Problemas_Data'].apply(lambda x: 'Sem n√∫meros' in x or 'Caracteres inv√°lidos' in x)]
if not problemas_graves.empty:
    print(problemas_graves[['Adicionar data', 'Problemas_Data']].head(5).to_string())

# 8. Estat√≠sticas finais
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"Total de registros: {len(df)}")
print(f"Valores convertidos para datetime: {df['Data_Datetime'].notnull().sum()}")
print(f"Valores problem√°ticos: {len(df[df['Problemas_Data'].apply(lambda x: 'OK' not in x)])}")

if df['Data_Datetime'].notnull().any():
    print(f"Per√≠odo coberto: {df['Data_Datetime'].min()} to {df['Data_Datetime'].max()}")

# Salvar an√°lise
#df.to_csv('Base_Dados_Exercicio_01_data.csv', index=False)
#print(f"\nüíæ An√°lise salva em 'Base_Dados_Exercicio_01_data.csv'")

import pandas as pd
import numpy as np

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_setor.csv')

print("=== SIMPLIFICANDO COLUNAS TEMPORAIS ===")

# 1. Manter apenas a coluna datetime completa
df['Data_Completa'] = pd.to_datetime(df['Adicionar data'])

# 2. Criar apenas as colunas essenciais solicitadas
print("üìÖ Criando colunas temporais essenciais...")

# Colunas b√°sicas no formato solicitado
df['Ano'] = df['Data_Completa'].dt.year.astype(int)
df['Mes'] = df['Data_Completa'].dt.month.astype(int)
df['Dia'] = df['Data_Completa'].dt.day.astype(int)
df['Trimestre'] = df['Data_Completa'].dt.quarter.astype(int)
df['Semana'] = df['Data_Completa'].dt.isocalendar().week.astype(int)
df['Dia_Semana'] = df['Data_Completa'].dt.day_name()


# 4. Verificar estrutura final
print(f"\n‚úÖ Estrutura final simplificada:")
print(f"Total de colunas: {len(df.columns)}")
print(f"Total de registros: {len(df)}")

# Mostrar apenas as colunas temporais
colunas_temporais = ['Data_Completa', 'Ano', 'Mes', 'Dia', 'Trimestre', 'Semana', 'Dia_Semana']
print(f"\nüìä Colunas temporais mantidas ({len(colunas_temporais)}):")
for col in colunas_temporais:
    if col in df.columns:
        print(f"  - {col} ({df[col].dtype})")

# 5. Mostrar amostra dos dados
print(f"\nüéØ Amostra dos dados temporais:")
amostra = df[colunas_temporais].head(10)
print(amostra.to_string(index=False))

# 6. Estat√≠sticas b√°sicas
print(f"\nüìà Estat√≠sticas das colunas temporais:")
print(f"Ano: {df['Ano'].unique()} (√∫nico)")
print(f"Meses: {sorted(df['Mes'].unique())}")
print(f"Dias: {df['Dia'].nunique()} dias √∫nicos")
print(f"Trimestres: {df['Trimestre'].unique()}")
print(f"Semanas: {sorted(df['Semana'].unique())}")
print(f"Dias da semana: {df['Dia_Semana'].unique()}")

# 7. Salvar dataset simplificado
df.to_csv('Base_Dados_Exercicio_01_data.csv', index=False)
print(f"üìç Arquivo: 'Base_Dados_Exercicio_01_data.csv'")

# 8. Verifica√ß√£o de tipos de dados
print(f"\nüîç Verifica√ß√£o de tipos de dados:")
for col in colunas_temporais:
    if col in df.columns:
        print(f"{col}: {df[col].dtype}")

print(f"\n‚úÖ Simplifica√ß√£o conclu√≠da! Mantidas apenas 7 colunas temporais essenciais.")

import pandas as pd
import numpy as np
import re

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_data.csv')

print("=== AN√ÅLISE DA COLUNA 'Nome da empresa' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Nome da empresa'].isnull().sum()}")
print(f"Valores vazios/em branco: {(df['Nome da empresa'] == '').sum()}")
print(f"Valores √∫nicos: {df['Nome da empresa'].nunique()}")

# Verificar primeiros valores
print("\nüìã Primeiros 20 valores:")
print(df['Nome da empresa'].head(20))

# Verificar √∫ltimos 20 valores
print("\nüìã √öltimos 20 valores:")
print(df['Nome da empresa'].tail(20))

# An√°lise detalhada
print("\n=== AN√ÅLISE DETALHADA ===")

# 1. Distribui√ß√£o geral das empresas
print("üìä Distribui√ß√£o geral das empresas:")
distribuicao_empresas = df['Nome da empresa'].value_counts()
print(distribuicao_empresas.head(15))  # Top 15 empresas

# 2. Identificar problemas e inconsist√™ncias
def identificar_problemas_empresa(empresa):
    if pd.isna(empresa) or empresa == '':
        return ['Vazio']

    problemas = []
    empresa_str = str(empresa).strip()

    if len(empresa_str) < 2:
        problemas.append('Muito curto')
    if len(empresa_str) > 100:
        problemas.append('Muito longo')
    if any(char.isdigit() for char in empresa_str):
        problemas.append('Cont√©m n√∫meros')
    if re.search(r'[^\w\s\-\.,&()]', empresa_str):  # Caracteres especiais
        problemas.append('Caracteres especiais')
    if empresa_str.strip() != empresa_str:
        problemas.append('Espa√ßos extras')
    if '  ' in empresa_str:
        problemas.append('M√∫ltiplos espa√ßos')
    if empresa_str.isupper():
        problemas.append('Tudo mai√∫sculo')
    if empresa_str.islower():
        problemas.append('Tudo min√∫sculo')
    if 'test' in empresa_str.lower() or 'example' in empresa_str.lower():
        problemas.append('Poss√≠vel teste')

    return problemas if problemas else ['OK']

df['Problemas_Empresa'] = df['Nome da empresa'].apply(identificar_problemas_empresa)

# Contar problemas
todos_problemas = [problema for sublist in df['Problemas_Empresa'] for problema in sublist]
print(f"\n‚ö†Ô∏è  Problemas identificados:")
print(pd.Series(todos_problemas).value_counts())

# 3. Identificar varia√ß√µes do mesmo nome
empresas_unicas = df['Nome da empresa'].dropna().unique()
empresas_similares = {}

for empresa in empresas_unicas:
    # Limpar e normalizar o nome
    empresa_clean = re.sub(r'[^\w\s]', '', str(empresa).lower()).strip()
    empresa_clean = re.sub(r'\s+', ' ', empresa_clean)

    if empresa_clean not in empresas_similares:
        empresas_similares[empresa_clean] = []
    empresas_similares[empresa_clean].append(empresa)

# Mostrar varia√ß√µes problem√°ticas
print(f"\nüîç Varia√ß√µes de mesma empresa (exemplos):")
variacoes_problematicas = 0
for empresa_base, variacoes in list(empresas_similares.items())[:15]:
    if len(variacoes) > 1:
        print(f"  {empresa_base}: {variacoes}")
        variacoes_problematicas += 1

print(f"\nüìà Total de empresas com varia√ß√µes: {variacoes_problematicas}")

# 4. An√°lise de padr√µes de nomenclatura
def analisar_tipo_nome(empresa):
    if pd.isna(empresa) or empresa == '':
        return 'Vazio'

    empresa_str = str(empresa)

    # Verificar se cont√©m Ltd, GmbH, SA, etc.
    sufixos_corporativos = ['Ltd', 'GmbH', 'AG', 'SA', 'SL', 'LLC', 'Inc', 'Corp', 'PLC']
    if any(sufixo in empresa_str for sufixo in sufixos_corporativos):
        return 'Com sufixo corporativo'

    # Verificar se √© muito curto
    if len(empresa_str) < 5:
        return 'Muito curto'

    # Verificar se cont√©m siglas
    if re.search(r'\b[A-Z]{2,}\b', empresa_str):
        return 'Cont√©m siglas'

    return 'Nome padr√£o'

df['Tipo_Nome_Empresa'] = df['Nome da empresa'].apply(analisar_tipo_nome)

print(f"\nüè¢ Tipos de nomenclatura:")
print(df['Tipo_Nome_Empresa'].value_counts())

# 5. Identificar empresas muito comuns (poss√≠veis placeholders)
empresas_comuns = df['Nome da empresa'].value_counts()
empresas_muito_comuns = empresas_comuns[empresas_comuns > 10]

print(f"\nüîç Empresas muito comuns (poss√≠veis placeholders):")
print(empresas_muito_comuns.head(10))

# 6. Cruzamento com outras colunas
print(f"\nüîó Rela√ß√£o com Setor:")
if 'Setor' in df.columns:
    cruzamento_setor = pd.crosstab(df['Nome da empresa'], df['Setor']).sum(axis=1)
    print(f"Empresas com m√∫ltiplos setores: {len(cruzamento_setor[cruzamento_setor > 1])}")

# 7. Mostrar exemplos problem√°ticos
print(f"\nüéØ Exemplos de valores problem√°ticos:")
problemas_graves = df[df['Problemas_Empresa'].apply(lambda x: 'Muito curto' in x or 'Poss√≠vel teste' in x)]
if not problemas_graves.empty:
    print(problemas_graves[['Nome da empresa', 'Problemas_Empresa']].head(5).to_string())

# Mostrar empresas com varia√ß√µes
print(f"\nüîç Exemplos de varia√ß√µes de nome:")
for empresa_base, variacoes in list(empresas_similares.items())[:5]:
    if len(variacoes) > 1:
        print(f"{empresa_base}: {variacoes}")

# 8. Estat√≠sticas finais
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"Total de registros: {len(df)}")
print(f"Taxa de preenchimento: {(len(df) - df['Nome da empresa'].isnull().sum()) / len(df) * 100:.1f}%")
print(f"Empresas √∫nicas: {df['Nome da empresa'].nunique()}")
print(f"Problemas identificados: {len(df[df['Problemas_Empresa'].apply(lambda x: 'OK' not in x)])}")
print(f"Varia√ß√µes de nomenclatura: {variacoes_problematicas}")


# Dicion√°rio de padroniza√ß√£o de empresas comuns
PADRONIZACAO_EMPRESAS = {
    'TRAFI': 'Trafi',
    'Trafi': 'Trafi',
    'Parser': 'Parser Digital',
    'GovData Ltd': 'GovData',
    'Art2Trading': 'Art2Trading',
    'Hove': 'Hove',
    'Lindera': 'Lindera',
    'Thinkproject': 'Thinkproject',
    'Selency': 'Selency',
    'Strix PL': 'Strix',
    'Mytraffic': 'MyTraffic',
    'TheForceCode': 'TheForceCode',
    'Capgemini Invent': 'Capgemini',
    'Aquila Data Enabler': 'Aquila Data'
}

# Sufixos corporativos para remover/padronizar
SUFIXOS_CORPORATIVOS = {
    'GmbH': '', 'Ltd': '', 'SL': '', 'SA': '', 'LLC': '', 'Inc': '',
    'Corp': '', 'PLC': '', 'Lda': '', 'AG': '', 'Co': ''
}

def padronizar_nome_empresa(empresa):
    if pd.isna(empresa) or empresa == '':
        return 'N√£o Informado'

    # 1. Aplicar padroniza√ß√£o de empresas conhecidas
    if empresa in PADRONIZACAO_EMPRESAS:
        return PADRONIZACAO_EMPRESAS[empresa]

    empresa_str = str(empresa).strip()

    # 2. Remover sufixos corporativos
    for sufixo, substituicao in SUFIXOS_CORPORATIVOS.items():
        if empresa_str.endswith(sufixo):
            empresa_str = empresa_str.replace(sufixo, substituicao).strip()
        elif f" {sufixo}" in empresa_str:
            empresa_str = empresa_str.replace(f" {sufixo}", substituicao).strip()

    # 3. Capitaliza√ß√£o inteligente (Title Case mas preservar siglas)
    palavras = empresa_str.split()
    palavras_padronizadas = []

    for palavra in palavras:
        if palavra.isupper() and len(palavra) > 2:  # Preservar siglas verdadeiras
            palavras_padronizadas.append(palavra)
        else:
            palavras_padronizadas.append(palavra.title())

    empresa_str = ' '.join(palavras_padronizadas)

    # 4. Remover caracteres especiais problem√°ticos
    empresa_str = re.sub(r'[^\w\s\-\&]', '', empresa_str)

    # 5. Corrigir espa√ßos m√∫ltiplos
    empresa_str = re.sub(r'\s+', ' ', empresa_str).strip()

    # 6. Tratamento especial para nomes muito curtos
    if len(empresa_str) < 3:
        return f"{empresa_str} (abreviado)"

    return empresa_str

# Aplicar padroniza√ß√£o
df['Empresa_Padronizada'] = df['Nome da empresa'].apply(padronizar_nome_empresa)

# Verificar resultados
print("‚úÖ Resultados da padroniza√ß√£o:")
print(f"Empresas √∫nicas antes: {df['Nome da empresa'].nunique()}")
print(f"Empresas √∫nicas depois: {df['Empresa_Padronizada'].nunique()}")
print(f"Problemas resolvidos: {232 - len(df[df['Problemas_Empresa'].apply(lambda x: 'OK' not in x)])}")

print(f"\nüìä Exemplos de padroniza√ß√£o:")
exemplos = df[['Nome da empresa', 'Empresa_Padronizada']].head(10)
print(exemplos.to_string(index=False))

# An√°lise de qualidade p√≥s-padroniza√ß√£o
def verificar_qualidade_padronizacao(empresa):
    if pd.isna(empresa) or empresa == 'N√£o Informado':
        return 'Inv√°lido'

    emp_str = str(empresa)

    if len(emp_str) < 3:
        return 'Muito curto'
    if emp_str.isupper():
        return 'Tudo mai√∫sculo'
    if emp_str.islower():
        return 'Tudo min√∫sculo'
    if any(char.isdigit() for char in emp_str):
        return 'Cont√©m n√∫meros'

    return 'OK'

df['Qualidade_Padronizada'] = df['Empresa_Padronizada'].apply(verificar_qualidade_padronizacao)

print(f"\nüìà Qualidade ap√≥s padroniza√ß√£o:")
print(df['Qualidade_Padronizada'].value_counts())

# Salvar an√°lise
df.to_csv('Base_Dados_Exercicio_01_empresa.csv', index=False)
print(f"\nüíæ An√°lise salva em 'Base_Dados_Exercicio_01_empresa.csv'")

import pandas as pd
import numpy as np
import re
from urllib.parse import urlparse, urlunparse

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_empresa.csv')

print("=== AN√ÅLISE DA COLUNA 'URL da empresa' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['URL da empresa'].isnull().sum()}")
print(f"Valores vazios/em branco: {(df['URL da empresa'] == '').sum()}")
print(f"Valores √∫nicos: {df['URL da empresa'].nunique()}")

# Verificar primeiros valores
print("\nüìã Primeiros 20 valores:")
print(df['URL da empresa'].head(20))

# Verificar √∫ltimos 20 valores
print("\nüìã √öltimos 20 valores:")
print(df['URL da empresa'].tail(20))

# An√°lise detalhada
print("\n=== AN√ÅLISE DETALHADA ===")

# 1. Distribui√ß√£o geral das URLs
print("üìä Distribui√ß√£o geral das URLs:")
url_counts = df['URL da empresa'].value_counts()
print(url_counts.head(15))  # Top 15 URLs

# 2. Identificar problemas e inconsist√™ncias
def identificar_problemas_url(url):
    if pd.isna(url) or url == '':
        return ['Vazio']

    url_str = str(url).strip()
    problemas = []

    # Verificar se parece uma URL
    if not re.match(r'^(http|https|www\.)', url_str, re.IGNORECASE):
        problemas.append('N√£o come√ßa com http/https/www')

    # Verificar comprimento
    if len(url_str) < 8:
        problemas.append('Muito curta')
    if len(url_str) > 200:
        problemas.append('Muito longa')

    # Verificar caracteres problem√°ticos
    if re.search(r'[\s<>{}|\\^~\[\]]', url_str):
        problemas.append('Caracteres inv√°lidos')

    # Verificar se tem dom√≠nio v√°lido
    if not re.search(r'\.(com|org|net|io|co|edu|gov|br|de|fr|uk|es|it|pl|eu)$', url_str, re.IGNORECASE):
        problemas.append('Dom√≠nio possivelmente inv√°lido')

    # Verificar espa√ßos
    if ' ' in url_str:
        problemas.append('Cont√©m espa√ßos')
    if url_str.strip() != url_str:
        problemas.append('Espa√ßos extras')

    return problemas if problemas else ['OK']

df['Problemas_URL'] = df['URL da empresa'].apply(identificar_problemas_url)

# Contar problemas
todos_problemas = [problema for sublist in df['Problemas_URL'] for problema in sublist]
print(f"\n‚ö†Ô∏è  Problemas identificados:")
print(pd.Series(todos_problemas).value_counts())

# 3. Extrair componentes das URLs
def extrair_componentes_url(url):
    if pd.isna(url) or url == '':
        return None, None, None

    try:
        parsed = urlparse(url)
        dominio = parsed.netloc.replace('www.', '')
        caminho = parsed.path
        extensao = url.split('.')[-1].lower() if '.' in url else None

        return dominio, caminho, extensao
    except:
        return None, None, None

# Extrair componentes
componentes = df['URL da empresa'].apply(extrair_componentes_url)
df['Dominio'] = componentes.apply(lambda x: x[0] if x else None)
df['Caminho_URL'] = componentes.apply(lambda x: x[1] if x else None)
df['Extensao_URL'] = componentes.apply(lambda x: x[2] if x else None)

print(f"\nüåê Componentes extra√≠dos:")
print(f"Dom√≠nios extra√≠dos: {df['Dominio'].notnull().sum()}")
print(f"Extens√µes √∫nicas: {df['Extensao_URL'].nunique()}")

# 4. An√°lise de dom√≠nios mais comuns
print(f"\nüè¢ Top 10 dom√≠nios mais comuns:")
if df['Dominio'].notnull().any():
    print(df['Dominio'].value_counts().head(10))

# 5. Verificar URLs v√°lidas
def verificar_url_valida(url):
    if pd.isna(url) or url == '':
        return False

    url_str = str(url)
    try:
        parsed = urlparse(url_str)
        return bool(parsed.netloc) and '.' in parsed.netloc
    except:
        return False

df['URL_Valida'] = df['URL da empresa'].apply(verificar_url_valida)

print(f"\n‚úÖ URLs v√°lidas: {df['URL_Valida'].sum()}")
print(f"‚ùå URLs inv√°lidas: {len(df) - df['URL_Valida'].sum() - df['URL da empresa'].isnull().sum()}")

# 6. Identificar padr√µes de URLs
def classificar_tipo_url(url):
    if pd.isna(url) or url == '':
        return 'Vazio'

    url_str = str(url).lower()

    if 'linkedin.com' in url_str:
        return 'LinkedIn'
    elif 'facebook.com' in url_str:
        return 'Facebook'
    elif 'twitter.com' in url_str or 'x.com' in url_str:
        return 'Twitter/X'
    elif 'github.com' in url_str:
        return 'GitHub'
    elif 'youtube.com' in url_str:
        return 'YouTube'
    elif 'http' in url_str:
        return 'Website Corporativo'
    else:
        return 'Outro'

df['Tipo_URL'] = df['URL da empresa'].apply(classificar_tipo_url)

print(f"\nüîó Tipos de URLs:")
print(df['Tipo_URL'].value_counts())

# 7. Cruzamento com nome da empresa
def verificar_consistencia_empresa_url(row):
    if pd.isna(row['Nome da empresa']) or pd.isna(row['Dominio']):
        return 'Dados incompletos'

    nome_empresa = str(row['Nome da empresa']).lower()
    dominio = str(row['Dominio']).lower()

    # Verificar se o nome da empresa aparece no dom√≠nio
    palavras_nome = nome_empresa.split()
    for palavra in palavras_nome:
        if len(palavra) > 3 and palavra in dominio:
            return 'Consistente'

    return 'Inconsistente'

df['Consistencia_Empresa_URL'] = df.apply(verificar_consistencia_empresa_url, axis=1)

print(f"\nüîç Consist√™ncia entre Empresa e URL:")
print(df['Consistencia_Empresa_URL'].value_counts())

# 8. Mostrar exemplos problem√°ticos
print(f"\nüéØ Exemplos de valores problem√°ticos:")
problemas_graves = df[df['Problemas_URL'].apply(lambda x: 'Caracteres inv√°lidos' in x or 'Dom√≠nio possivelmente inv√°lido' in x)]
if not problemas_graves.empty:
    print(problemas_graves[['URL da empresa', 'Problemas_URL']].head(5).to_string())

# Mostrar inconsist√™ncias
inconsistentes = df[df['Consistencia_Empresa_URL'] == 'Inconsistente']
print(f"\nüîç Exemplos de inconsist√™ncias:")
if not inconsistentes.empty:
    print(inconsistentes[['Nome da empresa', 'Dominio', 'URL da empresa']].head(5).to_string())

# 9. Estat√≠sticas finais
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"Total de registros: {len(df)}")
print(f"Taxa de preenchimento: {(len(df) - df['URL da empresa'].isnull().sum()) / len(df) * 100:.1f}%")
print(f"URLs √∫nicas: {df['URL da empresa'].nunique()}")
print(f"Problemas identificados: {len(df[df['Problemas_URL'].apply(lambda x: 'OK' not in x)])}")
print(f"Inconsist√™ncias com nome da empresa: {len(inconsistentes)}")

import pandas as pd
import re
from urllib.parse import urlparse, urlunparse

def padronizar_url_empresa(url):
    if pd.isna(url) or url == '':
        return None

    url_str = str(url).strip()

    # 1. Adicionar protocolo se faltando
    if not url_str.startswith(('http://', 'https://')):
        if url_str.startswith('www.'):
            url_str = 'https://' + url_str
        else:
            url_str = 'https://' + url_str

    # 2. Garantir HTTPS como padr√£o
    url_str = url_str.replace('http://', 'https://')

    try:
        # 3. Parse e reconstru√ß√£o da URL
        parsed = urlparse(url_str)

        # 4. Padronizar dom√≠nio (min√∫sculas, sem www)
        dominio = parsed.netloc.lower().replace('www.', '')

        # 5. Remover paths desnecess√°rios para valida√ß√£o
        caminho = parsed.path.rstrip('/') if parsed.path != '/' else ''

        # 6. Reconstruir URL padronizada
        url_padronizada = urlunparse(('https', dominio, caminho, '', '', ''))

        return url_padronizada

    except Exception as e:
        print(f"Erro ao processar URL: {url_str} - {e}")
        return None

def validar_dominio_empresa(row):
    """Validar se o dom√≠nio corresponde ao nome da empresa"""
    if pd.isna(row['URL_Padronizada']) or pd.isna(row['Nome da empresa']):
        return False

    try:
        dominio = urlparse(row['URL_Padronizada']).netloc.lower()
        nome_empresa = str(row['Nome da empresa']).lower()

        # Remover sufixos corporativos e caracteres especiais
        nome_clean = re.sub(r'[^\w]', '', nome_empresa)
        dominio_clean = re.sub(r'[^\w]', '', dominio.split('.')[0])

        # Verificar se o nome da empresa aparece no dom√≠nio
        return nome_clean in dominio_clean or dominio_clean in nome_clean

    except:
        return False

# Aplicar padroniza√ß√£o
df['URL_Padronizada'] = df['URL da empresa'].apply(padronizar_url_empresa)

# Validar consist√™ncia
df['URL_Consistente'] = df.apply(validar_dominio_empresa, axis=1)

# Extrair dom√≠nio padronizado
df['Dominio_Padronizado'] = df['URL_Padronizada'].apply(
    lambda x: urlparse(x).netloc if pd.notna(x) else None
)

# An√°lise dos resultados
print("‚úÖ Resultados da padroniza√ß√£o:")
print(f"URLs padronizadas: {df['URL_Padronizada'].notnull().sum()}")
print(f"URLs consistentes: {df['URL_Consistente'].sum()}")
print(f"Melhoria na consist√™ncia: {df['URL_Consistente'].sum() - 814}")

# Identificar URLs ainda problem√°ticas
df['Problemas_Resolvidos'] = df['URL_Padronizada'].apply(
    lambda x: 'OK' if pd.notna(x) and len(x) > 10 else 'Ainda problem√°tica'
)

print(f"\nüìä Status ap√≥s padroniza√ß√£o:")
print(df['Problemas_Resolvidos'].value_counts())

# Mostrar exemplos de corre√ß√£o
print(f"\nüéØ Exemplos de URLs corrigidas:")
exemplos = df[['URL da empresa', 'URL_Padronizada', 'URL_Consistente']].head(10)
print(exemplos.to_string(index=False))

# Salvar an√°lise
df.to_csv('Base_Dados_Exercicio_01_url_empresa.csv', index=False)
print(f"\nüíæ An√°lise salva em 'Base_Dados_Exercicio_01_url_empresa.csv'")

import pandas as pd
import numpy as np
import re

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_url_empresa.csv')

print("=== AN√ÅLISE DA COLUNA 'Empresa - redes sociais' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Empresa - redes sociais'].isnull().sum()}")
print(f"Valores vazios/em branco: {(df['Empresa - redes sociais'] == '').sum()}")
print(f"Valores √∫nicos: {df['Empresa - redes sociais'].nunique()}")

# Verificar primeiros valores
print("\nüìã Primeiros 20 valores:")
print(df['Empresa - redes sociais'].head(20))

# Verificar √∫ltimos 20 valores
print("\nüìã √öltimos 20 valores:")
print(df['Empresa - redes sociais'].tail(20))

# An√°lise detalhada
print("\n=== AN√ÅLISE DETALHADA ===")

# 1. Distribui√ß√£o geral das redes sociais
print("üìä Distribui√ß√£o geral:")
redes_sociais_counts = df['Empresa - redes sociais'].value_counts()
print(redes_sociais_counts.head(15))  # Top 15

# 2. Identificar tipos de redes sociais
def classificar_tipo_rede_social(url):
    if pd.isna(url) or url == '':
        return 'Vazio'

    url_str = str(url).lower()

    if 'linkedin.com' in url_str:
        return 'LinkedIn'
    elif 'facebook.com' in url_str:
        return 'Facebook'
    elif 'twitter.com' in url_str or 'x.com' in url_str:
        return 'Twitter/X'
    elif 'instagram.com' in url_str:
        return 'Instagram'
    elif 'youtube.com' in url_str:
        return 'YouTube'
    elif 'github.com' in url_str:
        return 'GitHub'
    elif 'tiktok.com' in url_str:
        return 'TikTok'
    elif 'pinterest.com' in url_str:
        return 'Pinterest'
    elif 'http' in url_str:
        return 'Outra Rede Social'
    else:
        return 'Texto/Nome'

df['Tipo_Rede_Social'] = df['Empresa - redes sociais'].apply(classificar_tipo_rede_social)

print(f"\nüîó Tipos de redes sociais identificadas:")
print(df['Tipo_Rede_Social'].value_counts())

# 3. Identificar problemas
def identificar_problemas_rede_social(url):
    if pd.isna(url) or url == '':
        return ['Vazio']

    problemas = []
    url_str = str(url).strip()

    if len(url_str) < 5:
        problemas.append('Muito curto')
    if len(url_str) > 200:
        problemas.append('Muito longo')
    if ' ' in url_str and 'http' not in url_str:
        problemas.append('Espa√ßos em URL')
    if re.search(r'[<>{}|\\^~\[\]]', url_str):
        problemas.append('Caracteres inv√°lidos')
    if url_str.strip() != url_str:
        problemas.append('Espa√ßos extras')

    return problemas if problemas else ['OK']

df['Problemas_Rede_Social'] = df['Empresa - redes sociais'].apply(identificar_problemas_rede_social)

# Contar problemas
todos_problemas = [problema for sublist in df['Problemas_Rede_Social'] for problema in sublist]
print(f"\n‚ö†Ô∏è  Problemas identificados:")
print(pd.Series(todos_problemas).value_counts())

# 4. Extrair informa√ß√µes das URLs
def extrair_info_rede_social(url):
    if pd.isna(url) or url == '':
        return None, None

    url_str = str(url)

    # Extrair nome de usu√°rio/perfil quando poss√≠vel
    if 'linkedin.com/company/' in url_str:
        match = re.search(r'linkedin\.com/company/([^/?]+)', url_str)
        if match:
            return 'LinkedIn Company', match.group(1)
    elif 'linkedin.com/in/' in url_str:
        match = re.search(r'linkedin\.com/in/([^/?]+)', url_str)
        if match:
            return 'LinkedIn Profile', match.group(1)
    elif 'facebook.com/' in url_str:
        match = re.search(r'facebook\.com/([^/?]+)', url_str)
        if match:
            return 'Facebook', match.group(1)
    elif 'twitter.com/' in url_str:
        match = re.search(r'twitter\.com/([^/?]+)', url_str)
        if match:
            return 'Twitter', match.group(1)

    return None, None

# Aplicar extra√ß√£o
info_extraida = df['Empresa - redes sociais'].apply(extrair_info_rede_social)
df['Tipo_Perfil_RS'] = info_extraida.apply(lambda x: x[0] if x else None)
df['Usuario_Perfil_RS'] = info_extraida.apply(lambda x: x[1] if x else None)

print(f"\nüë§ Informa√ß√µes extra√≠das:")
print(f"Perfis identificados: {df['Tipo_Perfil_RS'].notnull().sum()}")
print(f"Usu√°rios extra√≠dos: {df['Usuario_Perfil_RS'].notnull().sum()}")

# 5. Mostrar exemplos problem√°ticos
print(f"\nüéØ Exemplos de valores problem√°ticos:")
problemas_graves = df[df['Problemas_Rede_Social'].apply(lambda x: 'Caracteres inv√°lidos' in x or 'Muito curto' in x)]
if not problemas_graves.empty:
    print(problemas_graves[['Empresa - redes sociais', 'Problemas_Rede_Social']].head(5).to_string())

# 6. Estat√≠sticas finais
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"Total de registros: {len(df)}")
print(f"Taxa de preenchimento: {(len(df) - df['Empresa - redes sociais'].isnull().sum()) / len(df) * 100:.1f}%")
print(f"Redes sociais √∫nicas: {df['Empresa - redes sociais'].nunique()}")
print(f"Problemas identificados: {len(df[df['Problemas_Rede_Social'].apply(lambda x: 'OK' not in x)])}")

# 7. Salvar an√°lise (apenas com colunas adicionais desta an√°lise)
colunas_manter = list(df.columns)  # Manter todas as colunas existentes

import pandas as pd
import numpy as np
import re
from urllib.parse import urlparse

# Carregar a base
df = pd.read_csv('Base_Dados_Exercicio_01_url_empresa.csv')

print("=== PADRONIZA√á√ÉO AVAN√áADA - EMPRESA REDES SOCIAIS ===")

# Fun√ß√£o completa de padroniza√ß√£o
def padronizar_rede_social(url):
    if pd.isna(url) or str(url).strip() == '':
        return np.nan, np.nan, np.nan, np.nan, 'Nulo'

    url_str = str(url).strip()

    # Padroniza√ß√£o b√°sica da URL
    if not url_str.startswith(('http://', 'https://')):
        url_str = 'https://' + url_str
    elif url_str.startswith('http://'):
        url_str = url_str.replace('http://', 'https://')

    # Remover par√¢metros e fragmentos
    url_clean = url_str.split('?')[0].split('#')[0]

    # Extrair informa√ß√µes
    company_id = None
    company_slug = None
    tipo_rede = 'Outra'
    status = 'OK'

    # An√°lise do LinkedIn
    if 'linkedin.com' in url_clean:
        tipo_rede = 'LinkedIn'

        # Extrair ID da empresa
        id_match = re.search(r'company/(\d+)(?:/|$)', url_clean)
        if id_match:
            company_id = id_match.group(1)
            status = 'URL_Completa'
        else:
            # Extrair slug da empresa
            slug_match = re.search(r'company/([^/?]+)(?:/|$)', url_clean)
            if slug_match:
                company_slug = slug_match.group(1)
                status = 'URL_Slug'
            else:
                status = 'URL_Incompleta'

    # Verificar outros tipos de redes sociais
    elif 'facebook.com' in url_clean:
        tipo_rede = 'Facebook'
    elif 'twitter.com' in url_clean or 'x.com' in url_clean:
        tipo_rede = 'Twitter'
    elif 'instagram.com' in url_clean:
        tipo_rede = 'Instagram'

    return url_clean, company_id, company_slug, tipo_rede, status

# Aplicar padroniza√ß√£o
resultados = df['Empresa - redes sociais'].apply(padronizar_rede_social)

# Criar novas colunas
df['URL_Redes_Sociais_Padronizada'] = [r[0] for r in resultados]
df['ID_Company_LinkedIn'] = [r[1] for r in resultados]
df['Slug_Company_LinkedIn'] = [r[2] for r in resultados]
df['Tipo_Rede_Social'] = [r[3] for r in resultados]
df['Status_URL'] = [r[4] for r in resultados]

# M√©tricas de qualidade
df['URL_Valida'] = df['URL_Redes_Sociais_Padronizada'].notna()
df['Possui_ID'] = df['ID_Company_LinkedIn'].notna()
df['Possui_Slug'] = df['Slug_Company_LinkedIn'].notna()

# Estat√≠sticas
print(f"üìä ESTAT√çSTICAS DE PADRONIZA√á√ÉO:")
print(f"Total de URLs: {len(df)}")
print(f"URLs padronizadas: {df['URL_Valida'].sum()}")
print(f"LinkedIn IDs extra√≠dos: {df['Possui_ID'].sum()}")
print(f"LinkedIn Slugs extra√≠dos: {df['Possui_Slug'].sum()}")
print(f"Tipo predominante: {df['Tipo_Rede_Social'].value_counts().idxmax()}")

print(f"\nüîç DISTRIBUI√á√ÉO DOS STATUS:")
print(df['Status_URL'].value_counts())

print(f"\nüéØ AMOSTRA DOS RESULTADOS:")
amostra = df[['Empresa - redes sociais', 'URL_Redes_Sociais_Padronizada',
              'ID_Company_LinkedIn', 'Tipo_Rede_Social', 'Status_URL']].head(10)
print(amostra.to_string())

# Salvar resultados
df.to_csv('Base_Dados_Exercicio_01_redes_sociais_empresa.csv', index=False)
print(f"\nüíæ Arquivo salvo: 'Base_Dados_Exercicio_01_redes_sociais_empresa.csv'")
print("‚úÖ Padroniza√ß√£o conclu√≠da com sucesso!")

import pandas as pd
import numpy as np

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_redes_sociais_empresa.csv')

print("=== AN√ÅLISE DA COLUNA 'Tamanho da empresa' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Tamanho da empresa'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Tamanho da empresa'].nunique()}")
print(f"\nValores √∫nicos encontrados:")
print(df['Tamanho da empresa'].value_counts())

# Fun√ß√£o para extrair e padronizar os valores
def analisar_tamanho_empresa(valor):
    if pd.isna(valor):
        return np.nan, np.nan, np.nan, 'Nulo'

    valor_str = str(valor).strip()

    # Caso especial: 10001+
    if valor_str == '10001+':
        return 10001, None, 10001, 'Enterprise'

    # Caso especial: valores com "+"
    elif '+' in valor_str:
        try:
            min_val = int(valor_str.replace('+', ''))
            return min_val, None, min_val, 'Grande_Scale'
        except:
            return np.nan, np.nan, np.nan, 'Invalido'

    # Caso padr√£o: intervalo "min-max"
    elif '-' in valor_str:
        try:
            partes = valor_str.split('-')
            min_val = int(partes[0].strip())
            max_val = int(partes[1].strip())

            # Classificar por tamanho
            if max_val <= 10:
                categoria = 'Pequena'
            elif max_val <= 50:
                categoria = 'Pequena-Media'
            elif max_val <= 200:
                categoria = 'Media'
            elif max_val <= 500:
                categoria = 'Media-Grande'
            elif max_val <= 1000:
                categoria = 'Grande'
            elif max_val <= 5000:
                categoria = 'Muito_Grande'
            else:
                categoria = 'Enterprise'

            return min_val, max_val, (min_val + max_val) / 2, categoria

        except:
            return np.nan, np.nan, np.nan, 'Invalido'

    # Tentar converter valor √∫nico
    else:
        try:
            valor_num = int(valor_str)
            if valor_num <= 10:
                categoria = 'Pequena'
            elif valor_num <= 50:
                categoria = 'Pequena-Media'
            elif valor_num <= 200:
                categoria = 'Media'
            elif valor_num <= 500:
                categoria = 'Media-Grande'
            elif valor_num <= 1000:
                categoria = 'Grande'
            elif valor_num <= 5000:
                categoria = 'Muito_Grande'
            else:
                categoria = 'Enterprise'

            return valor_num, valor_num, valor_num, categoria

        except:
            return np.nan, np.nan, np.nan, 'Invalido'

# Aplicar an√°lise
resultados = df['Tamanho da empresa'].apply(analisar_tamanho_empresa)

# Criar novas colunas
df['Tamanho_Min'] = [r[0] for r in resultados]
df['Tamanho_Max'] = [r[1] for r in resultados]
df['Tamanho_Medio'] = [r[2] for r in resultados]
df['Categoria_Tamanho'] = [r[3] for r in resultados]

# An√°lise estat√≠stica
print(f"\nüìä ESTAT√çSTICAS DETALHADAS:")
print(f"Valores nulos: {df['Tamanho_Min'].isnull().sum()}")
print(f"Valores inv√°lidos: {(df['Categoria_Tamanho'] == 'Invalido').sum()}")

print(f"\nüìà DISTRIBUI√á√ÉO POR CATEGORIA:")
print(df['Categoria_Tamanho'].value_counts())

print(f"\nüî¢ ESTAT√çSTICAS NUM√âRICAS:")
print(f"M√≠nimo do tamanho m√≠nimo: {df['Tamanho_Min'].min()}")
print(f"M√°ximo do tamanho m√≠nimo: {df['Tamanho_Min'].max()}")
print(f"M√©dia do tamanho m√©dio: {df['Tamanho_Medio'].mean():.1f}")
print(f"Mediana do tamanho m√©dio: {df['Tamanho_Medio'].median()}")

# Verificar valores problem√°ticos
valores_invalidos = df[df['Categoria_Tamanho'] == 'Invalido']
if not valores_invalidos.empty:
    print(f"\n‚ö†Ô∏è  VALORES PROBLEM√ÅTICOS:")
    print(valores_invalidos[['Tamanho da empresa', 'Categoria_Tamanho']].head())

# Mostrar exemplos de cada categoria
print(f"\nüéØ EXEMPLOS POR CATEGORIA:")
for categoria in df['Categoria_Tamanho'].unique():
    if pd.notna(categoria):
        exemplo = df[df['Categoria_Tamanho'] == categoria].iloc[0]
        print(f"{categoria}: {exemplo['Tamanho da empresa']} ‚Üí Min:{exemplo['Tamanho_Min']}, Max:{exemplo['Tamanho_Max']}")

# Rela√ß√£o com a coluna Classifica√ß√£o existente
print(f"\nüîó RELA√á√ÉO COM COLUNA 'Classifica√ß√£o':")
if 'Classifica√ß√£o' in df.columns:
    cross_tab = pd.crosstab(df['Categoria_Tamanho'], df['Classifica√ß√£o'], margins=True)
    print(cross_tab)


print("=== PADRONIZA√á√ÉO DA COLUNA 'Tamanho da empresa' ===")

# 1. CORRIGIR VALORES "Self" - inferir com base em outras informa√ß√µes
def corrigir_valor_self(row):
    if row['Tamanho da empresa'] == 'Self':
        # Tentar inferir pelo setor ou tipo de empresa
        if pd.notna(row['Setor da empresa']):
            setor = str(row['Setor da empresa']).lower()
            if any(word in setor for word in ['consultoria', 'freelancer', 'independente', 'individual']):
                return '1-10'  # Pequeno neg√≥cio/consultor individual
        return '1-10'  # Default para pequeno
    return row['Tamanho da empresa']

df['Tamanho da empresa'] = df.apply(corrigir_valor_self, axis=1)

# 2. PREENCHER VALORES NULOS - estrat√©gia inteligente
def preencher_nulos_tamanho(row):
    if pd.isna(row['Tamanho da empresa']):
        # Usar a classifica√ß√£o existente como guia
        classificacao = row['Classifica√ß√£o']
        if classificacao == 'Pequena':
            return '1-10'
        elif classificacao == 'M√©dia':
            return '51-200'
        elif classificacao == 'Grande':
            return '501-1000'
        elif classificacao == 'Muito grande':
            return '1001-5000'
        elif classificacao == 'Enorme':
            return '5001-10000'
        elif classificacao == 'Enterprise':
            return '10001+'
    return row['Tamanho da empresa']

df['Tamanho da empresa'] = df.apply(preencher_nulos_tamanho, axis=1)

# 3. CRIAR COLUNA PADRONIZADA COM CATEGORIAS CONSISTENTES
mapeamento_categorias = {
    '1-10': 'Pequena',
    '11-50': 'Pequena-M√©dia',
    '51-200': 'M√©dia',
    '201-500': 'M√©dia-Grande',
    '501-1000': 'Grande',
    '1001-5000': 'Muito Grande',
    '5001-10000': 'Enorme',
    '10001+': 'Enterprise'
}

df['Tamanho_Empresa_Padronizado'] = df['Tamanho da empresa'].map(mapeamento_categorias)

# 4. GARANTIR CONSIST√äNCIA COM A COLUNA CLASSIFICA√á√ÉO
# Verificar e corrigir inconsist√™ncias
inconsistencias = df[df['Tamanho_Empresa_Padronizado'] != df['Classifica√ß√£o']]
print(f"Inconsist√™ncias encontradas: {len(inconsistencias)}")

# Priorizar a classifica√ß√£o existente (que parece mais confi√°vel)
df['Tamanho_Empresa_Padronizado'] = df['Classifica√ß√£o']

# 5. CRIAR COLUNAS NUM√âRICAS PARA AN√ÅLISE
def extrair_valores_numericos(tamanho):
    if pd.isna(tamanho):
        return np.nan, np.nan

    if tamanho == '10001+':
        return 10001, None

    if '-' in str(tamanho):
        min_val, max_val = map(int, tamanho.split('-'))
        return min_val, max_val

    return np.nan, np.nan

df[['Tamanho_Min', 'Tamanho_Max']] = pd.DataFrame(
    df['Tamanho da empresa'].apply(extrair_valores_numericos).tolist(),
    index=df.index
)

# 6. RELAT√ìRIO FINAL
print(f"\n‚úÖ PADRONIZA√á√ÉO CONCLU√çDA:")
print(f"Valores 'Self' corrigidos: {(df['Tamanho da empresa'] == '1-10').sum() - 83}")
print(f"Valores nulos preenchidos: {12 - df['Tamanho da empresa'].isnull().sum()}")
print(f"Valores √∫nicos finais: {df['Tamanho da empresa'].nunique()}")

print(f"\nüìä DISTRIBUI√á√ÉO PADRONIZADA:")
print(df['Tamanho_Empresa_Padronizado'].value_counts())



# Salvar resultados
df.to_csv('Base_Dados_Exercicio_01_tamanho_empresa.csv', index=False)
print(f"\nüíæ Arquivo salvo: 'Base_Dados_Exercicio_01_tamanho_empresa.csv'")

import pandas as pd
import numpy as np
import re


# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_tamanho_empresa.csv')

print("=== AN√ÅLISE DA COLUNA 'Localiza√ß√£o da empresa' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Localiza√ß√£o da empresa'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Localiza√ß√£o da empresa'].nunique()}")

# Examinar amostra dos dados
print(f"\nüìã PRIMEIROS 20 VALORES:")
print(df['Localiza√ß√£o da empresa'].head(20))

print(f"\nüìã √öLTIMOS 20 VALORES:")
print(df['Localiza√ß√£o da empresa'].tail(20))

# Analisar estrutura dos dados
print(f"\nüîç AN√ÅLISE DA ESTRUTURA:")

# Verificar padr√£o de formata√ß√£o
def analisar_formato(localizacao):
    if pd.isna(localizacao):
        return 'Nulo'

    loc_str = str(localizacao)
    partes = loc_str.split(',')

    if len(partes) == 3:
        return 'Formato_Completo'
    elif len(partes) == 2:
        return 'Formato_Parcial'
    elif len(partes) == 1:
        return 'Formato_Simples'
    else:
        return 'Formato_Complexo'

df['Formato_Localizacao'] = df['Localiza√ß√£o da empresa'].apply(analisar_formato)
print("Distribui√ß√£o dos formatos:")
print(df['Formato_Localizacao'].value_counts())

# Extrair componentes
def extrair_componentes(localizacao):
    if pd.isna(localizacao):
        return np.nan, np.nan, np.nan

    loc_str = str(localizacao).strip()
    partes = [parte.strip() for parte in loc_str.split(',')]

    cidade = partes[0] if len(partes) > 0 else np.nan
    estado = partes[1] if len(partes) > 1 else np.nan
    pais = partes[2] if len(partes) > 2 else np.nan

    return cidade, estado, pais

# Aplicar extra√ß√£o
componentes = df['Localiza√ß√£o da empresa'].apply(extrair_componentes)
df['Cidade_empresa'] = [comp[0] for comp in componentes]
df['Estado_empresa'] = [comp[1] for comp in componentes]
df['Pais_empresa'] = [comp[2] for comp in componentes]

# Verificar consist√™ncia com outras colunas de localiza√ß√£o
print(f"\nüîó CONSIST√äNCIA COM OUTRAS COLUNAS:")

if 'Pa√≠s' in df.columns and 'Pais_empresa' in df.columns:
    inconsist√™ncias_pais = df[df['Pa√≠s'] != df['Pais_empresa']]
    print(f"Inconsist√™ncias Pa√≠s vs Pais_empresa: {len(inconsist√™ncias_pais)}")

# Analisar valores √∫nicos de cada componente
print(f"\nüåç AN√ÅLISE DOS COMPONENTES:")

print(f"Cidades √∫nicas: {df['Cidade_empresa'].nunique()}")
print(f"Estados √∫nicos: {df['Estado_empresa'].nunique()}")
print(f"Pa√≠ses √∫nicos: {df['Pais_empresa'].nunique()}")

print(f"\nüèôÔ∏è TOP 10 CIDADES:")
print(df['Cidade_empresa'].value_counts().head(10))

print(f"\nüó∫Ô∏è TOP 10 ESTADOS:")
print(df['Estado_empresa'].value_counts().head(10))

print(f"\nüåé TOP 10 PA√çSES:")
print(df['Pais_empresa'].value_counts().head(10))

# Identificar problemas comuns
def identificar_problemas(localizacao):
    if pd.isna(localizacao):
        return ['Nulo']

    problemas = []
    loc_str = str(localizacao)

    if loc_str.strip() != loc_str:
        problemas.append('Espa√ßos_extras')
    if '  ' in loc_str:
        problemas.append('Espa√ßos_duplos')
    if loc_str.lower() != loc_str and loc_str.upper() != loc_str:
        problemas.append('Capitaliza√ß√£o_inconsistente')
    if len(loc_str.split(',')) != 3:
        problemas.append('Formato_incompleto')

    return problemas if problemas else ['OK']

df['Problemas_Localizacao'] = df['Localiza√ß√£o da empresa'].apply(identificar_problemas)

# Contar problemas
todos_problemas = [prob for sublist in df['Problemas_Localizacao'] for prob in sublist]
print(f"\n‚ö†Ô∏è PROBLEMAS IDENTIFICADOS:")
print(pd.Series(todos_problemas).value_counts())

# Mostrar exemplos problem√°ticos
problemas_graves = df[df['Problemas_Localizacao'].apply(lambda x: 'Formato_incompleto' in x)]
if not problemas_graves.empty:
    print(f"\nüéØ EXEMPLOS DE FORMATO INCOMPLETO:")
    print(problemas_graves[['Localiza√ß√£o da empresa', 'Problemas_Localizacao']].head(5))

# Estat√≠sticas finais
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"Taxa de preenchimento: {(len(df) - df['Localiza√ß√£o da empresa'].isnull().sum()) / len(df) * 100:.1f}%")
print(f"Formato completo (Cidade, Estado, Pa√≠s): {(df['Formato_Localizacao'] == 'Formato_Completo').sum()}")
print(f"Valores com problemas: {len(df[df['Problemas_Localizacao'].apply(lambda x: 'OK' not in x)])}")



print("=== PADRONIZA√á√ÉO DA COLUNA 'Localiza√ß√£o da empresa' ===")

# 1. DICION√ÅRIOS DE PADRONIZA√á√ÉO
mapeamento_paises = {
    'Lithuania': 'Litu√¢nia',
    'Germany': 'Alemanha',
    'Spain': 'Espanha',
    'United Kingdom': 'Reino Unido',
    'France': 'Fran√ßa',
    'Portugal': 'Portugal',
    'Poland': 'Pol√¥nia',
    'Belgium': 'B√©lgica',
    'Ireland': 'Irlanda',
    'Brazil': 'Brasil',
    'Netherlands': 'Holanda',
    'Italy': 'It√°lia',
    'Switzerland': 'Su√≠√ßa',
    'Luxembourg': 'Luxemburgo',
    'Austria': '√Åustria',
    'Czech Republic': 'Rep√∫blica Tcheca'
}

mapeamento_estados = {
    '√éle-de-France': 'Ilha de Fran√ßa',
    'Bavaria': 'Baviera',
    'North Rhine-Westphalia': 'Ren√¢nia do Norte-Vestf√°lia',
    'Baden-W√ºrttemberg': 'Baden-W√ºrttemberg',
    'Community of Madrid': 'Comunidade de Madrid',
    'Catalonia': 'Catalunha',
    'England': 'Inglaterra',
    'Lisbon': 'Lisboa',
    'Hesse': 'Hessen',
    'Principality of Asturias': 'Ast√∫rias',
    'Vilniaus': 'Vilnius',
    'Ma≈Çopolskie': 'Pequena Pol√¥nia',
    'Pomorskie': 'Pomer√¢nia',
    'Dolno≈õlƒÖskie': 'Baixa Sil√©sia'
}

# 2. FUN√á√ÉO DE PADRONIZA√á√ÉO COMPLETA
def padronizar_localizacao(localizacao):
    if pd.isna(localizacao):
        return np.nan, np.nan, np.nan, np.nan

    # Limpeza b√°sica
    loc_str = str(localizacao).strip()
    loc_str = re.sub(r'\s+', ' ', loc_str)  # Remover espa√ßos m√∫ltiplos

    # Dividir em componentes
    partes = [parte.strip() for parte in loc_str.split(',')]

    # Preencher componentes faltantes
    cidade = partes[0] if len(partes) > 0 else np.nan
    estado = partes[1] if len(partes) > 1 else np.nan
    pais = partes[2] if len(partes) > 2 else np.nan

    # Se s√≥ tem 2 partes, assumir que a segunda √© o pa√≠s
    if len(partes) == 2 and pais is np.nan:
        pais = estado
        estado = np.nan

    # Padronizar pa√≠s
    if pd.notna(pais):
        pais = mapeamento_paises.get(pais, pais)
        # Capitaliza√ß√£o consistente
        pais = pais.title() if not pais.isupper() else pais

    # Padronizar estado
    if pd.notna(estado):
        estado = mapeamento_estados.get(estado, estado)
        estado = estado.title() if not estado.isupper() else estado

    # Padronizar cidade
    if pd.notna(cidade):
        cidade = cidade.title() if not cidade.isupper() else cidade
        # Corrigir caracteres especiais
        cidade = cidade.replace('√É¬≠', '√≠').replace('√É¬£', '√£').replace('√É¬°', '√°')

    # Reconstruir localiza√ß√£o padronizada
    componentes = [comp for comp in [cidade, estado, pais] if pd.notna(comp)]
    localizacao_padronizada = ', '.join(componentes)

    return localizacao_padronizada, cidade, estado, pais

# 3. APLICAR PADRONIZA√á√ÉO
resultados = df['Localiza√ß√£o da empresa'].apply(padronizar_localizacao)

# 4. CRIAR COLUNAS PADRONIZADAS
df['Localizacao_empresa_padronizada'] = [result[0] for result in resultados]
df['Cidade_empresa_padronizada'] = [result[1] for result in resultados]
df['Estado_empresa_padronizada'] = [result[2] for result in resultados]
df['Pais_empresa_padronizada'] = [result[3] for result in resultados]

# 5. CORRIGIR INCONSIST√äNCIAS COM OUTRAS COLUNAS GEOGR√ÅFICAS
def corrigir_inconsistencias(row):
    if pd.notna(row['Pa√≠s']) and pd.notna(row['Pais_empresa_padronizada']):
        if row['Pa√≠s'] != row['Pais_empresa_padronizada']:
            # Priorizar o pa√≠s da localiza√ß√£o da empresa (mais espec√≠fico)
            return row['Pais_empresa_padronizada']
    return row['Pa√≠s'] if pd.notna(row['Pa√≠s']) else row['Pais_empresa_padronizada']

df['Pais_consistente'] = df.apply(corrigir_inconsistencias, axis=1)

# 6. PREENCHER VALORES NULOS/FALTANTES
def preencher_faltantes(row):
    if pd.isna(row['Localizacao_empresa_padronizada']):
        componentes = []
        if pd.notna(row['Cidade']):
            componentes.append(row['Cidade'])
        if pd.notna(row['Estado']):
            componentes.append(row['Estado'])
        if pd.notna(row['Pais_consistente']):
            componentes.append(row['Pais_consistente'])

        if componentes:
            return ', '.join(componentes)
    return row['Localizacao_empresa_padronizada']

df['Localizacao_empresa_padronizada'] = df.apply(preencher_faltantes, axis=1)

# 7. VALIDA√á√ÉO FINAL
print(f"‚úÖ VALORES NULOS AP√ìS PADRONIZA√á√ÉO: {df['Localizacao_empresa_padronizada'].isnull().sum()}")
print(f"üåé PA√çSES √öNICOS: {df['Pais_empresa_padronizada'].nunique()}")
print(f"üèôÔ∏è CIDADES √öNICAS: {df['Cidade_empresa_padronizada'].nunique()}")

print(f"\nüìä DISTRIBUI√á√ÉO DOS PRINCIPAIS PA√çSES:")
print(df['Pais_empresa_padronizada'].value_counts().head(10))

print(f"\nüéØ EXEMPLOS ANTES E DEPOIS:")
amostra = df[['Localiza√ß√£o da empresa', 'Localizacao_empresa_padronizada']].head(10)
print(amostra.to_string())

# 8. REMOVER COLUNAS TEMPOR√ÅRIAS (opcional)
colunas_manter = [col for col in df.columns if not col.endswith('_padronizada') or col in [
    'Localizacao_empresa_padronizada',
    'Cidade_empresa_padronizada',
    'Estado_empresa_padronizada',
    'Pais_empresa_padronizada',
    'Pais_consistente'
]]

df_final = df[colunas_manter]

# 9. SALVAR
df_final.to_csv('Base_Dados_Exercicio_01_localizacao_empresa.csv', index=False)
print(f"\nüíæ Arquivo salvo: 'Base_Dados_Exercicio_01_localizacao_empresa.csv'")
print("‚úÖ Padroniza√ß√£o conclu√≠da com sucesso!")

import pandas as pd
import numpy as np

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_localizacao_empresa.csv')

print("=== AN√ÅLISE DA COLUNA 'Setor da empresa' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Setor da empresa'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Setor da empresa'].nunique()}")

# Examinar amostra dos dados
print(f"\nüìã PRIMEIROS 20 VALORES:")
print(df['Setor da empresa'].head(20))

print(f"\nüìã √öLTIMOS 20 VALORES:")
print(df['Setor da empresa'].tail(20))

# Analisar distribui√ß√£o completa
print(f"\nüìä DISTRIBUI√á√ÉO COMPLETA DOS VALORES:")
setor_counts = df['Setor da empresa'].value_counts()
print(setor_counts)

print(f"\nüîç TOP 20 SETORES MAIS COMUNS:")
print(setor_counts.head(20))

# An√°lise de valores nulos/vazios
print(f"\n‚ö†Ô∏è  AN√ÅLISE DE VALORES FALTANTES:")
print(f"Valores nulos: {df['Setor da empresa'].isnull().sum()}")
print(f"Valores vazios: {(df['Setor da empresa'] == '').sum()}")

# Identificar categorias principais
def categorizar_setor(setor):
    if pd.isna(setor) or setor == '':
        return 'N√£o Informado'

    setor_str = str(setor).lower()

    # Tecnologia e TI
    if any(palavra in setor_str for palavra in ['computer software', 'information technology', 'it services', 'software', 'technology', 'internet', 'telecommunications']):
        return 'Tecnologia & TI'

    # Consultoria
    elif any(palavra in setor_str for palavra in ['consulting', 'management consulting', 'consultoria', 'professional services']):
        return 'Consultoria'

    # Financeiro
    elif any(palavra in setor_str for palavra in ['financial services', 'banking', 'insurance', 'fintech', 'finance']):
        return 'Servi√ßos Financeiros'

    # Sa√∫de
    elif any(palavra in setor_str for palavra in ['pharmaceuticals', 'healthcare', 'medical', 'biotechnology', 'hospital']):
        return 'Sa√∫de & Farmac√™utico'

    # Manufatura & Industrial
    elif any(palavra in setor_str for palavra in ['manufacturing', 'automotive', 'industrial', 'construction', 'engineering']):
        return 'Manufatura & Industrial'

    # Varejo & Consumo
    elif any(palavra in setor_str for palavra in ['retail', 'consumer goods', 'e-commerce', 'furniture', 'apparel']):
        return 'Varejo & Consumo'

    # M√≠dia & Marketing
    elif any(palavra in setor_str for palavra in ['media', 'marketing', 'advertising', 'public relations', 'entertainment']):
        return 'M√≠dia & Marketing'

    # Educa√ß√£o
    elif any(palavra in setor_str for palavra in ['education', 'e-learning', 'training', 'research']):
        return 'Educa√ß√£o & Pesquisa'

    # Energia & Utilities
    elif any(palavra in setor_str for palavra in ['energy', 'utilities', 'oil', 'gas', 'renewable']):
        return 'Energia & Utilities'

    # Governo & ONGs
    elif any(palavra in setor_str for palavra in ['government', 'non-profit', 'ngo', 'public administration']):
        return 'Governo & ONGs'

    else:
        return 'Outros'

df['Categoria_Setor'] = df['Setor da empresa'].apply(categorizar_setor)

print(f"\nüè∑Ô∏è  CATEGORIZA√á√ÉO DOS SETORES:")
print(df['Categoria_Setor'].value_counts())

# An√°lise de granularidade
def analisar_granularidade(setor):
    if pd.isna(setor) or setor == '':
        return 'N√£o Informado'

    setor_str = str(setor)
    palavras = setor_str.split()

    if len(palavras) <= 2:
        return 'Gen√©rico'
    elif len(palavras) <= 4:
        return 'Espec√≠fico'
    else:
        return 'Muito Espec√≠fico'

df['Granularidade_Setor'] = df['Setor da empresa'].apply(analisar_granularidade)

print(f"\nüìè GRANULARIDADE DOS SETORES:")
print(df['Granularidade_Setor'].value_counts())

# Identificar problemas comuns
def identificar_problemas_setor(setor):
    if pd.isna(setor):
        return ['Nulo']
    if setor == '':
        return ['Vazio']

    problemas = []
    setor_str = str(setor)

    if setor_str.strip() != setor_str:
        problemas.append('Espa√ßos extras')
    if '  ' in setor_str:
        problemas.append('Espa√ßos m√∫ltiplos')
    if setor_str.lower() != setor_str and setor_str.upper() != setor_str:
        problemas.append('Capitaliza√ß√£o inconsistente')
    if len(setor_str) > 100:
        problemas.append('Muito longo')
    if len(setor_str) < 3:
        problemas.append('Muito curto')

    return problemas if problemas else ['OK']

df['Problemas_Setor'] = df['Setor da empresa'].apply(identificar_problemas_setor)

# Contar problemas
todos_problemas = [prob for sublist in df['Problemas_Setor'] for prob in sublist]
print(f"\n‚ö†Ô∏è  PROBLEMAS IDENTIFICADOS:")
print(pd.Series(todos_problemas).value_counts())

# Rela√ß√£o com outras colunas
print(f"\nüîó RELA√á√ÉO COM TAMANHO DA EMPRESA:")
if 'Tamanho_Empresa_Padronizado' in df.columns:
    cross_tab = pd.crosstab(df['Categoria_Setor'], df['Tamanho_Empresa_Padronizado'])
    print(cross_tab)

# Estat√≠sticas finais
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"Taxa de preenchimento: {(len(df) - df['Setor da empresa'].isnull().sum()) / len(df) * 100:.1f}%")
print(f"Setores √∫nicos: {df['Setor da empresa'].nunique()}")
print(f"Categorias principais: {df['Categoria_Setor'].nunique()}")

# Mostrar exemplos de cada categoria
print(f"\nüéØ EXEMPLOS POR CATEGORIA:")
for categoria in df['Categoria_Setor'].unique():
    exemplos = df[df['Categoria_Setor'] == categoria]['Setor da empresa'].head(3).tolist()
    print(f"{categoria}: {exemplos}")

print("=== PADRONIZA√á√ÉO DA COLUNA 'Setor da empresa' ===")

# 1. DICION√ÅRIO DE PADRONIZA√á√ÉO COMPLETO
mapeamento_setores = {
    # Tecnologia & TI
    'Computer Software': 'Software',
    'Information Technology & Services': 'Tecnologia da Informa√ß√£o & Servi√ßos',
    'Internet': 'Internet & Servi√ßos Online',
    'Computer & Network Security': 'Seguran√ßa da Informa√ß√£o',
    'Computer Games': 'Jogos Eletr√¥nicos',
    'Data Security Software Products': 'Seguran√ßa de Dados',
    'Computer Hardware': 'Hardware de Computador',
    'Technology, Information and Media': 'Tecnologia, Informa√ß√£o & M√≠dia',

    # Consultoria & Servi√ßos Profissionais
    'Management Consulting': 'Consultoria em Gest√£o',
    'Environmental Services': 'Servi√ßos Ambientais',
    'Engineering Services': 'Servi√ßos de Engenharia',
    'Technical and Vocational Training': 'Treinamento T√©cnico',

    # Financeiro
    'Financial Services': 'Servi√ßos Financeiros',
    'Venture Capital & Private Equity': 'Private Equity & Venture Capital',
    'Insurance': 'Seguros',
    'Accounting': 'Contabilidade',

    # Sa√∫de & Farmac√™utico
    'Pharmaceuticals': 'Farmac√™utico',
    'Biotechnology': 'Biotecnologia',
    'Hospital & Health Care': 'Sa√∫de & Hospitais',
    'Health, Wellness & Fitness': 'Sa√∫de & Bem-estar',

    # Manufatura & Industrial
    'Industrial Automation': 'Automa√ß√£o Industrial',
    'Electrical & Electronic Manufacturing': 'Manufatura Eletr√¥nica',
    'Machinery': 'Maquin√°rio',
    'Mechanical Or Industrial Engineering': 'Engenharia Industrial',
    'Communications Equipment Manufacturing': 'Equipamentos de Comunica√ß√£o',
    'Automotive': 'Automotivo',

    # Varejo & Consumo
    'Retail': 'Varejo',
    'Apparel & Fashion': 'Vestu√°rio & Moda',
    'Consumer Goods': 'Bens de Consumo',
    'Food Production': 'Produ√ß√£o de Alimentos',
    'Cosmetics': 'Cosm√©ticos',
    'Supermarkets': 'Supermercados',
    'Wine & Spirits': 'Vinhos & Bebidas',

    # M√≠dia & Marketing
    'Public Relations & Communications': 'Rela√ß√µes P√∫blicas & Comunica√ß√£o',
    'Marketing & Advertising': 'Marketing & Publicidade',
    'Design': 'Design',

    # Educa√ß√£o & Pesquisa
    'Research': 'Pesquisa',
    'Higher Education': 'Ensino Superior',

    # Outros
    'Luxury Goods & Jewelry': 'Produtos de Luxo & Joalheria',
    'Restaurants': 'Restaurantes',
    'Transportation/Trucking/Railroad': 'Transporte & Log√≠stica',
    'Textiles': 'T√™xtil',
    'Leisure, Travel & Tourism': 'Turismo & Lazer',
    'Services for Renewable Energy': 'Servi√ßos de Energia Renov√°vel',
    'Government Relations': 'Rela√ß√µes Governamentais',
    'Government Administration': 'Administra√ß√£o P√∫blica'
}

# 2. FUN√á√ÉO DE PADRONIZA√á√ÉO
def padronizar_setor(setor):
    if pd.isna(setor) or setor == '':
        return 'N√£o Informado'

    setor_str = str(setor).strip()

    # Aplicar mapeamento
    setor_padronizado = mapeamento_setores.get(setor_str, setor_str)

    # Capitaliza√ß√£o consistente (Title Case)
    setor_padronizado = setor_padronizado.title()

    return setor_padronizado

# 3. APLICAR PADRONIZA√á√ÉO
df['Setor_empresa_padronizado'] = df['Setor da empresa'].apply(padronizar_setor)

# 4. PREENCHER VALORES NULOS
print(f"Valores nulos antes: {df['Setor da empresa'].isnull().sum()}")
df['Setor_empresa_padronizado'] = df['Setor_empresa_padronizado'].replace('N√£o Informado', np.nan)
print(f"Valores nulos ap√≥s: {df['Setor_empresa_padronizado'].isnull().sum()}")

# 5. ATUALIZAR CATEGORIZA√á√ÉO
def categorizar_setor_padronizado(setor):
    if pd.isna(setor):
        return 'N√£o Informado'

    setor_str = str(setor).lower()

    categorias = {
        'software': 'Tecnologia & TI',
        'tecnologia da informa√ß√£o': 'Tecnologia & TI',
        'internet': 'Tecnologia & TI',
        'seguran√ßa': 'Tecnologia & TI',
        'consultoria': 'Consultoria & Servi√ßos',
        'engenharia': 'Manufatura & Industrial',
        'financeiro': 'Servi√ßos Financeiros',
        'farmac√™utico': 'Sa√∫de & Farmac√™utico',
        'biotecnologia': 'Sa√∫de & Farmac√™utico',
        'sa√∫de': 'Sa√∫de & Farmac√™utico',
        'manufatura': 'Manufatura & Industrial',
        'automotivo': 'Manufatura & Industrial',
        'varejo': 'Varejo & Consumo',
        'marketing': 'M√≠dia & Marketing',
        'publicidade': 'M√≠dia & Marketing',
        'educa√ß√£o': 'Educa√ß√£o & Pesquisa',
        'pesquisa': 'Educa√ß√£o & Pesquisa'
    }

    for palavra_chave, categoria in categorias.items():
        if palavra_chave in setor_str:
            return categoria

    return 'Outros'

df['Categoria_Setor_Padronizada'] = df['Setor_empresa_padronizado'].apply(categorizar_setor_padronizado)

# 6. ESTAT√çSTICAS FINAIS
print(f"\n‚úÖ PADRONIZA√á√ÉO CONCLU√çDA:")
print(f"Setores √∫nicos ap√≥s padroniza√ß√£o: {df['Setor_empresa_padronizado'].nunique()}")
print(f"Valores padronizados: {len(df) - df['Setor_empresa_padronizado'].isnull().sum()}")

print(f"\nüìä DISTRIBUI√á√ÉO DAS CATEGORIAS PADRONIZADAS:")
print(df['Categoria_Setor_Padronizada'].value_counts())

print(f"\nüè∑Ô∏è TOP 10 SETORES PADRONIZADOS:")
print(df['Setor_empresa_padronizado'].value_counts().head(10))

# 7. VALIDAR CONSIST√äNCIA
print(f"\nüîç COMPARA√á√ÉO ANTES/DEPOIS:")
amostra = df[['Setor da empresa', 'Setor_empresa_padronizado', 'Categoria_Setor_Padronizada']].head(15)
print(amostra.to_string())

# 8. SALVAR RESULTADOS
df.to_csv('Base_Dados_Exercicio_01_setor_empresa.csv', index=False)
print(f"\nüíæ Arquivo salvo: 'Base_Dados_Exercicio_01_setor_empresa.csv'")
print("‚úÖ Padroniza√ß√£o do setor conclu√≠da com sucesso!")

import pandas as pd
import numpy as np
import re

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_setor_empresa.csv')

print("=== AN√ÅLISE DA COLUNA 'Telefone da sede' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Telefone da sede'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Telefone da sede'].nunique()}")

# Examinar amostra dos dados
print(f"\nüìã PRIMEIROS 20 VALORES:")
print(df['Telefone da sede'].head(20))

print(f"\nüìã √öLTIMOS 20 VALORES:")
print(df['Telefone da sede'].tail(20))

# Analisar distribui√ß√£o dos valores
print(f"\nüìä DISTRIBUI√á√ÉO DOS VALORES:")
telefone_counts = df['Telefone da sede'].value_counts()
print(telefone_counts.head(15))  # Mostrar os 15 mais comuns

# An√°lise detalhada dos tipos de valores
def analisar_tipo_telefone(telefone):
    if pd.isna(telefone):
        return 'Nulo'

    tel_str = str(telefone)

    # Verificar se √© num√©rico
    if tel_str.replace('.', '').isdigit():
        return 'Num√©rico'

    # Verificar formato internacional
    if re.match(r'^\+?[\d\s\-\(\)\.]+$', tel_str):
        return 'Formato Internacional'

    # Verificar se est√° vazio/em branco
    if tel_str.strip() == '':
        return 'Vazio'

    return 'Outro Formato'

df['Tipo_Telefone'] = df['Telefone da sede'].apply(analisar_tipo_telefone)

print(f"\nüîç TIPOS DE TELEFONE IDENTIFICADOS:")
print(df['Tipo_Telefone'].value_counts())

# An√°lise de valores num√©ricos
telefones_numericos = df[df['Tipo_Telefone'] == 'Num√©rico']['Telefone da sede']
if not telefones_numericos.empty:
    print(f"\nüìû ESTAT√çSTICAS DOS TELEFONES NUM√âRICOS:")
    print(f"Quantidade: {len(telefones_numericos)}")
    print(f"Valor m√≠nimo: {telefones_numericos.astype(float).min()}")
    print(f"Valor m√°ximo: {telefones_numericos.astype(float).max()}")
    print(f"M√©dia: {telefones_numericos.astype(float).mean():.0f}")

# Identificar padr√µes de formata√ß√£o
def identificar_formato_telefone(telefone):
    if pd.isna(telefone):
        return 'Nulo'

    tel_str = str(telefone).strip()

    # Padr√µes comuns
    if re.match(r'^\d{2,3}\d{7,10}$', tel_str.replace('.', '')):
        return 'Num√©rico Sem Formata√ß√£o'
    elif re.match(r'^\+\d{1,3}\s?\d{1,4}\s?\d{4,10}$', tel_str):
        return 'Formato Internacional'
    elif re.match(r'^\(\d{2,3}\)\s?\d{4,5}\-?\d{4}$', tel_str):
        return 'Formato Nacional'
    elif '.' in tel_str and tel_str.replace('.', '').isdigit():
        return 'Num√©rico com Pontos'
    elif tel_str == '':
        return 'Vazio'

    return 'Formato Desconhecido'

df['Formato_Telefone'] = df['Telefone da sede'].apply(identificar_formato_telefone)

print(f"\nüéØ FORMATOS IDENTIFICADOS:")
print(df['Formato_Telefone'].value_counts())

# Extrair c√≥digo do pa√≠s (quando poss√≠vel)
def extrair_codigo_pais(telefone):
    if pd.isna(telefone):
        return np.nan

    tel_str = str(telefone)

    # Procurar c√≥digo internacional
    match = re.search(r'\+(\d{1,3})', tel_str)
    if match:
        return match.group(1)

    # Inferir pelo pa√≠s da empresa (se dispon√≠vel)
    if 'Pais_empresa_padronizada' in df.columns:
        pais = df.loc[df['Telefone da sede'] == telefone, 'Pais_empresa_padronizada'].iloc[0] if not df[df['Telefone da sede'] == telefone].empty else np.nan
        codigos_pais = {
            'Alemanha': '49', 'Germany': '49',
            'Reino Unido': '44', 'United Kingdom': '44',
            'Fran√ßa': '33', 'France': '33',
            'Espanha': '34', 'Spain': '34',
            'Portugal': '351', 'Portugal': '351',
            'Pol√¥nia': '48', 'Poland': '48',
            'Brasil': '55', 'Brazil': '55'
        }
        return codigos_pais.get(str(pais), np.nan)

    return np.nan

df['Codigo_Pais_Telefone'] = df['Telefone da sede'].apply(extrair_codigo_pais)

print(f"\nüåç C√ìDIGOS DE PA√çS IDENTIFICADOS:")
print(df['Codigo_Pais_Telefone'].value_counts())

# Identificar problemas
def identificar_problemas_telefone(telefone):
    if pd.isna(telefone):
        return ['Nulo']

    problemas = []
    tel_str = str(telefone).strip()

    if len(tel_str) < 5:
        problemas.append('Muito Curto')
    if len(tel_str) > 20:
        problemas.append('Muito Longo')
    if not any(char.isdigit() for char in tel_str):
        problemas.append('Sem D√≠gitos')
    if re.search(r'[a-zA-Z]', tel_str):
        problemas.append('Cont√©m Letras')
    if tel_str.strip() != tel_str:
        problemas.append('Espa√ßos Extras')

    return problemas if problemas else ['OK']

df['Problemas_Telefone'] = df['Telefone da sede'].apply(identificar_problemas_telefone)

# Contar problemas
todos_problemas = [prob for sublist in df['Problemas_Telefone'] for prob in sublist]
print(f"\n‚ö†Ô∏è  PROBLEMAS IDENTIFICADOS:")
print(pd.Series(todos_problemas).value_counts())

# An√°lise de qualidade geral
print(f"\nüìà ESTAT√çSTICAS DE QUALIDADE:")
print(f"Taxa de preenchimento: {(len(df) - df['Telefone da sede'].isnull().sum()) / len(df) * 100:.1f}%")
print(f"Telefones v√°lidos: {(df['Problemas_Telefone'].apply(lambda x: 'OK' in x)).sum()}")
print(f"Telefones problem√°ticos: {len(df) - (df['Problemas_Telefone'].apply(lambda x: 'OK' in x)).sum() - df['Telefone da sede'].isnull().sum()}")

# Rela√ß√£o com pa√≠s da empresa
if 'Pais_empresa_padronizada' in df.columns:
    print(f"\nüîó RELA√á√ÉO COM PA√çS DA EMPRESA:")
    cross_tab = pd.crosstab(df['Pais_empresa_padronizada'], df['Tipo_Telefone'])
    print(cross_tab)

# Mostrar exemplos problem√°ticos
problemas_graves = df[df['Problemas_Telefone'].apply(lambda x: any(prob in x for prob in ['Sem D√≠gitos', 'Cont√©m Letras']))]
if not problemas_graves.empty:
    print(f"\nüéØ EXEMPLOS PROBLEM√ÅTICOS:")
    print(problemas_graves[['Telefone da sede', 'Problemas_Telefone']].head(5))

# Salvar an√°lise
df.to_csv('Base_Dados_Exercicio_01_telefone_sede.csv', index=False)
print(f"\nüíæ An√°lise salva: 'Base_Dados_Exercicio_01_telefone_sede.csv'")

import pandas as pd
import numpy as np
import re

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_telefone_sede.csv')

print("=== AN√ÅLISE DA COLUNA 'Telefone' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Telefone'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Telefone'].nunique()}")

# Examinar amostra dos dados
print(f"\nüìã PRIMEIROS 20 VALORES:")
print(df['Telefone'].head(20))

print(f"\nüìã √öLTIMOS 20 VALORES:")
print(df['Telefone'].tail(20))

# Analisar distribui√ß√£o dos valores
print(f"\nüìä DISTRIBUI√á√ÉO DOS VALORES:")
telefone_counts = df['Telefone'].value_counts()
print(telefone_counts.head(15))  # Mostrar os 15 mais comuns

# An√°lise detalhada dos tipos de valores
def analisar_tipo_telefone(telefone):
    if pd.isna(telefone):
        return 'Nulo'

    tel_str = str(telefone)

    # Verificar se √© num√©rico
    if tel_str.replace('.', '').isdigit():
        return 'Num√©rico'

    # Verificar formato internacional
    if re.match(r'^\+?[\d\s\-\(\)\.]+$', tel_str):
        return 'Formato Internacional'

    # Verificar se est√° vazio/em branco
    if tel_str.strip() == '':
        return 'Vazio'

    return 'Outro Formato'

df['Tipo_Telefone_Col'] = df['Telefone'].apply(analisar_tipo_telefone)

print(f"\nüîç TIPOS DE TELEFONE IDENTIFICADOS:")
print(df['Tipo_Telefone_Col'].value_counts())

# An√°lise de valores num√©ricos
telefones_numericos = df[df['Tipo_Telefone_Col'] == 'Num√©rico']['Telefone']
if not telefones_numericos.empty:
    print(f"\nüìû ESTAT√çSTICAS DOS TELEFONES NUM√âRICOS:")
    print(f"Quantidade: {len(telefones_numericos)}")
    # Converter para float para an√°lise
    tels_float = telefones_numericos.astype(float)
    print(f"Valor m√≠nimo: {tels_float.min()}")
    print(f"Valor m√°ximo: {tels_float.max()}")
    print(f"M√©dia: {tels_float.mean():.0f}")

# Identificar padr√µes de formata√ß√£o
def identificar_formato_telefone_col(telefone):
    if pd.isna(telefone):
        return 'Nulo'

    tel_str = str(telefone).strip()

    # Padr√µes comuns
    if re.match(r'^\d{2,3}\d{7,10}$', tel_str.replace('.', '')):
        return 'Num√©rico Sem Formata√ß√£o'
    elif re.match(r'^\+\d{1,3}\s?\d{1,4}\s?\d{4,10}$', tel_str):
        return 'Formato Internacional'
    elif re.match(r'^\(\d{2,3}\)\s?\d{4,5}\-?\d{4}$', tel_str):
        return 'Formato Nacional'
    elif '.' in tel_str and tel_str.replace('.', '').isdigit():
        return 'Num√©rico com Pontos'
    elif tel_str == '':
        return 'Vazio'

    return 'Formato Desconhecido'

df['Formato_Telefone_Col'] = df['Telefone'].apply(identificar_formato_telefone_col)

print(f"\nüéØ FORMATOS IDENTIFICADOS:")
print(df['Formato_Telefone_Col'].value_counts())

# Compara√ß√£o com a coluna "Telefone da sede"
if 'Telefone_Sede_Valido' in df.columns:
    print(f"\nüîó COMPARA√á√ÉO COM 'Telefone da sede':")
    comparacao = pd.crosstab(df['Telefone_Sede_Valido'], df['Tipo_Telefone_Col'])
    print(comparacao)

# Identificar problemas
def identificar_problemas_telefone_col(telefone):
    if pd.isna(telefone):
        return ['Nulo']

    problemas = []
    tel_str = str(telefone).strip()

    if len(tel_str) < 5:
        problemas.append('Muito Curto')
    if len(tel_str) > 20:
        problemas.append('Muito Longo')
    if not any(char.isdigit() for char in tel_str):
        problemas.append('Sem D√≠gitos')
    if re.search(r'[a-zA-Z]', tel_str):
        problemas.append('Cont√©m Letras')
    if tel_str.strip() != tel_str:
        problemas.append('Espa√ßos Extras')

    return problemas if problemas else ['OK']

df['Problemas_Telefone_Col'] = df['Telefone'].apply(identificar_problemas_telefone_col)

# Contar problemas
todos_problemas = [prob for sublist in df['Problemas_Telefone_Col'] for prob in sublist]
print(f"\n‚ö†Ô∏è  PROBLEMAS IDENTIFICADOS:")
print(pd.Series(todos_problemas).value_counts())

# An√°lise de qualidade geral
print(f"\nüìà ESTAT√çSTICAS DE QUALIDADE:")
print(f"Taxa de preenchimento: {(len(df) - df['Telefone'].isnull().sum()) / len(df) * 100:.1f}%")
telefones_validos = (df['Problemas_Telefone_Col'].apply(lambda x: 'OK' in x)).sum()
print(f"Telefones v√°lidos: {telefones_validos}")
print(f"Telefones problem√°ticos: {len(df) - telefones_validos - df['Telefone'].isnull().sum()}")

# Verificar duplicidade com "Telefone da sede"
if 'Telefone da sede' in df.columns:
    print(f"\nüîç DUPLICIDADE COM 'Telefone da sede':")
    iguais = (df['Telefone'] == df['Telefone da sede']).sum()
    print(f"Valores id√™nticos: {iguais}")
    print(f"Valores diferentes: {len(df) - iguais - df['Telefone'].isnull().sum() - df['Telefone da sede'].isnull().sum()}")

# Mostrar exemplos problem√°ticos
problemas_graves = df[df['Problemas_Telefone_Col'].apply(lambda x: any(prob in x for prob in ['Sem D√≠gitos', 'Cont√©m Letras']))]
if not problemas_graves.empty:
    print(f"\nüéØ EXEMPLOS PROBLEM√ÅTICOS:")
    print(problemas_graves[['Telefone', 'Problemas_Telefone_Col']].head(5))

# An√°lise de valores √∫nicos interessantes
valores_unicos = df['Telefone'].unique()
print(f"\nüîé VALORES √öNICOS INTERESSANTES (amostra):")
for i, valor in enumerate(valores_unicos[:10]):
    if pd.notna(valor) and str(valor).strip() != '':
        print(f"  {i+1}. {valor}")

# Estat√≠sticas finais
print(f"\nüìã ESTAT√çSTICAS FINAIS:")
print(f"Total de registros: {len(df)}")
print(f"Valores preenchidos: {len(df) - df['Telefone'].isnull().sum()}")
print(f"Valores nulos: {df['Telefone'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Telefone'].nunique()}")
print(f"Taxa de preenchimento: {(len(df) - df['Telefone'].isnull().sum()) / len(df) * 100:.1f}%")


print("=== TRATAMENTO DA COLUNA 'Telefone' ===")
print("üìä RESULTADO DA AN√ÅLISE:")
print("   ‚Ä¢ 100% dos valores s√£o nulos (1027/1027)")
print("   ‚Ä¢ 0% de taxa de preenchimento")
print("   ‚Ä¢ Coluna completamente vazia")

# DECIS√ÉO: REMOVER COLUNA (n√£o cont√©m informa√ß√£o √∫til)
print(f"\nüéØ DECIS√ÉO: Remover coluna completamente vazia")

# Remover coluna e todas as colunas de an√°lise criadas
colunas_para_remover = [
    'Telefone',  # Coluna principal vazia
    'Tipo_Telefone_Col',
    'Formato_Telefone_Col',
    'Problemas_Telefone_Col'
]

# Manter apenas colunas que existem no DataFrame
colunas_para_remover = [col for col in colunas_para_remover if col in df.columns]

df = df.drop(columns=colunas_para_remover)

print(f"‚úÖ Colunas removidas: {colunas_para_remover}")

# SALVAR RESULTADO
df.to_csv('Base_Dados_Exercicio_01_telefone.csv', index=False)
print(f"\nüíæ Arquivo salvo: 'Base_Dados_Exercicio_01_telefone.csv'")

# RELAT√ìRIO FINAL
print(f"\nüìã RELAT√ìRIO FINAL:")
print(f"   ‚Ä¢ Coluna 'Telefone': REMOVIDA (100% vazia)")
print(f"   ‚Ä¢ Colunas de an√°lise removidas: {len(colunas_para_remover)}")
print(f"   ‚Ä¢ Dataset mais limpo e eficiente")
print(f"   ‚Ä¢ Foco mantido nas colunas com dados relevantes")

import pandas as pd
import numpy as np

# Carregar a base atual
df = pd.read_csv('Base_Dados_Exercicio_01_telefone.csv')

print("=== AN√ÅLISE DA COLUNA 'Classifica√ß√£o' ===")

# An√°lise inicial
print(f"Total de registros: {len(df)}")
print(f"Valores nulos: {df['Classifica√ß√£o'].isnull().sum()}")
print(f"Valores √∫nicos: {df['Classifica√ß√£o'].nunique()}")

# Examinar amostra dos dados
print(f"\nüìã PRIMEIROS 20 VALORES:")
print(df['Classifica√ß√£o'].head(20))

print(f"\nüìã √öLTIMOS 20 VALORES:")
print(df['Classifica√ß√£o'].tail(20))

# Analisar distribui√ß√£o completa
print(f"\nüìä DISTRIBUI√á√ÉO COMPLETA DOS VALORES:")
classificacao_counts = df['Classifica√ß√£o'].value_counts()
print(classificacao_counts)

# An√°lise de valores nulos/vazios
print(f"\n‚ö†Ô∏è  AN√ÅLISE DE VALORES FALTANTES:")
print(f"Valores nulos: {df['Classifica√ß√£o'].isnull().sum()}")
print(f"Valores vazios: {(df['Classifica√ß√£o'] == '').sum()}")

# Verificar consist√™ncia com Tamanho da Empresa
if 'Tamanho_Empresa_Padronizado' in df.columns:
    print(f"\nüîó CONSIST√äNCIA COM 'Tamanho_Empresa_Padronizado':")
    cross_tab = pd.crosstab(df['Classifica√ß√£o'], df['Tamanho_Empresa_Padronizado'])
    print(cross_tab)

# Identificar problemas de formata√ß√£o
def identificar_problemas_classificacao(classificacao):
    if pd.isna(classificacao):
        return ['Nulo']
    if classificacao == '':
        return ['Vazio']

    problemas = []
    class_str = str(classificacao).strip()

    if class_str.strip() != class_str:
        problemas.append('Espa√ßos extras')
    if '  ' in class_str:
        problemas.append('Espa√ßos m√∫ltiplos')
    if class_str.lower() != class_str and class_str.upper() != class_str:
        problemas.append('Capitaliza√ß√£o inconsistente')
    if len(class_str) > 50:
        problemas.append('Muito longo')

    return problemas if problemas else ['OK']

df['Problemas_Classificacao'] = df['Classifica√ß√£o'].apply(identificar_problemas_classificacao)

# Contar problemas
todos_problemas = [prob for sublist in df['Problemas_Classificacao'] for prob in sublist]
print(f"\n‚ö†Ô∏è  PROBLEMAS IDENTIFICADOS:")
print(pd.Series(todos_problemas).value_counts())

# An√°lise de rela√ß√£o com outras colunas
print(f"\nüîç RELA√á√ïES COM OUTRAS COLUNAS:")

# Com setor da empresa
if 'Categoria_Setor_Padronizada' in df.columns:
    print(f"\nüìà RELA√á√ÉO COM CATEGORIA DO SETOR:")
    cross_setor = pd.crosstab(df['Classifica√ß√£o'], df['Categoria_Setor_Padronizada'])
    print(cross_setor)

# Com tamanho da empresa (j√° analisado, mas mostrar estat√≠sticas)
if 'Tamanho_Empresa_Padronizado' in df.columns:
    print(f"\nüìä DISTRIBUI√á√ÉO POR TAMANHO:")
    tamanho_stats = df.groupby('Tamanho_Empresa_Padronizado')['Classifica√ß√£o'].value_counts()
    print(tamanho_stats)

# Estat√≠sticas de qualidade
print(f"\nüìà ESTAT√çSTICAS DE QUALIDADE:")
print(f"Taxa de preenchimento: {(len(df) - df['Classifica√ß√£o'].isnull().sum()) / len(df) * 100:.1f}%")
classificacoes_validas = (df['Problemas_Classificacao'].apply(lambda x: 'OK' in x)).sum()
print(f"Classifica√ß√µes v√°lidas: {classificacoes_validas}")
print(f"Classifica√ß√µes problem√°ticas: {len(df) - classificacoes_validas - df['Classifica√ß√£o'].isnull().sum()}")

# Mostrar exemplos de cada classifica√ß√£o
print(f"\nüéØ EXEMPLOS DE CADA CLASSIFICA√á√ÉO:")
for classificacao in df['Classifica√ß√£o'].unique():
    if pd.notna(classificacao):
        empresas_exemplo = df[df['Classifica√ß√£o'] == classificacao].head(3)
        nomes_empresas = empresas_exemplo['Nome da empresa'].tolist() if 'Nome da empresa' in df.columns else []
        print(f"   ‚Ä¢ {classificacao}: {nomes_empresas if nomes_empresas else 'Exemplos dispon√≠veis'}")

# Verificar se h√° necessidade de padroniza√ß√£o
print(f"\nüîé NECESSIDADE DE PADRONIZA√á√ÉO:")
valores_unicos = df['Classifica√ß√£o'].unique()
print(f"Valores √∫nicos encontrados: {len(valores_unicos)}")
if len(valores_unicos) <= 10:  # Se poucos valores, provavelmente j√° padronizado
    print("‚úÖ Coluna parece j√° estar padronizada")
else:
    print("‚ö†Ô∏è  Poss√≠vel necessidade de padroniza√ß√£o")



# RELAT√ìRIO FINAL
print(f"\nüìã RELAT√ìRIO FINAL DA AN√ÅLISE:")
print(f"‚Ä¢ Total de registros: {len(df)}")
print(f"‚Ä¢ Valores √∫nicos: {df['Classifica√ß√£o'].nunique()}")
print(f"‚Ä¢ Valores nulos: {df['Classifica√ß√£o'].isnull().sum()}")
print(f"‚Ä¢ Taxa de preenchimento: {(len(df) - df['Classifica√ß√£o'].isnull().sum()) / len(df) * 100:.1f}%")
print(f"‚Ä¢ Problemas identificados: {len(df) - classificacoes_validas - df['Classifica√ß√£o'].isnull().sum()}")


print("=== PADRONIZA√á√ÉO FINAL DA COLUNA 'Classifica√ß√£o' ===")

# 1. VERIFICAR SE H√Å NECESSIDADE REAL DE PADRONIZA√á√ÉO
print("üìä Status atual da coluna:")
print(f"   ‚Ä¢ Valores √∫nicos: {df['Classifica√ß√£o'].unique()}")
print(f"   ‚Ä¢ Distribui√ß√£o: \n{df['Classifica√ß√£o'].value_counts()}")

# 2. APENAS CORRIGIR CAPITALIZA√á√ÉO (Title Case)
def padronizar_capitalizacao(classificacao):
    """Aplica capitaliza√ß√£o consistente (Title Case)"""
    if pd.isna(classificacao):
        return classificacao

    # Mapeamento para corre√ß√µes espec√≠ficas
    correcoes = {
        'Muito grande': 'Muito Grande',
        'Fora da faixa': 'Fora da Faixa'
    }

    # Aplicar corre√ß√µes espec√≠ficas ou title case geral
    return correcoes.get(classificacao, classificacao.title())

df['Classifica√ß√£o_Padronizada'] = df['Classifica√ß√£o'].apply(padronizar_capitalizacao)

# 3. VERIFICAR SE HOUVE MUDAN√áAS
valores_alterados = (df['Classifica√ß√£o'] != df['Classifica√ß√£o_Padronizada']).sum()
print(f"\nüîß Corre√ß√µes aplicadas: {valores_alterados} valores")

if valores_alterados > 0:
    print("üìã Antes e depois das corre√ß√µes:")
    for original, padronizado in zip(df['Classifica√ß√£o'].unique(), df['Classifica√ß√£o_Padronizada'].unique()):
        if original != padronizado:
            print(f"   ‚Ä¢ '{original}' ‚Üí '{padronizado}'")

# 4. SUBSTITUIR COLUNA ORIGINAL (se houve mudan√ßas)
if valores_alterados > 0:
    df['Classifica√ß√£o'] = df['Classifica√ß√£o_Padronizada']
    df = df.drop(columns=['Classifica√ß√£o_Padronizada'])
    print(f"\n‚úÖ Coluna original atualizada com capitaliza√ß√£o correta")
else:
    df = df.drop(columns=['Classifica√ß√£o_Padronizada'])
    print(f"\n‚úÖ Coluna j√° estava padronizada - nenhuma altera√ß√£o necess√°ria")

# 5. CRIAR COLUNA ORDINAL PARA AN√ÅLISE NUM√âRICA
mapeamento_ordinal = {
    'Pequena': 1,
    'M√©dia': 2,
    'Grande': 3,
    'Muito Grande': 4,
    'Enorme': 5,
    'Enterprise': 6,
    'Fora da Faixa': 0  # Categoria especial
}

df['Classifica√ß√£o_Ordinal'] = df['Classifica√ß√£o'].map(mapeamento_ordinal)

# 6. VALIDAR CONSIST√äNCIA COM TAMANHO DA EMPRESA
if 'Tamanho_Empresa_Padronizado' in df.columns:
    print(f"\nüîó VALIDA√á√ÉO DE CONSIST√äNCIA:")

    # Verificar se as classifica√ß√µes fazem sentido com os tamanhos
    inconsistencias = df.groupby(['Classifica√ß√£o', 'Tamanho_Empresa_Padronizado']).size().unstack()
    print("Tabela de conting√™ncia:")
    print(inconsistencias.fillna(0).astype(int))

# 7. ESTAT√çSTICAS FINAIS
print(f"\nüìà ESTAT√çSTICAS FINAIS:")
print(f"   ‚Ä¢ Categorias: {df['Classifica√ß√£o'].nunique()}")
print(f"   ‚Ä¢ Distribui√ß√£o: \n{df['Classifica√ß√£o'].value_counts().sort_index()}")
print(f"   ‚Ä¢ Valores ordinais: {df['Classifica√ß√£o_Ordinal'].value_counts().sort_index()}")

# 8. REMOVER COLUNAS TEMPOR√ÅRIAS DE AN√ÅLISE
colunas_remover = [col for col in ['Problemas_Classificacao'] if col in df.columns]
df = df.drop(columns=colunas_remover)

# 9. SALVAR RESULTADO
df.to_csv('Base_Dados_Exercicio_01_classificacao.csv', index=False)
print(f"\nüíæ Arquivo salvo: 'Base_Dados_Exercicio_01_classificacao.csv'")

# 10. RELAT√ìRIO FINAL
print(f"\nüéØ PADRONIZA√á√ÉO CONCLU√çDA:")
print(f"   ‚úÖ Coluna 'Classifica√ß√£o' mantida e validada")
print(f"   ‚úÖ Capitaliza√ß√£o consistente aplicada")
print(f"   ‚úÖ Coluna ordinal criada para an√°lise num√©rica")
print(f"   ‚úÖ Consist√™ncia validada com tamanho da empresa")
print(f"   ‚úÖ 0 valores nulos - 100% de qualidade")

print(f"\nüìä CATEGORIAS FINAIS:")
for i, (categoria, count) in enumerate(df['Classifica√ß√£o'].value_counts().items(), 1):
    print(f"   {i}. {categoria}: {count} empresas")

